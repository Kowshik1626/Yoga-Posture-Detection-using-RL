{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9fb365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprting packages\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy ap np\n",
    "import pyttsx3\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d85f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which takes a text file as parameter and convert the text into audio,when the function is called.\n",
    "engine = pyttsx3.init()\n",
    "def text2speech(text_file):\n",
    "    pose=text_file\n",
    "    f=open(pose,'r')\n",
    "    text=f.read()\n",
    "    f.close()\n",
    "    engine.setProperty('rate',150)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcbd4775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to calculate angles between two bones which will be used further.\n",
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4283e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Creating lable variable\n",
    "label=\"Unknown Pose\"\n",
    "\n",
    "# Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        ##STEP I \n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "    \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "        # Extract landmarks \n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            right_shoulder= [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            \n",
    "            # STEP II:Calculate angle between the joints\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle=calculate_angle(right_shoulder,right_elbow,right_wrist)\n",
    "            left_shoulder_angle = calculate_angle(left_hip, left_shoulder, left_elbow)\n",
    "            right_shoulder_angle = calculate_angle(right_hip, right_shoulder, right_elbow)\n",
    "            left_hip_angle=calculate_angle(left_knee,left_hip,left_shoulder)\n",
    "            right_hip_angle=calculate_angle(right_knee,right_hip,right_shoulder)\n",
    "            left_knee_angle=calculate_angle(left_ankle,left_knee,left_hip)\n",
    "            right_knee_angle=calculate_angle(right_ankle,right_knee,right_hip)\n",
    "           \n",
    "            #STEP III: Classifing poses\n",
    "            #Check if hands are staright or not\n",
    "            if left_elbow_angle > 165 and left_elbow_angle < 195 and right_elbow_angle > 165 and right_elbow_angle < 195:\n",
    "                if left_shoulder_angle > 80 and left_shoulder_angle < 110 and right_shoulder_angle > 80 and right_shoulder_angle < 110:\n",
    "                    #Warrior II pose\n",
    "                    if left_knee_angle > 165 and left_knee_angle < 195 or right_knee_angle > 165 and right_knee_angle < 195:\n",
    "                        if left_knee_angle > 90 and left_knee_angle < 120 or right_knee_angle > 90 and right_knee_angle < 120:\n",
    "                            label=\"warrior II Pose\"\n",
    "                            text2speech(\"Warrior_II.txt\")\n",
    "                    #T Pose\n",
    "                    if left_knee_angle > 160 and left_knee_angle < 195 and right_knee_angle > 160 and right_knee_angle < 195:\n",
    "                        label = 'T Pose'    \n",
    "                        text2speech(\"TPose.txt\")\n",
    "            #Tree Pose\n",
    "            if left_knee_angle > 165 and left_knee_angle < 195 or right_knee_angle > 165 and right_knee_angle < 195 :\n",
    "                if left_knee_angle > 315 and left_knee_angle < 335 or right_knee_angle > 25 and right_knee_angle < 45 :\n",
    "                    label = 'Tree Pose'\n",
    "                    text2speech(\"treepose.txt\")\n",
    "                    \n",
    "            else:\n",
    "                label = 'Unknown Pose'\n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #Showing label on the output screen\n",
    "        cv2.putText(image, label,(10,60),cv2.FONT_HERSHEY_SIMPLEX, 1,(0,255,0), 1, cv2.LINE_AA)\n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2))\n",
    "                \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "686b8fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "\n",
    "# class PolicyNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(PolicyNetwork, self).__init__()\n",
    "#         self.fc1 = nn.Linear(16, 128) # 16 joint angles as input\n",
    "#         self.fc2 = nn.Linear(128, 16) # 16 joint angles as output (representing the pose)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = torch.tanh(self.fc2(x)) # tanh is used for continuous action spaces\n",
    "#         return x\n",
    "\n",
    "# policy = PolicyNetwork()\n",
    "# optimizer = optim.Adam(policy.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# def get_reward(current_pose, target_pose):\n",
    "#     return -torch.sum(torch.abs(current_pose - target_pose))\n",
    "\n",
    "# # Inside your main loop\n",
    "# state = torch.tensor([left_elbow_angle, right_elbow_angle, left_shoulder_angle, \n",
    "#                       right_shoulder_angle, left_hip_angle, right_hip_angle, \n",
    "#                       left_knee_angle, right_knee_angle], requires_grad=True) # Add more angles as required\n",
    "\n",
    "# action = policy(state)\n",
    "# next_state = apply_action(state, action) # You need to define this function to simulate the pose change\n",
    "\n",
    "# reward = get_reward(next_state, target_pose) # target_pose should be defined somewhere\n",
    "\n",
    "# # Save the reward and log prob for REINFORCE\n",
    "# rewards.append(reward)\n",
    "# log_probs.append(torch.log(policy(state)))\n",
    "\n",
    "# # After an episode ends\n",
    "# returns = []\n",
    "# R = 0\n",
    "# for r in rewards[::-1]:\n",
    "#     R = r + 0.99 * R\n",
    "#     returns.insert(0, R)\n",
    "\n",
    "# returns = torch.tensor(returns)\n",
    "# returns = (returns - returns.mean()) / (returns.std() + 1e-9)\n",
    "\n",
    "# for log_prob, R in zip(log_probs, returns):\n",
    "#     policy_loss.append(-log_prob * R)\n",
    "\n",
    "# optimizer.zero_grad()\n",
    "# policy_loss.backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b13e25f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import logging\n",
    "\n",
    "# Set up the logger\n",
    "logging.basicConfig(filename='log.txt', level=logging.INFO)\n",
    "\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(16, 128) # 16 joint angles as input\n",
    "        self.fc2 = nn.Linear(128, 16) # 16 joint angles as output (representing the pose)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x)) # tanh is used for continuous action spaces\n",
    "        return x\n",
    "\n",
    "policy = PolicyNetwork()\n",
    "optimizer = optim.Adam(policy.parameters(), lr=0.01)\n",
    "\n",
    "def get_reward(current_pose, target_pose):\n",
    "    return -torch.sum(torch.abs(current_pose - target_pose))\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Creating label variable\n",
    "label=\"Unknown Pose\"\n",
    "\n",
    "# Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Extract landmarks \n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            right_shoulder= [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            \n",
    "            # STEP II:Calculate angle between the joints\n",
    "            left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "            right_elbow_angle=calculate_angle(right_shoulder,right_elbow,right_wrist)\n",
    "            left_shoulder_angle = calculate_angle(left_hip, left_shoulder, left_elbow)\n",
    "            right_shoulder_angle = calculate_angle(right_hip, right_shoulder, right_elbow)\n",
    "            left_hip_angle=calculate_angle(left_knee,left_hip,left_shoulder)\n",
    "            right_hip_angle=calculate_angle(right_knee,right_hip,right_shoulder)\n",
    "            left_knee_angle=calculate_angle(left_ankle,left_knee,left_hip)\n",
    "            right_knee_angle=calculate_angle(right_ankle,right_knee,right_hip) \n",
    "\n",
    "            #STEP III: Classifing poses\n",
    "            #Check if hands are staright or not\n",
    "            if left_elbow_angle > 165 and left_elbow_angle < 195 and right_elbow_angle > 165 and right_elbow_angle < 195:\n",
    "                if left_shoulder_angle > 80 and left_shoulder_angle < 110 and right_shoulder_angle > 80 and right_shoulder_angle < 110:\n",
    "                    #Warrior II pose\n",
    "                    if left_knee_angle > 165 and left_knee_angle < 195 or right_knee_angle > 165 and right_knee_angle < 195:\n",
    "                        if left_knee_angle > 90 and left_knee_angle < 120 or right_knee_angle > 90 and right_knee_angle < 120:\n",
    "                            label=\"warrior II Pose\"\n",
    "                            text2speech(\"Warrior_II.txt\")\n",
    "                    #T Pose\n",
    "                    if left_knee_angle > 160 and left_knee_angle < 195 and right_knee_angle > 160 and right_knee_angle < 195:\n",
    "                        label = 'T Pose'    \n",
    "                        text2speech(\"TPose.txt\")\n",
    "            #Tree Posey\n",
    "            if left_knee_angle > 165 and left_knee_angle < 195 or right_knee_angle > 165 and right_knee_angle < 195 :\n",
    "                if left_knee_angle > 315 and left_knee_angle < 335 or right_knee_angle > 25 and right_knee_angle < 45 :\n",
    "                    label = 'Tree Pose'\n",
    "                    text2speech(\"treepose.txt\")\n",
    "                    \n",
    "            else:\n",
    "                label = 'Unknown Pose'\n",
    "\n",
    "\n",
    "            action = policy(state)\n",
    "            next_state = apply_action(state, action) # You need to define this function to simulate the pose change\n",
    "\n",
    "            reward = get_reward(next_state, target_pose) # target_pose should be defined somewhere\n",
    "\n",
    "            # Save the reward and log prob for REINFORCE\n",
    "            rewards.append(reward)\n",
    "            log_probs.append(torch.log(policy(state)))\n",
    "\n",
    "            # After an episode ends\n",
    "            returns = []\n",
    "            R = 0\n",
    "            for r in rewards[::-1]:\n",
    "                R = r + 0.99 * R\n",
    "                returns.insert(0, R)\n",
    "\n",
    "            returns = torch.tensor(returns)\n",
    "            returns = (returns - returns.mean()) / (returns.std() + 1e-9)\n",
    "\n",
    "            for log_prob, R in zip(log_probs, returns):\n",
    "                policy_loss.append(-log_prob * R)\n",
    "            \n",
    "            # Log the reward and policy loss\n",
    "            logging.info(f\"Reward: {reward}\")\n",
    "            logging.info(f\"Policy loss: {policy_loss}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            policy_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Showing label on the output screen\n",
    "        cv2.putText(image, label,(10,60),cv2.FONT_HERSHEY_SIMPLEX, 1,(0,255,0), 1, cv2.LINE_AA)\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2))\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da86fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a) \n",
    "    b = np.array(b) \n",
    "    c = np.array(c) \n",
    "\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle\n",
    "\n",
    "def get_joint_angles(landmarks):\n",
    "    # Extract landmarks\n",
    "    left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "    left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "    left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "    left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "    left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "    left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "    right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "    right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "    right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "    right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "    right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "    right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "    # Calculate angles\n",
    "    left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "    right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "    left_shoulder_angle = calculate_angle(left_hip, left_shoulder, left_elbow)\n",
    "    right_shoulder_angle = calculate_angle(right_hip, right_shoulder, right_elbow)\n",
    "    left_hip_angle = calculate_angle(left_knee, left_hip, left_shoulder)\n",
    "    right_hip_angle = calculate_angle(right_knee, right_hip, right_shoulder)\n",
    "    left_knee_angle = calculate_angle(left_ankle, left_knee, left_hip)\n",
    "    right_knee_angle = calculate_angle(right_ankle, right_knee, right_hip)\n",
    "\n",
    "    joint_angles = [left_elbow_angle, right_elbow_angle, left_shoulder_angle, right_shoulder_angle, left_hip_angle, right_hip_angle, left_knee_angle, right_knee_angle]\n",
    "\n",
    "    return joint_angles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a50c1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Add MediaPipe Hands\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Define the Policy Network\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(16, 128) # 16 joint angles as input\n",
    "        self.fc2 = nn.Linear(128, 16) # 16 joint angles as output (representing the pose)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x)) # tanh is used for continuous action spaces\n",
    "        return x\n",
    "\n",
    "# Initialize the policy and optimizer\n",
    "policy = PolicyNetwork()\n",
    "optimizer = optim.Adam(policy.parameters(), lr=0.01)\n",
    "\n",
    "def apply_action(state, action):\n",
    "    next_state = state + action\n",
    "    return next_state\n",
    "\n",
    "def get_reward(current_pose, target_pose):\n",
    "    return -torch.sum(torch.abs(current_pose - target_pose))\n",
    "\n",
    "target_pose = torch.tensor([90, 90, 0, 0, 0, 90, 90, 0, 0, 0, 90, 90, 0, 0, 0, 90])  # Example target pose\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get joint angles\n",
    "            joint_angles = get_joint_angles(landmarks)\n",
    "            state = torch.tensor(joint_angles)\n",
    "            action = policy(state)\n",
    "            next_state = apply_action(state, action)\n",
    "            \n",
    "            reward = get_reward(next_state, target_pose)\n",
    "            print(f\"Reward: {reward}\")\n",
    "\n",
    "            policy_loss = -reward\n",
    "            print(f\"Policy loss: {policy_loss}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            policy_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a28562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Define the Policy Network\n",
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PolicyNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(16, 128) # 16 joint angles as input\n",
    "        self.fc2 = nn.Linear(128, 16) # 16 joint angles as output (representing the pose)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x)) # tanh is used for continuous action spaces\n",
    "        return x\n",
    "\n",
    "# Initialize the policy and optimizer\n",
    "policy = PolicyNetwork()\n",
    "optimizer = optim.Adam(policy.parameters(), lr=0.01)\n",
    "\n",
    "def apply_action(state, action):\n",
    "    next_state = state + action\n",
    "    return next_state\n",
    "\n",
    "def get_reward(current_pose, target_pose):\n",
    "    return -torch.sum(torch.abs(current_pose - target_pose))\n",
    "\n",
    "target_pose = torch.tensor([90, 90, 0, 0, 0, 90, 90, 0, 0, 0, 90, 90, 0, 0, 0, 90])  # Example target pose\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get joint angles\n",
    "            joint_angles = get_joint_angles(landmarks)  # You need to define this function\n",
    "            state = torch.tensor(joint_angles)\n",
    "            action = policy(state)\n",
    "            next_state = apply_action(state, action)\n",
    "            \n",
    "            reward = get_reward(next_state, target_pose)\n",
    "            print(f\"Reward: {reward}\")\n",
    "\n",
    "            policy_loss = -reward\n",
    "            print(f\"Policy loss: {policy_loss}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            policy_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# import torch\n",
    "\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "# mp_pose = mp.solutions.pose\n",
    "\n",
    "# # Define your policy network here\n",
    "# class PolicyNetwork(nn.Module):\n",
    "#     # Define the structure of your network here\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Define the forward pass of your network here\n",
    "#         return output\n",
    "\n",
    "# # Initialize the policy and optimizer\n",
    "# policy = PolicyNetwork()\n",
    "# optimizer = torch.optim.Adam(policy.parameters(), lr=0.01)\n",
    "\n",
    "# # Placeholder functions\n",
    "# def apply_action(state, action):\n",
    "#     return state + action\n",
    "\n",
    "# def get_reward(state, target_pose):\n",
    "#     return -torch.sum(torch.abs(state - target_pose))\n",
    "\n",
    "# def calculate_angle(a, b, c):\n",
    "#     a = torch.tensor(a) - torch.tensor(b)\n",
    "#     b = torch.tensor(c) - torch.tensor(b)\n",
    "    \n",
    "#     cosine_angle = torch.dot(a, b) / (torch.norm(a) * torch.norm(b))\n",
    "#     angle = torch.arccos(cosine_angle)\n",
    "    \n",
    "#     return angle\n",
    "\n",
    "# def get_joint_angles(landmarks):\n",
    "#     # Same as before\n",
    "\n",
    "# # For the sake of demonstration, let's define a target_pose\n",
    "# target_pose = torch.tensor([180, 315, 0, 0, 0, 0, 0, 0])  # Change this according to your use case\n",
    "\n",
    "# # For webcam input:\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "#     while cap.isOpened():\n",
    "#         success, image = cap.read()\n",
    "#         if not success:\n",
    "#             print(\"Ignoring empty camera frame.\")\n",
    "#             continue\n",
    "\n",
    "#         # Same as before\n",
    "        \n",
    "#         try:\n",
    "#             landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "#             # Get joint angles\n",
    "#             joint_angles = get_joint_angles(landmarks)\n",
    "#             current_pose = torch.tensor(joint_angles)  # current_pose is the same as state in this case\n",
    "\n",
    "#             print(f\"Current pose: {current_pose}\")\n",
    "\n",
    "#             # Get action from policy\n",
    "#             action = policy(current_pose.float())\n",
    "\n",
    "#             print(f\"Action: {action}\")\n",
    "\n",
    "#             next_pose = apply_action(current_pose, action)\n",
    "\n",
    "#             print(f\"Next pose: {next_pose}\")\n",
    "\n",
    "#             reward = get_reward(next_pose, target_pose)\n",
    "\n",
    "#             print(f\"Reward: {reward}\")\n",
    "            \n",
    "#             # Policy gradient step\n",
    "#             optimizer.zero_grad()\n",
    "#             loss = -reward  # we want to maximize reward, which is equivalent to minimizing negative reward\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"Exception: {e}\")\n",
    "\n",
    "# cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d442113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pose: tensor([2.7968, 2.7891, 0.3397, 0.3304, 3.0016, 3.1033, 3.1409, 3.0871])\n",
      "Action: tensor([2.7968, 2.7891, 0.3397, 0.3304, 3.0016, 3.1033, 3.1409, 3.0871])\n",
      "Next pose: tensor([5.5936, 5.5783, 0.6795, 0.6608, 6.0031, 6.2065, 6.2818, 6.1742])\n",
      "Reward: -19.102073669433594\n",
      "Discounted Reward: -19.102073669433594\n",
      "Current pose: tensor([2.7622, 2.7686, 0.3718, 0.3292, 2.9778, 3.1149, 3.1412, 3.0894])\n",
      "Action: tensor([2.7622, 2.7686, 0.3718, 0.3292, 2.9778, 3.1149, 3.1412, 3.0894])\n",
      "Next pose: tensor([5.5244, 5.5372, 0.7435, 0.6584, 5.9555, 6.2298, 6.2825, 6.1788])\n",
      "Reward: -18.910991668701172\n",
      "Discounted Reward: -18.721881866455078\n",
      "Current pose: tensor([2.7566, 2.7528, 0.3794, 0.3190, 2.9763, 3.1140, 3.1399, 3.0881])\n",
      "Action: tensor([2.7566, 2.7528, 0.3794, 0.3190, 2.9763, 3.1140, 3.1399, 3.0881])\n",
      "Next pose: tensor([5.5133, 5.5056, 0.7589, 0.6381, 5.9525, 6.2280, 6.2799, 6.1763])\n",
      "Reward: -18.86334800720215\n",
      "Discounted Reward: -18.487966537475586\n",
      "Current pose: tensor([2.7866, 2.7962, 0.4018, 0.2761, 2.9796, 3.1115, 3.1395, 3.0970])\n",
      "Action: tensor([2.7866, 2.7962, 0.4018, 0.2761, 2.9796, 3.1115, 3.1395, 3.0970])\n",
      "Next pose: tensor([5.5731, 5.5924, 0.8036, 0.5521, 5.9591, 6.2229, 6.2789, 6.1940])\n",
      "Reward: -19.069419860839844\n",
      "Discounted Reward: -18.50303840637207\n",
      "Current pose: tensor([2.7721, 2.8211, 0.4303, 0.2551, 2.9829, 3.1066, 3.1369, 3.0965])\n",
      "Action: tensor([2.7721, 2.8211, 0.4303, 0.2551, 2.9829, 3.1066, 3.1369, 3.0965])\n",
      "Next pose: tensor([5.5443, 5.6423, 0.8606, 0.5103, 5.9658, 6.2132, 6.2738, 6.1931])\n",
      "Reward: -19.06629180908203\n",
      "Discounted Reward: -18.315004348754883\n",
      "Current pose: tensor([2.7899, 2.8292, 0.4348, 0.2527, 2.9849, 3.0959, 3.1314, 3.1205])\n",
      "Action: tensor([2.7899, 2.8292, 0.4348, 0.2527, 2.9849, 3.0959, 3.1314, 3.1205])\n",
      "Next pose: tensor([5.5797, 5.6584, 0.8695, 0.5054, 5.9697, 6.1918, 6.2628, 6.2411])\n",
      "Reward: -19.133394241333008\n",
      "Discounted Reward: -18.195667266845703\n",
      "Current pose: tensor([2.8085, 2.8575, 0.4233, 0.2586, 2.9921, 3.0808, 3.1297, 3.1354])\n",
      "Action: tensor([2.8085, 2.8575, 0.4233, 0.2586, 2.9921, 3.0808, 3.1297, 3.1354])\n",
      "Next pose: tensor([5.6169, 5.7150, 0.8465, 0.5172, 5.9843, 6.1617, 6.2594, 6.2709])\n",
      "Reward: -19.249143600463867\n",
      "Discounted Reward: -18.1226863861084\n",
      "Current pose: tensor([2.7972, 2.8721, 0.4246, 0.2553, 2.9958, 3.0802, 3.1296, 3.1344])\n",
      "Action: tensor([2.7972, 2.8721, 0.4246, 0.2553, 2.9958, 3.0802, 3.1296, 3.1344])\n",
      "Next pose: tensor([5.5944, 5.7441, 0.8492, 0.5106, 5.9915, 6.1604, 6.2592, 6.2688])\n",
      "Reward: -19.263429641723633\n",
      "Discounted Reward: -17.954774856567383\n",
      "Current pose: tensor([2.7962, 2.8416, 0.4290, 0.2552, 2.9973, 3.0835, 3.1309, 3.1303])\n",
      "Action: tensor([2.7962, 2.8416, 0.4290, 0.2552, 2.9973, 3.0835, 3.1309, 3.1303])\n",
      "Next pose: tensor([5.5924, 5.6833, 0.8581, 0.5104, 5.9946, 6.1670, 6.2618, 6.2606])\n",
      "Reward: -19.19586181640625\n",
      "Discounted Reward: -17.712879180908203\n",
      "Current pose: tensor([2.7868, 2.8402, 0.4323, 0.2555, 2.9989, 3.0854, 3.1313, 3.1288])\n",
      "Action: tensor([2.7868, 2.8402, 0.4323, 0.2555, 2.9989, 3.0854, 3.1313, 3.1288])\n",
      "Next pose: tensor([5.5736, 5.6805, 0.8646, 0.5110, 5.9978, 6.1709, 6.2627, 6.2576])\n",
      "Reward: -19.172199249267578\n",
      "Discounted Reward: -17.514135360717773\n",
      "Current pose: tensor([2.8163, 2.9352, 0.4157, 0.2508, 3.0021, 3.0722, 3.1228, 3.1344])\n",
      "Action: tensor([2.8163, 2.9352, 0.4157, 0.2508, 3.0021, 3.0722, 3.1228, 3.1344])\n",
      "Next pose: tensor([5.6326, 5.8704, 0.8315, 0.5016, 6.0041, 6.1444, 6.2455, 6.2688])\n",
      "Reward: -19.437620162963867\n",
      "Discounted Reward: -17.57903480529785\n",
      "Current pose: tensor([2.8089, 2.9528, 0.4155, 0.2492, 3.0050, 3.0724, 3.1262, 3.1416])\n",
      "Action: tensor([2.8089, 2.9528, 0.4155, 0.2492, 3.0050, 3.0724, 3.1262, 3.1416])\n",
      "Next pose: tensor([5.6178, 5.9056, 0.8311, 0.4984, 6.0100, 6.1447, 6.2524, 6.2832])\n",
      "Reward: -19.488916397094727\n",
      "Discounted Reward: -17.449172973632812\n",
      "Current pose: tensor([2.8058, 2.9577, 0.4141, 0.2511, 3.0074, 3.0743, 3.1269, 3.1407])\n",
      "Action: tensor([2.8058, 2.9577, 0.4141, 0.2511, 3.0074, 3.0743, 3.1269, 3.1407])\n",
      "Next pose: tensor([5.6117, 5.9154, 0.8282, 0.5022, 6.0149, 6.1486, 6.2539, 6.2815])\n",
      "Reward: -19.500118255615234\n",
      "Discounted Reward: -17.284608840942383\n",
      "Current pose: tensor([2.8094, 2.9087, 0.4132, 0.2503, 3.0041, 3.0885, 3.1313, 3.1282])\n",
      "Action: tensor([2.8094, 2.9087, 0.4132, 0.2503, 3.0041, 3.0885, 3.1313, 3.1282])\n",
      "Next pose: tensor([5.6187, 5.8175, 0.8263, 0.5005, 6.0082, 6.1770, 6.2625, 6.2564])\n",
      "Reward: -19.418231964111328\n",
      "Discounted Reward: -17.039907455444336\n",
      "Current pose: tensor([2.8091, 2.8862, 0.4124, 0.2500, 3.0029, 3.0947, 3.1331, 3.1221])\n",
      "Action: tensor([2.8091, 2.8862, 0.4124, 0.2500, 3.0029, 3.0947, 3.1331, 3.1221])\n",
      "Next pose: tensor([5.6183, 5.7724, 0.8248, 0.5000, 6.0059, 6.1894, 6.2663, 6.2443])\n",
      "Reward: -19.376306533813477\n",
      "Discounted Reward: -16.833084106445312\n",
      "Current pose: tensor([2.8171, 2.9101, 0.3940, 0.2415, 3.0032, 3.0928, 3.1342, 3.1211])\n",
      "Action: tensor([2.8171, 2.9101, 0.3940, 0.2415, 3.0032, 3.0928, 3.1342, 3.1211])\n",
      "Next pose: tensor([5.6342, 5.8201, 0.7881, 0.4829, 6.0063, 6.1857, 6.2684, 6.2421])\n",
      "Reward: -19.490550994873047\n",
      "Discounted Reward: -16.763011932373047\n",
      "Current pose: tensor([2.8363, 2.9127, 0.3914, 0.2425, 3.0078, 3.0929, 3.1280, 3.1246])\n",
      "Action: tensor([2.8363, 2.9127, 0.3914, 0.2425, 3.0078, 3.0929, 3.1280, 3.1246])\n",
      "Next pose: tensor([5.6727, 5.8254, 0.7827, 0.4851, 6.0156, 6.1858, 6.2559, 6.2492])\n",
      "Reward: -19.541444778442383\n",
      "Discounted Reward: -16.638715744018555\n",
      "Current pose: tensor([2.8518, 2.9130, 0.3910, 0.2433, 3.0089, 3.0948, 3.1253, 3.1252])\n",
      "Action: tensor([2.8518, 2.9130, 0.3910, 0.2433, 3.0089, 3.0948, 3.1253, 3.1252])\n",
      "Next pose: tensor([5.7037, 5.8260, 0.7820, 0.4867, 6.0177, 6.1897, 6.2506, 6.2505])\n",
      "Reward: -19.57416534423828\n",
      "Discounted Reward: -16.499910354614258\n",
      "Current pose: tensor([2.8478, 2.9098, 0.3960, 0.2444, 3.0073, 3.0965, 3.1237, 3.1281])\n",
      "Action: tensor([2.8478, 2.9098, 0.3960, 0.2444, 3.0073, 3.0965, 3.1237, 3.1281])\n",
      "Next pose: tensor([5.6956, 5.8195, 0.7921, 0.4888, 6.0146, 6.1929, 6.2474, 6.2562])\n",
      "Reward: -19.550148010253906\n",
      "Discounted Reward: -16.314868927001953\n",
      "Current pose: tensor([2.8516, 2.8986, 0.4055, 0.2450, 3.0057, 3.0990, 3.1240, 3.1260])\n",
      "Action: tensor([2.8516, 2.8986, 0.4055, 0.2450, 3.0057, 3.0990, 3.1240, 3.1260])\n",
      "Next pose: tensor([5.7033, 5.7971, 0.8109, 0.4900, 6.0115, 6.1980, 6.2481, 6.2521])\n",
      "Reward: -19.513809204101562\n",
      "Discounted Reward: -16.12169647216797\n",
      "Current pose: tensor([2.8490, 2.9140, 0.4124, 0.2194, 3.0042, 3.0948, 3.1250, 3.1235])\n",
      "Action: tensor([2.8490, 2.9140, 0.4124, 0.2194, 3.0042, 3.0948, 3.1250, 3.1235])\n",
      "Next pose: tensor([5.6980, 5.8281, 0.8248, 0.4388, 6.0084, 6.1896, 6.2501, 6.2469])\n",
      "Reward: -19.562192916870117\n",
      "Discounted Reward: -16.00005340576172\n",
      "Current pose: tensor([2.8328, 2.9070, 0.4256, 0.2312, 2.9904, 3.0848, 3.1373, 3.1250])\n",
      "Action: tensor([2.8328, 2.9070, 0.4256, 0.2312, 2.9904, 3.0848, 3.1373, 3.1250])\n",
      "Next pose: tensor([5.6656, 5.8140, 0.8512, 0.4623, 5.9808, 6.1695, 6.2746, 6.2499])\n",
      "Reward: -19.445743560791016\n",
      "Discounted Reward: -15.745759963989258\n",
      "Current pose: tensor([2.8400, 2.9049, 0.4276, 0.2359, 2.9832, 3.0801, 3.1377, 3.1272])\n",
      "Action: tensor([2.8400, 2.9049, 0.4276, 0.2359, 2.9832, 3.0801, 3.1377, 3.1272])\n",
      "Next pose: tensor([5.6800, 5.8099, 0.8552, 0.4717, 5.9664, 6.1602, 6.2755, 6.2543])\n",
      "Reward: -19.424091339111328\n",
      "Discounted Reward: -15.57094669342041\n",
      "Current pose: tensor([0.1124, 2.6811, 0.5539, 0.2817, 2.9259, 3.0968, 3.1048, 2.8897])\n",
      "Action: tensor([0.1124, 2.6811, 0.5539, 0.2817, 2.9259, 3.0968, 3.1048, 2.8897])\n",
      "Next pose: tensor([0.2248, 5.3623, 1.1077, 0.5634, 5.8518, 6.1936, 6.2096, 5.7795])\n",
      "Reward: -18.384084701538086\n",
      "Discounted Reward: -14.589872360229492\n",
      "Current pose: tensor([0.0475, 2.5680, 0.5854, 0.3091, 2.9696, 3.0657, 3.1205, 2.7682])\n",
      "Action: tensor([0.0475, 2.5680, 0.5854, 0.3091, 2.9696, 3.0657, 3.1205, 2.7682])\n",
      "Next pose: tensor([0.0950, 5.1360, 1.1707, 0.6182, 5.9391, 6.1315, 6.2409, 5.5364])\n",
      "Reward: -17.98322105407715\n",
      "Discounted Reward: -14.129023551940918\n",
      "Current pose: tensor([0.4648, 2.5493, 0.5906, 0.3018, 2.9905, 3.0372, 3.0806, 2.8875])\n",
      "Action: tensor([0.4648, 2.5493, 0.5906, 0.3018, 2.9905, 3.0372, 3.0806, 2.8875])\n",
      "Next pose: tensor([0.9296, 5.0985, 1.1811, 0.6037, 5.9809, 6.0744, 6.1612, 5.7750])\n",
      "Reward: -17.258880615234375\n",
      "Discounted Reward: -13.424325942993164\n",
      "Current pose: tensor([0.9490, 2.5316, 0.6073, 0.3334, 2.9978, 3.0196, 3.0646, 2.9157])\n",
      "Action: tensor([0.9490, 2.5316, 0.6073, 0.3334, 2.9978, 3.0196, 3.0646, 2.9157])\n",
      "Next pose: tensor([1.8979, 5.0632, 1.2147, 0.6668, 5.9955, 6.0392, 6.1291, 5.8314])\n",
      "Reward: -16.162429809570312\n",
      "Discounted Reward: -12.445768356323242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pose: tensor([0.3689, 1.1785, 0.5574, 0.4495, 3.0506, 2.9867, 2.7815, 2.7521])\n",
      "Action: tensor([0.3689, 1.1785, 0.5574, 0.4495, 3.0506, 2.9867, 2.7815, 2.7521])\n",
      "Next pose: tensor([0.7379, 2.3571, 1.1147, 0.8990, 6.1013, 5.9733, 5.5629, 5.5042])\n",
      "Reward: -14.841346740722656\n",
      "Discounted Reward: -11.314191818237305\n",
      "Current pose: tensor([2.6556, 2.6076, 0.4503, 0.2753, 2.9994, 3.0404, 3.0578, 3.0544])\n",
      "Action: tensor([2.6556, 2.6076, 0.4503, 0.2753, 2.9994, 3.0404, 3.0578, 3.0544])\n",
      "Next pose: tensor([5.3112, 5.2151, 0.9006, 0.5506, 5.9987, 6.0809, 6.1155, 6.1088])\n",
      "Reward: -17.98379135131836\n",
      "Discounted Reward: -13.572714805603027\n",
      "Current pose: tensor([2.8197, 2.7068, 0.3871, 0.2485, 2.9940, 3.0502, 3.1037, 3.1210])\n",
      "Action: tensor([2.8197, 2.7068, 0.3871, 0.2485, 2.9940, 3.0502, 3.1037, 3.1210])\n",
      "Next pose: tensor([5.6394, 5.4136, 0.7742, 0.4969, 5.9880, 6.1004, 6.2075, 6.2421])\n",
      "Reward: -18.92440414428711\n",
      "Discounted Reward: -14.139786720275879\n",
      "Current pose: tensor([2.9667, 2.7709, 0.4164, 0.2337, 2.9959, 3.0638, 3.1364, 3.1345])\n",
      "Action: tensor([2.9667, 2.7709, 0.4164, 0.2337, 2.9959, 3.0638, 3.1364, 3.1345])\n",
      "Next pose: tensor([5.9335, 5.5418, 0.8329, 0.4673, 5.9917, 6.1276, 6.2728, 6.2690])\n",
      "Reward: -19.440828323364258\n",
      "Discounted Reward: -14.380388259887695\n",
      "Current pose: tensor([2.9917, 2.7881, 0.4473, 0.2179, 2.9958, 3.0879, 3.1253, 3.0960])\n",
      "Action: tensor([2.9917, 2.7881, 0.4473, 0.2179, 2.9958, 3.0879, 3.1253, 3.0960])\n",
      "Next pose: tensor([5.9835, 5.5761, 0.8947, 0.4358, 5.9916, 6.1758, 6.2506, 6.1920])\n",
      "Reward: -19.443843841552734\n",
      "Discounted Reward: -14.238792419433594\n",
      "Current pose: tensor([3.1395, 2.8961, 0.2794, 0.2413, 2.9842, 3.1272, 3.1245, 3.0731])\n",
      "Action: tensor([3.1395, 2.8961, 0.2794, 0.2413, 2.9842, 3.1272, 3.1245, 3.0731])\n",
      "Next pose: tensor([6.2790, 5.7922, 0.5589, 0.4825, 5.9684, 6.2544, 6.2490, 6.1461])\n",
      "Reward: -20.252408981323242\n",
      "Discounted Reward: -14.682599067687988\n",
      "Current pose: tensor([1.6455, 2.0687, 0.1990, 0.2385, 3.0522, 3.1127, 3.1381, 3.0472])\n",
      "Action: tensor([1.6455, 2.0687, 0.1990, 0.2385, 3.0522, 3.1127, 3.1381, 3.0472])\n",
      "Next pose: tensor([3.2910, 4.1374, 0.3979, 0.4769, 6.1043, 6.2255, 6.2762, 6.0945])\n",
      "Reward: -15.858670234680176\n",
      "Discounted Reward: -11.382251739501953\n",
      "Current pose: tensor([1.1393, 2.1522, 0.3326, 0.2535, 3.0248, 3.0163, 3.1320, 2.9222])\n",
      "Action: tensor([1.1393, 2.1522, 0.3326, 0.2535, 3.0248, 3.0163, 3.1320, 2.9222])\n",
      "Next pose: tensor([2.2787, 4.3044, 0.6653, 0.5069, 6.0496, 6.0325, 6.2639, 5.8445])\n",
      "Reward: -15.92733383178711\n",
      "Discounted Reward: -11.317218780517578\n",
      "Current pose: tensor([2.0597, 2.2491, 0.2446, 0.2491, 2.9912, 3.0898, 3.1121, 2.9362])\n",
      "Action: tensor([2.0597, 2.2491, 0.2446, 0.2491, 2.9912, 3.0898, 3.1121, 2.9362])\n",
      "Next pose: tensor([4.1194, 4.4982, 0.4891, 0.4982, 5.9823, 6.1796, 6.2241, 5.8725])\n",
      "Reward: -16.49350929260254\n",
      "Discounted Reward: -11.60232162475586\n",
      "Current pose: tensor([2.4147, 2.5286, 0.2660, 0.3218, 2.9912, 3.1131, 3.0957, 2.9905])\n",
      "Action: tensor([2.4147, 2.5286, 0.2660, 0.3218, 2.9912, 3.1131, 3.0957, 2.9905])\n",
      "Next pose: tensor([4.8293, 5.0572, 0.5320, 0.6437, 5.9824, 6.2263, 6.1914, 5.9810])\n",
      "Reward: -17.696796417236328\n",
      "Discounted Reward: -12.3242826461792\n",
      "Current pose: tensor([2.1666, 2.6946, 0.3440, 0.3599, 2.9856, 3.1201, 3.0369, 2.9854])\n",
      "Action: tensor([2.1666, 2.6946, 0.3440, 0.3599, 2.9856, 3.1201, 3.0369, 2.9854])\n",
      "Next pose: tensor([4.3332, 5.3892, 0.6879, 0.7197, 5.9713, 6.2403, 6.0737, 5.9708])\n",
      "Reward: -17.175628662109375\n",
      "Discounted Reward: -11.841721534729004\n",
      "Current pose: tensor([2.4283, 2.6904, 0.3358, 0.3843, 3.0313, 3.0545, 3.0764, 3.0519])\n",
      "Action: tensor([2.4283, 2.6904, 0.3358, 0.3843, 3.0313, 3.0545, 3.0764, 3.0519])\n",
      "Next pose: tensor([4.8565, 5.3807, 0.6715, 0.7686, 6.0626, 6.1090, 6.1527, 6.1038])\n",
      "Reward: -17.83002471923828\n",
      "Discounted Reward: -12.169965744018555\n",
      "Current pose: tensor([2.7186, 2.3114, 0.3290, 0.3730, 3.0133, 3.0503, 3.0728, 3.0918])\n",
      "Action: tensor([2.7186, 2.3114, 0.3290, 0.3730, 3.0133, 3.0503, 3.0728, 3.0918])\n",
      "Next pose: tensor([5.4371, 4.6228, 0.6581, 0.7461, 6.0265, 6.1006, 6.1457, 6.1836])\n",
      "Reward: -17.7169246673584\n",
      "Discounted Reward: -11.971840858459473\n",
      "Current pose: tensor([2.8484, 2.4388, 0.3307, 0.3714, 3.0031, 3.0430, 3.0762, 3.1173])\n",
      "Action: tensor([2.8484, 2.4388, 0.3307, 0.3714, 3.0031, 3.0430, 3.0762, 3.1173])\n",
      "Next pose: tensor([5.6968, 4.8776, 0.6615, 0.7427, 6.0062, 6.0860, 6.1524, 6.2346])\n",
      "Reward: -18.25406837463379\n",
      "Discounted Reward: -12.211456298828125\n",
      "Current pose: tensor([3.1087, 2.5358, 0.2877, 0.3593, 3.0157, 3.0691, 3.1196, 3.1362])\n",
      "Action: tensor([3.1087, 2.5358, 0.2877, 0.3593, 3.0157, 3.0691, 3.1196, 3.1362])\n",
      "Next pose: tensor([6.2174, 5.0716, 0.5754, 0.7186, 6.0314, 6.1383, 6.2392, 6.2725])\n",
      "Reward: -19.281084060668945\n",
      "Discounted Reward: -12.769515991210938\n",
      "Current pose: tensor([3.0026, 2.6361, 0.2624, 0.4130, 2.9332, 2.9918, 2.9729, 3.0744])\n",
      "Action: tensor([3.0026, 2.6361, 0.2624, 0.4130, 2.9332, 2.9918, 2.9729, 3.0744])\n",
      "Next pose: tensor([6.0051, 5.2721, 0.5248, 0.8260, 5.8663, 5.9835, 5.9459, 6.1487])\n",
      "Reward: -18.47553062438965\n",
      "Discounted Reward: -12.113651275634766\n",
      "Current pose: tensor([2.9700, 2.9310, 0.3058, 0.3319, 2.9983, 2.9977, 3.0649, 3.1355])\n",
      "Action: tensor([2.9700, 2.9310, 0.3058, 0.3319, 2.9983, 2.9977, 3.0649, 3.1355])\n",
      "Next pose: tensor([5.9401, 5.8620, 0.6115, 0.6638, 5.9966, 5.9955, 6.1299, 6.2710])\n",
      "Reward: -19.524364471435547\n",
      "Discounted Reward: -12.67331600189209\n",
      "Current pose: tensor([3.0097, 3.0341, 0.2811, 0.2976, 2.9171, 3.0100, 2.9307, 3.1133])\n",
      "Action: tensor([3.0097, 3.0341, 0.2811, 0.2976, 2.9171, 3.0100, 2.9307, 3.1133])\n",
      "Next pose: tensor([6.0194, 6.0682, 0.5622, 0.5953, 5.8342, 6.0199, 5.8613, 6.2266])\n",
      "Reward: -19.476951599121094\n",
      "Discounted Reward: -12.516115188598633\n",
      "Current pose: tensor([3.1333, 3.0173, 0.3027, 0.3548, 3.0578, 3.0224, 3.1280, 3.1263])\n",
      "Action: tensor([3.1333, 3.0173, 0.3027, 0.3548, 3.0578, 3.0224, 3.1280, 3.1263])\n",
      "Next pose: tensor([6.2666, 6.0345, 0.6054, 0.7095, 6.1155, 6.0448, 6.2560, 6.2526])\n",
      "Reward: -20.25987434387207\n",
      "Discounted Reward: -12.8890380859375\n",
      "Current pose: tensor([3.0592, 3.0266, 0.3195, 0.3441, 3.0734, 2.9823, 3.1299, 3.1069])\n",
      "Action: tensor([3.0592, 3.0266, 0.3195, 0.3441, 3.0734, 2.9823, 3.1299, 3.1069])\n",
      "Next pose: tensor([6.1185, 6.0533, 0.6391, 0.6881, 6.1469, 5.9646, 6.2597, 6.2138])\n",
      "Reward: -20.034282684326172\n",
      "Discounted Reward: -12.618064880371094\n",
      "Current pose: tensor([2.9938, 2.9803, 0.3410, 0.4034, 3.0744, 3.0087, 3.1259, 3.1233])\n",
      "Action: tensor([2.9938, 2.9803, 0.3410, 0.4034, 3.0744, 3.0087, 3.1259, 3.1233])\n",
      "Next pose: tensor([5.9875, 5.9607, 0.6821, 0.8069, 6.1487, 6.0175, 6.2518, 6.2466])\n",
      "Reward: -19.72857666015625\n",
      "Discounted Reward: -12.301268577575684\n",
      "Current pose: tensor([3.1362, 2.9580, 0.3194, 0.2908, 3.0887, 2.9565, 3.1322, 3.1065])\n",
      "Action: tensor([3.1362, 2.9580, 0.3194, 0.2908, 3.0887, 2.9565, 3.1322, 3.1065])\n",
      "Next pose: tensor([6.2724, 5.9161, 0.6388, 0.5815, 6.1775, 5.9130, 6.2645, 6.2129])\n",
      "Reward: -20.140769958496094\n",
      "Discounted Reward: -12.432698249816895\n",
      "Current pose: tensor([3.0752, 3.0006, 0.3837, 0.3843, 3.0941, 2.9168, 3.0772, 3.1136])\n",
      "Action: tensor([3.0752, 3.0006, 0.3837, 0.3843, 3.0941, 2.9168, 3.0772, 3.1136])\n",
      "Next pose: tensor([6.1503, 6.0011, 0.7675, 0.7686, 6.1882, 5.8337, 6.1543, 6.2271])\n",
      "Reward: -19.623395919799805\n",
      "Discounted Reward: -11.992196083068848\n",
      "Current pose: tensor([3.0071, 3.0786, 0.3890, 0.3137, 3.1036, 2.8974, 3.0940, 3.0605])\n",
      "Action: tensor([3.0071, 3.0786, 0.3890, 0.3137, 3.1036, 2.8974, 3.0940, 3.0605])\n",
      "Next pose: tensor([6.0142, 6.1572, 0.7780, 0.6274, 6.2073, 5.7948, 6.1881, 6.1211])\n",
      "Reward: -19.681795120239258\n",
      "Discounted Reward: -11.907605171203613\n",
      "Current pose: tensor([2.9563, 3.0874, 0.3858, 0.2849, 3.0981, 2.9179, 3.0981, 3.0653])\n",
      "Action: tensor([2.9563, 3.0874, 0.3858, 0.2849, 3.0981, 2.9179, 3.0981, 3.0653])\n",
      "Next pose: tensor([5.9127, 6.1749, 0.7717, 0.5697, 6.1962, 5.8359, 6.1962, 6.1306])\n",
      "Reward: -19.709754943847656\n",
      "Discounted Reward: -11.805275917053223\n",
      "Current pose: tensor([2.9599, 3.0706, 0.3737, 0.2735, 3.0879, 2.9256, 3.1137, 3.0762])\n",
      "Action: tensor([2.9599, 3.0706, 0.3737, 0.2735, 3.0879, 2.9256, 3.1137, 3.0762])\n",
      "Next pose: tensor([5.9199, 6.1413, 0.7474, 0.5470, 6.1758, 5.8511, 6.2274, 6.1524])\n",
      "Reward: -19.77827262878418\n",
      "Discounted Reward: -11.727851867675781\n",
      "Current pose: tensor([2.9121, 3.1321, 0.3893, 0.2707, 3.1037, 2.9181, 3.1116, 3.0528])\n",
      "Action: tensor([2.9121, 3.1321, 0.3893, 0.2707, 3.1037, 2.9181, 3.1116, 3.0528])\n",
      "Next pose: tensor([5.8241, 6.2643, 0.7786, 0.5414, 6.2075, 5.8362, 6.2232, 6.1056])\n",
      "Reward: -19.745553970336914\n",
      "Discounted Reward: -11.5913667678833\n",
      "Current pose: tensor([2.8835, 3.1201, 0.3948, 0.2901, 3.0928, 2.9207, 3.1198, 3.0634])\n",
      "Action: tensor([2.8835, 3.1201, 0.3948, 0.2901, 3.0928, 2.9207, 3.1198, 3.0634])\n",
      "Next pose: tensor([5.7670, 6.2403, 0.7896, 0.5802, 6.1856, 5.8414, 6.2395, 6.1267])\n",
      "Reward: -19.63524627685547\n",
      "Discounted Reward: -11.411345481872559\n",
      "Current pose: tensor([2.8901, 3.1129, 0.3813, 0.2973, 3.0971, 2.9185, 3.1190, 3.0638])\n",
      "Action: tensor([2.8901, 3.1129, 0.3813, 0.2973, 3.0971, 2.9185, 3.1190, 3.0638])\n",
      "Next pose: tensor([5.7802, 6.2259, 0.7626, 0.5946, 6.1942, 5.8371, 6.2379, 6.1276])\n",
      "Reward: -19.650327682495117\n",
      "Discounted Reward: -11.305909156799316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pose: tensor([2.7913, 3.0966, 0.3936, 0.2842, 3.0856, 2.9565, 3.1172, 3.0748])\n",
      "Action: tensor([2.7913, 3.0966, 0.3936, 0.2842, 3.0856, 2.9565, 3.1172, 3.0748])\n",
      "Next pose: tensor([5.5827, 6.1931, 0.7872, 0.5683, 6.1712, 5.9130, 6.2345, 6.1497])\n",
      "Reward: -19.49334716796875\n",
      "Discounted Reward: -11.103433609008789\n",
      "Current pose: tensor([2.7621, 3.1013, 0.3988, 0.2988, 3.0762, 2.9579, 3.1165, 3.0758])\n",
      "Action: tensor([2.7621, 3.1013, 0.3988, 0.2988, 3.0762, 2.9579, 3.1165, 3.0758])\n",
      "Next pose: tensor([5.5242, 6.2026, 0.7976, 0.5975, 6.1525, 5.9157, 6.2330, 6.1516])\n",
      "Reward: -19.38920783996582\n",
      "Discounted Reward: -10.933674812316895\n",
      "Current pose: tensor([2.7652, 3.0895, 0.3901, 0.3009, 3.0744, 2.9559, 3.1192, 3.0727])\n",
      "Action: tensor([2.7652, 3.0895, 0.3901, 0.3009, 3.0744, 2.9559, 3.1192, 3.0727])\n",
      "Next pose: tensor([5.5304, 6.1789, 0.7801, 0.6017, 6.1489, 5.9117, 6.2385, 6.1453])\n",
      "Reward: -19.376617431640625\n",
      "Discounted Reward: -10.817310333251953\n",
      "Current pose: tensor([2.6903, 3.1074, 0.3706, 0.3169, 3.1325, 2.9136, 3.1088, 3.0482])\n",
      "Action: tensor([2.6903, 3.1074, 0.3706, 0.3169, 3.1325, 2.9136, 3.1088, 3.0482])\n",
      "Next pose: tensor([5.3807, 6.2148, 0.7412, 0.6339, 6.2650, 5.8273, 6.2177, 6.0964])\n",
      "Reward: -19.231483459472656\n",
      "Discounted Reward: -10.628923416137695\n",
      "Current pose: tensor([2.7458, 3.1259, 0.3398, 0.3126, 3.1390, 2.9070, 3.1065, 3.0376])\n",
      "Action: tensor([2.7458, 3.1259, 0.3398, 0.3126, 3.1390, 2.9070, 3.1065, 3.0376])\n",
      "Next pose: tensor([5.4915, 6.2518, 0.6795, 0.6252, 6.2780, 5.8141, 6.2129, 6.0751])\n",
      "Reward: -19.423381805419922\n",
      "Discounted Reward: -10.627632141113281\n",
      "Current pose: tensor([2.8297, 3.1195, 0.3051, 0.2931, 3.1325, 2.9159, 3.1084, 3.0441])\n",
      "Action: tensor([2.8297, 3.1195, 0.3051, 0.2931, 3.1325, 2.9159, 3.1084, 3.0441])\n",
      "Next pose: tensor([5.6593, 6.2390, 0.6102, 0.5862, 6.2649, 5.8318, 6.2169, 6.0883])\n",
      "Reward: -19.708391189575195\n",
      "Discounted Reward: -10.675742149353027\n",
      "Current pose: tensor([2.8537, 3.0758, 0.3138, 0.2215, 3.1353, 2.9182, 3.1220, 3.0431])\n",
      "Action: tensor([2.8537, 3.0758, 0.3138, 0.2215, 3.1353, 2.9182, 3.1220, 3.0431])\n",
      "Next pose: tensor([5.7075, 6.1516, 0.6276, 0.4430, 6.2707, 5.8364, 6.2439, 6.0862])\n",
      "Reward: -19.83040428161621\n",
      "Discounted Reward: -10.634415626525879\n",
      "Current pose: tensor([2.7915, 3.1065, 0.3408, 0.2065, 3.1363, 2.9284, 3.1089, 3.0415])\n",
      "Action: tensor([2.7915, 3.1065, 0.3408, 0.2065, 3.1363, 2.9284, 3.1089, 3.0415])\n",
      "Next pose: tensor([5.5831, 6.2130, 0.6816, 0.4130, 6.2727, 5.8568, 6.2177, 6.0830])\n",
      "Reward: -19.736303329467773\n",
      "Discounted Reward: -10.478113174438477\n",
      "Current pose: tensor([2.8462, 3.1396, 0.3096, 0.2041, 3.1349, 2.9352, 3.1080, 3.0451])\n",
      "Action: tensor([2.8462, 3.1396, 0.3096, 0.2041, 3.1349, 2.9352, 3.1080, 3.0451])\n",
      "Next pose: tensor([5.6924, 6.2793, 0.6191, 0.4081, 6.2698, 5.8704, 6.2159, 6.0901])\n",
      "Reward: -19.995357513427734\n",
      "Discounted Reward: -10.509490013122559\n",
      "Current pose: tensor([2.9102, 3.1377, 0.2829, 0.1957, 3.1416, 2.9543, 3.1147, 3.0474])\n",
      "Action: tensor([2.9102, 3.1377, 0.2829, 0.1957, 3.1416, 2.9543, 3.1147, 3.0474])\n",
      "Next pose: tensor([5.8203, 6.2753, 0.5658, 0.3915, 6.2832, 5.9085, 6.2295, 6.0949])\n",
      "Reward: -20.259130477905273\n",
      "Discounted Reward: -10.541646003723145\n",
      "Current pose: tensor([2.9475, 3.1207, 0.2711, 0.2110, 3.1395, 2.9669, 3.1004, 3.0457])\n",
      "Action: tensor([2.9475, 3.1207, 0.2711, 0.2110, 3.1395, 2.9669, 3.1004, 3.0457])\n",
      "Next pose: tensor([5.8949, 6.2415, 0.5422, 0.4220, 6.2790, 5.9337, 6.2007, 6.0915])\n",
      "Reward: -20.28187370300293\n",
      "Discounted Reward: -10.447946548461914\n",
      "Current pose: tensor([2.9498, 3.1264, 0.2669, 0.2262, 3.1354, 2.9622, 3.0940, 3.0430])\n",
      "Action: tensor([2.9498, 3.1264, 0.2669, 0.2262, 3.1354, 2.9622, 3.0940, 3.0430])\n",
      "Next pose: tensor([5.8997, 6.2528, 0.5339, 0.4524, 6.2707, 5.9243, 6.1881, 6.0860])\n",
      "Reward: -20.239992141723633\n",
      "Discounted Reward: -10.322107315063477\n",
      "Current pose: tensor([2.9842, 3.0971, 0.2687, 0.2314, 3.1295, 2.9515, 3.1044, 3.0571])\n",
      "Action: tensor([2.9842, 3.0971, 0.2687, 0.2314, 3.1295, 2.9515, 3.1044, 3.0571])\n",
      "Next pose: tensor([5.9684, 6.1943, 0.5374, 0.4627, 6.2589, 5.9030, 6.2087, 6.1142])\n",
      "Reward: -20.25210952758789\n",
      "Discounted Reward: -10.225005149841309\n",
      "Current pose: tensor([2.9832, 3.0912, 0.2805, 0.2360, 3.1236, 2.9489, 3.0999, 3.0531])\n",
      "Action: tensor([2.9832, 3.0912, 0.2805, 0.2360, 3.1236, 2.9489, 3.0999, 3.0531])\n",
      "Next pose: tensor([5.9663, 6.1824, 0.5609, 0.4719, 6.2472, 5.8978, 6.1997, 6.1062])\n",
      "Reward: -20.171533584594727\n",
      "Discounted Reward: -10.082479476928711\n",
      "Current pose: tensor([2.9729, 3.0871, 0.2756, 0.2800, 3.1237, 2.9327, 3.0896, 3.0415])\n",
      "Action: tensor([2.9729, 3.0871, 0.2756, 0.2800, 3.1237, 2.9327, 3.0896, 3.0415])\n",
      "Next pose: tensor([5.9457, 6.1742, 0.5512, 0.5600, 6.2475, 5.8653, 6.1791, 6.0829])\n",
      "Reward: -19.98822593688965\n",
      "Discounted Reward: -9.890946388244629\n",
      "Current pose: tensor([2.9682, 3.1293, 0.2969, 0.3170, 3.1108, 2.9305, 3.1074, 3.0458])\n",
      "Action: tensor([2.9682, 3.1293, 0.2969, 0.3170, 3.1108, 2.9305, 3.1074, 3.0458])\n",
      "Next pose: tensor([5.9365, 6.2586, 0.5937, 0.6340, 6.2216, 5.8611, 6.2148, 6.0916])\n",
      "Reward: -19.9610595703125\n",
      "Discounted Reward: -9.778729438781738\n",
      "Current pose: tensor([2.9418, 3.1072, 0.3120, 0.3158, 3.1149, 2.9291, 3.1062, 3.0547])\n",
      "Action: tensor([2.9418, 3.1072, 0.3120, 0.3158, 3.1149, 2.9291, 3.1062, 3.0547])\n",
      "Next pose: tensor([5.8836, 6.2144, 0.6240, 0.6316, 6.2298, 5.8582, 6.2125, 6.1094])\n",
      "Reward: -19.85688018798828\n",
      "Discounted Reward: -9.630415916442871\n",
      "Current pose: tensor([2.9348, 3.0968, 0.3129, 0.3124, 3.1166, 2.9449, 3.0938, 3.0574])\n",
      "Action: tensor([2.9348, 3.0968, 0.3129, 0.3124, 3.1166, 2.9449, 3.0938, 3.0574])\n",
      "Next pose: tensor([5.8695, 6.1935, 0.6258, 0.6248, 6.2332, 5.8898, 6.1876, 6.1148])\n",
      "Reward: -19.842578887939453\n",
      "Discounted Reward: -9.527244567871094\n",
      "Current pose: tensor([2.9207, 3.0256, 0.3351, 0.3472, 3.1236, 2.9408, 3.0839, 3.0595])\n",
      "Action: tensor([2.9207, 3.0256, 0.3351, 0.3472, 3.1236, 2.9408, 3.0839, 3.0595])\n",
      "Next pose: tensor([5.8414, 6.0512, 0.6703, 0.6945, 6.2472, 5.8815, 6.1677, 6.1191])\n",
      "Reward: -19.548145294189453\n",
      "Discounted Reward: -9.29201602935791\n",
      "Current pose: tensor([2.9393, 3.0242, 0.3315, 0.3672, 3.1291, 2.9370, 3.0889, 3.0592])\n",
      "Action: tensor([2.9393, 3.0242, 0.3315, 0.3672, 3.1291, 2.9370, 3.0889, 3.0592])\n",
      "Next pose: tensor([5.8786, 6.0484, 0.6630, 0.7344, 6.2581, 5.8740, 6.1779, 6.1184])\n",
      "Reward: -19.562734603881836\n",
      "Discounted Reward: -9.205961227416992\n",
      "Current pose: tensor([2.9992, 3.0240, 0.2828, 0.3766, 3.1279, 2.9265, 3.1039, 3.0541])\n",
      "Action: tensor([2.9992, 3.0240, 0.2828, 0.3766, 3.1279, 2.9265, 3.1039, 3.0541])\n",
      "Next pose: tensor([5.9984, 6.0479, 0.5657, 0.7531, 6.2559, 5.8529, 6.2078, 6.1083])\n",
      "Reward: -19.75716209411621\n",
      "Discounted Reward: -9.204482078552246\n",
      "Current pose: tensor([2.9278, 2.7248, 0.2947, 0.4105, 3.1085, 2.9530, 3.1199, 3.0404])\n",
      "Action: tensor([2.9278, 2.7248, 0.2947, 0.4105, 3.1085, 2.9530, 3.1199, 3.0404])\n",
      "Next pose: tensor([5.8557, 5.4496, 0.5893, 0.8211, 6.2170, 5.9061, 6.2399, 6.0807])\n",
      "Reward: -18.943262100219727\n",
      "Discounted Reward: -8.737048149108887\n",
      "Current pose: tensor([2.9007, 2.8242, 0.3141, 0.3666, 3.1173, 2.9604, 3.1232, 3.0485])\n",
      "Action: tensor([2.9007, 2.8242, 0.3141, 0.3666, 3.1173, 2.9604, 3.1232, 3.0485])\n",
      "Next pose: tensor([5.8014, 5.6484, 0.6282, 0.7331, 6.2345, 5.9208, 6.2463, 6.0970])\n",
      "Reward: -19.191768646240234\n",
      "Discounted Reward: -8.76314926147461\n",
      "Current pose: tensor([2.9130, 2.8527, 0.3140, 0.3554, 3.1193, 2.9632, 3.1216, 3.0495])\n",
      "Action: tensor([2.9130, 2.8527, 0.3140, 0.3554, 3.1193, 2.9632, 3.1216, 3.0495])\n",
      "Next pose: tensor([5.8260, 5.7054, 0.6280, 0.7108, 6.2385, 5.9264, 6.2432, 6.0991])\n",
      "Reward: -19.30446434020996\n",
      "Discounted Reward: -8.726460456848145\n",
      "Current pose: tensor([2.9237, 2.9922, 0.3262, 0.3291, 3.1243, 2.9478, 3.1242, 3.0361])\n",
      "Action: tensor([2.9237, 2.9922, 0.3262, 0.3291, 3.1243, 2.9478, 3.1242, 3.0361])\n",
      "Next pose: tensor([5.8475, 5.9844, 0.6524, 0.6582, 6.2485, 5.8956, 6.2484, 6.0723])\n",
      "Reward: -19.5908145904541\n",
      "Discounted Reward: -8.76734447479248\n",
      "Current pose: tensor([2.9535, 2.9834, 0.3172, 0.3139, 3.1204, 2.9389, 3.1177, 3.0340])\n",
      "Action: tensor([2.9535, 2.9834, 0.3172, 0.3139, 3.1204, 2.9389, 3.1177, 3.0340])\n",
      "Next pose: tensor([5.9070, 5.9669, 0.6343, 0.6277, 6.2409, 5.8779, 6.2354, 6.0680])\n",
      "Reward: -19.638643264770508\n",
      "Discounted Reward: -8.700860977172852\n",
      "Current pose: tensor([2.9693, 3.0445, 0.3115, 0.3069, 3.1198, 2.9318, 3.1171, 3.0344])\n",
      "Action: tensor([2.9693, 3.0445, 0.3115, 0.3069, 3.1198, 2.9318, 3.1171, 3.0344])\n",
      "Next pose: tensor([5.9386, 6.0891, 0.6230, 0.6137, 6.2396, 5.8637, 6.2342, 6.0688])\n",
      "Reward: -19.802030563354492\n",
      "Discounted Reward: -8.685517311096191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pose: tensor([2.9231, 2.8984, 0.3550, 0.2931, 3.0926, 2.9441, 3.1376, 3.0369])\n",
      "Action: tensor([2.9231, 2.8984, 0.3550, 0.2931, 3.0926, 2.9441, 3.1376, 3.0369])\n",
      "Next pose: tensor([5.8462, 5.7967, 0.7099, 0.5863, 6.1851, 5.8882, 6.2751, 6.0737])\n",
      "Reward: -19.373661041259766\n",
      "Discounted Reward: -8.412651062011719\n",
      "Current pose: tensor([2.8170, 3.0011, 0.4295, 0.2718, 3.1045, 2.9546, 3.1288, 3.0490])\n",
      "Action: tensor([2.8170, 3.0011, 0.4295, 0.2718, 3.1045, 2.9546, 3.1288, 3.0490])\n",
      "Next pose: tensor([5.6339, 6.0022, 0.8589, 0.5435, 6.2090, 5.9092, 6.2576, 6.0981])\n",
      "Reward: -19.312299728393555\n",
      "Discounted Reward: -8.302145957946777\n",
      "Current pose: tensor([2.7723, 3.0303, 0.4462, 0.2703, 3.1085, 2.9558, 3.1169, 3.0487])\n",
      "Action: tensor([2.7723, 3.0303, 0.4462, 0.2703, 3.1085, 2.9558, 3.1169, 3.0487])\n",
      "Next pose: tensor([5.5446, 6.0606, 0.8924, 0.5407, 6.2171, 5.9116, 6.2337, 6.0974])\n",
      "Reward: -19.236637115478516\n",
      "Discounted Reward: -8.186923027038574\n",
      "Current pose: tensor([2.6735, 1.1404, 0.5697, 2.5584, 3.1014, 2.9707, 3.1218, 3.0712])\n",
      "Action: tensor([2.6735, 1.1404, 0.5697, 2.5584, 3.1014, 2.9707, 3.1218, 3.0712])\n",
      "Next pose: tensor([5.3469, 2.2809, 1.1395, 5.1168, 6.2028, 5.9413, 6.2437, 6.1423])\n",
      "Reward: -19.17104721069336\n",
      "Discounted Reward: -8.077418327331543\n",
      "Current pose: tensor([2.7567, 0.5971, 0.5349, 0.9402, 3.0787, 3.0004, 3.1398, 3.0995])\n",
      "Action: tensor([2.7567, 0.5971, 0.5349, 0.9402, 3.0787, 3.0004, 3.1398, 3.0995])\n",
      "Next pose: tensor([5.5134, 1.1941, 1.0697, 1.8804, 6.1574, 6.0009, 6.2796, 6.1991])\n",
      "Reward: -17.364349365234375\n",
      "Discounted Reward: -7.243032455444336\n",
      "Current pose: tensor([2.7187, 2.6913, 0.4237, 0.3242, 3.0832, 3.0052, 3.1294, 3.1019])\n",
      "Action: tensor([2.7187, 2.6913, 0.4237, 0.3242, 3.0832, 3.0052, 3.1294, 3.1019])\n",
      "Next pose: tensor([5.4375, 5.3826, 0.8475, 0.6483, 6.1665, 6.0103, 6.2588, 6.2039])\n",
      "Reward: -18.568273544311523\n",
      "Discounted Reward: -7.667762756347656\n",
      "Current pose: tensor([2.8434, 2.3454, 0.3887, 0.2991, 3.0889, 2.9772, 3.1184, 3.0677])\n",
      "Action: tensor([2.8434, 2.3454, 0.3887, 0.2991, 3.0889, 2.9772, 3.1184, 3.0677])\n",
      "Next pose: tensor([5.6868, 4.6907, 0.7773, 0.5983, 6.1778, 5.9544, 6.2368, 6.1354])\n",
      "Reward: -18.111072540283203\n",
      "Discounted Reward: -7.404171943664551\n",
      "Current pose: tensor([2.9962, 2.2976, 0.3307, 0.2649, 3.0960, 2.9698, 3.1059, 3.0493])\n",
      "Action: tensor([2.9962, 2.2976, 0.3307, 0.2649, 3.0960, 2.9698, 3.1059, 3.0493])\n",
      "Next pose: tensor([5.9924, 4.5953, 0.6614, 0.5298, 6.1920, 5.9396, 6.2117, 6.0986])\n",
      "Reward: -18.44320297241211\n",
      "Discounted Reward: -7.4645538330078125\n",
      "Current pose: tensor([2.9067, 1.5374, 0.3264, 1.9619, 3.0917, 2.9872, 3.1263, 3.0609])\n",
      "Action: tensor([2.9067, 1.5374, 0.3264, 1.9619, 3.0917, 2.9872, 3.1263, 3.0609])\n",
      "Next pose: tensor([5.8135, 3.0748, 0.6527, 3.9237, 6.1834, 5.9744, 6.2525, 6.1217])\n",
      "Reward: -18.36394500732422\n",
      "Discounted Reward: -7.358150959014893\n",
      "Current pose: tensor([2.9063, 0.3606, 0.3016, 1.5420, 3.0819, 2.9889, 3.1324, 3.0687])\n",
      "Action: tensor([2.9063, 0.3606, 0.3016, 1.5420, 3.0819, 2.9889, 3.1324, 3.0687])\n",
      "Next pose: tensor([5.8127, 0.7212, 0.6033, 3.0840, 6.1638, 5.9778, 6.2648, 6.1374])\n",
      "Reward: -19.713550567626953\n",
      "Discounted Reward: -7.81992769241333\n",
      "Current pose: tensor([2.9202, 0.8094, 0.2922, 0.4258, 3.1096, 2.9881, 3.1200, 3.0754])\n",
      "Action: tensor([2.9202, 0.8094, 0.2922, 0.4258, 3.1096, 2.9881, 3.1200, 3.0754])\n",
      "Next pose: tensor([5.8405, 1.6189, 0.5844, 0.8516, 6.2191, 5.9763, 6.2401, 6.1508])\n",
      "Reward: -17.9014835357666\n",
      "Discounted Reward: -7.030109882354736\n",
      "Current pose: tensor([2.9011, 2.5881, 0.3019, 0.2810, 3.1187, 2.9918, 3.1104, 3.0758])\n",
      "Action: tensor([2.9011, 2.5881, 0.3019, 0.2810, 3.1187, 2.9918, 3.1104, 3.0758])\n",
      "Next pose: tensor([5.8021, 5.1763, 0.6038, 0.5620, 6.2375, 5.9836, 6.2208, 6.1515])\n",
      "Reward: -19.010711669921875\n",
      "Discounted Reward: -7.391059398651123\n",
      "Current pose: tensor([2.2125, 1.3885, 0.2868, 0.3142, 3.1252, 2.9821, 3.1120, 3.0669])\n",
      "Action: tensor([2.2125, 1.3885, 0.2868, 0.3142, 3.1252, 2.9821, 3.1120, 3.0669])\n",
      "Next pose: tensor([4.4250, 2.7771, 0.5737, 0.6284, 6.2503, 5.9643, 6.2240, 6.1337])\n",
      "Reward: -15.547765731811523\n",
      "Discounted Reward: -5.984273910522461\n",
      "Current pose: tensor([2.8336, 2.8689, 0.2538, 0.2472, 3.1283, 2.9548, 3.0988, 3.0563])\n",
      "Action: tensor([2.8336, 2.8689, 0.2538, 0.2472, 3.1283, 2.9548, 3.0988, 3.0563])\n",
      "Next pose: tensor([5.6673, 5.7378, 0.5076, 0.4945, 6.2566, 5.9096, 6.1977, 6.1125])\n",
      "Reward: -19.484134674072266\n",
      "Discounted Reward: -7.424373626708984\n",
      "Current pose: tensor([2.9115, 3.0095, 0.2693, 0.2252, 3.1102, 2.9554, 3.1010, 3.0462])\n",
      "Action: tensor([2.9115, 3.0095, 0.2693, 0.2252, 3.1102, 2.9554, 3.1010, 3.0462])\n",
      "Next pose: tensor([5.8229, 6.0189, 0.5386, 0.4504, 6.2203, 5.9108, 6.2021, 6.0923])\n",
      "Reward: -19.883071899414062\n",
      "Discounted Reward: -7.5006232261657715\n",
      "Current pose: tensor([2.9549, 3.0402, 0.2528, 0.2084, 3.1221, 2.9444, 3.1062, 3.0667])\n",
      "Action: tensor([2.9549, 3.0402, 0.2528, 0.2084, 3.1221, 2.9444, 3.1062, 3.0667])\n",
      "Next pose: tensor([5.9097, 6.0804, 0.5056, 0.4168, 6.2443, 5.8888, 6.2123, 6.1333])\n",
      "Reward: -20.151153564453125\n",
      "Discounted Reward: -7.525736331939697\n",
      "Current pose: tensor([3.0158, 3.0258, 0.2458, 0.2169, 3.1028, 2.9590, 3.0922, 3.0610])\n",
      "Action: tensor([3.0158, 3.0258, 0.2458, 0.2169, 3.1028, 2.9590, 3.0922, 3.0610])\n",
      "Next pose: tensor([6.0317, 6.0515, 0.4915, 0.4337, 6.2056, 5.9180, 6.1843, 6.1220])\n",
      "Reward: -20.19257926940918\n",
      "Discounted Reward: -7.465795040130615\n",
      "Current pose: tensor([2.9836, 2.9903, 0.2586, 0.2235, 3.1219, 2.9527, 3.0637, 3.0464])\n",
      "Action: tensor([2.9836, 2.9903, 0.2586, 0.2235, 3.1219, 2.9527, 3.0637, 3.0464])\n",
      "Next pose: tensor([5.9672, 5.9806, 0.5172, 0.4471, 6.2439, 5.9054, 6.1274, 6.0928])\n",
      "Reward: -19.957630157470703\n",
      "Discounted Reward: -7.305138111114502\n",
      "Current pose: tensor([2.9223, 3.0957, 0.2432, 0.1840, 3.1329, 2.9631, 3.0464, 3.0194])\n",
      "Action: tensor([2.9223, 3.0957, 0.2432, 0.1840, 3.1329, 2.9631, 3.0464, 3.0194])\n",
      "Next pose: tensor([5.8445, 6.1914, 0.4864, 0.3680, 6.2659, 5.9262, 6.0928, 6.0387])\n",
      "Reward: -20.109844207763672\n",
      "Discounted Reward: -7.28724479675293\n",
      "Current pose: tensor([2.9349, 3.1196, 0.2473, 0.1894, 3.1182, 2.9638, 3.0254, 2.9934])\n",
      "Action: tensor([2.9349, 3.1196, 0.2473, 0.1894, 3.1182, 2.9638, 3.0254, 2.9934])\n",
      "Next pose: tensor([5.8697, 6.2392, 0.4947, 0.3789, 6.2365, 5.9277, 6.0509, 5.9868])\n",
      "Reward: -20.041854858398438\n",
      "Discounted Reward: -7.189980983734131\n",
      "Current pose: tensor([2.8743, 3.1314, 0.2523, 0.1785, 3.1011, 3.0059, 3.0428, 3.0338])\n",
      "Action: tensor([2.8743, 3.1314, 0.2523, 0.1785, 3.1011, 3.0059, 3.0428, 3.0338])\n",
      "Next pose: tensor([5.7485, 6.2628, 0.5046, 0.3571, 6.2021, 6.0117, 6.0856, 6.0676])\n",
      "Reward: -20.121423721313477\n",
      "Discounted Reward: -7.146340847015381\n",
      "Current pose: tensor([2.8588, 3.1215, 0.2559, 0.1921, 3.0828, 3.0260, 3.0520, 3.0676])\n",
      "Action: tensor([2.8588, 3.1215, 0.2559, 0.1921, 3.0828, 3.0260, 3.0520, 3.0676])\n",
      "Next pose: tensor([5.7176, 6.2429, 0.5119, 0.3843, 6.1655, 6.0519, 6.1040, 6.1353])\n",
      "Reward: -20.125810623168945\n",
      "Discounted Reward: -7.076420307159424\n",
      "Current pose: tensor([2.8759, 3.1078, 0.2499, 0.2041, 3.0752, 3.0350, 3.0660, 3.0863])\n",
      "Action: tensor([2.8759, 3.1078, 0.2499, 0.2041, 3.0752, 3.0350, 3.0660, 3.0863])\n",
      "Next pose: tensor([5.7518, 6.2156, 0.4999, 0.4082, 6.1505, 6.0700, 6.1319, 6.1726])\n",
      "Reward: -20.188976287841797\n",
      "Discounted Reward: -7.02764368057251\n",
      "Current pose: tensor([2.8254, 3.0747, 0.2341, 0.1948, 3.0471, 3.0024, 3.0894, 3.0224])\n",
      "Action: tensor([2.8254, 3.0747, 0.2341, 0.1948, 3.0471, 3.0024, 3.0894, 3.0224])\n",
      "Next pose: tensor([5.6507, 6.1495, 0.4682, 0.3897, 6.0941, 6.0048, 6.1789, 6.0447])\n",
      "Reward: -19.869617462158203\n",
      "Discounted Reward: -6.8473124504089355\n",
      "Current pose: tensor([2.7287, 3.0350, 0.2465, 0.2105, 3.0504, 2.9987, 3.1029, 3.0091])\n",
      "Action: tensor([2.7287, 3.0350, 0.2465, 0.2105, 3.0504, 2.9987, 3.1029, 3.0091])\n",
      "Next pose: tensor([5.4573, 6.0700, 0.4930, 0.4211, 6.1009, 5.9973, 6.2058, 6.0181])\n",
      "Reward: -19.5401611328125\n",
      "Discounted Reward: -6.666439533233643\n",
      "Current pose: tensor([1.7798, 2.9498, 0.3078, 0.2341, 3.0384, 3.0201, 3.1071, 3.0445])\n",
      "Action: tensor([1.7798, 2.9498, 0.3078, 0.2341, 3.0384, 3.0201, 3.1071, 3.0445])\n",
      "Next pose: tensor([3.5596, 5.8996, 0.6155, 0.4683, 6.0768, 6.0402, 6.2143, 6.0891])\n",
      "Reward: -17.40054702758789\n",
      "Discounted Reward: -5.877111434936523\n",
      "Current pose: tensor([1.5412, 2.9154, 0.3253, 0.2454, 3.0297, 3.0143, 3.1032, 3.0297])\n",
      "Action: tensor([1.5412, 2.9154, 0.3253, 0.2454, 3.0297, 3.0143, 3.1032, 3.0297])\n",
      "Next pose: tensor([3.0824, 5.8307, 0.6505, 0.4907, 6.0595, 6.0286, 6.2064, 6.0593])\n",
      "Reward: -16.844085693359375\n",
      "Discounted Reward: -5.632272720336914\n",
      "Current pose: tensor([1.6987, 2.8365, 0.3292, 0.2653, 3.0530, 3.0099, 3.0939, 3.0142])\n",
      "Action: tensor([1.6987, 2.8365, 0.3292, 0.2653, 3.0530, 3.0099, 3.0939, 3.0142])\n",
      "Next pose: tensor([3.3973, 5.6730, 0.6585, 0.5307, 6.1061, 6.0199, 6.1878, 6.0283])\n",
      "Reward: -16.82794952392578\n",
      "Discounted Reward: -5.570608139038086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pose: tensor([1.4496, 2.7777, 0.3453, 0.2741, 3.0565, 3.0492, 3.0836, 3.0597])\n",
      "Action: tensor([1.4496, 2.7777, 0.3453, 0.2741, 3.0565, 3.0492, 3.0836, 3.0597])\n",
      "Next pose: tensor([2.8993, 5.5553, 0.6907, 0.5482, 6.1130, 6.0983, 6.1672, 6.1195])\n",
      "Reward: -16.79839324951172\n",
      "Discounted Reward: -5.505215644836426\n",
      "Current pose: tensor([1.7451, 2.7294, 0.3264, 0.2343, 3.0565, 3.0595, 3.0831, 3.0348])\n",
      "Action: tensor([1.7451, 2.7294, 0.3264, 0.2343, 3.0565, 3.0595, 3.0831, 3.0348])\n",
      "Next pose: tensor([3.4903, 5.4587, 0.6528, 0.4686, 6.1131, 6.1190, 6.1661, 6.0695])\n",
      "Reward: -16.900007247924805\n",
      "Discounted Reward: -5.483131408691406\n",
      "Current pose: tensor([1.7833, 2.8614, 0.3105, 0.2258, 3.0535, 3.0572, 3.0865, 3.0601])\n",
      "Action: tensor([1.7833, 2.8614, 0.3105, 0.2258, 3.0535, 3.0572, 3.0865, 3.0601])\n",
      "Next pose: tensor([3.5666, 5.7229, 0.6209, 0.4516, 6.1071, 6.1145, 6.1730, 6.1203])\n",
      "Reward: -17.336477279663086\n",
      "Discounted Reward: -5.568495273590088\n",
      "Current pose: tensor([2.3770, 2.9305, 0.3055, 0.2327, 3.0333, 3.0792, 3.1124, 3.0768])\n",
      "Action: tensor([2.3770, 2.9305, 0.3055, 0.2327, 3.0333, 3.0792, 3.1124, 3.0768])\n",
      "Next pose: tensor([4.7540, 5.8609, 0.6110, 0.4654, 6.0666, 6.1583, 6.2248, 6.1536])\n",
      "Reward: -18.746450424194336\n",
      "Discounted Reward: -5.961165904998779\n",
      "Current pose: tensor([2.7046, 2.9229, 0.3045, 0.2492, 3.0336, 3.0528, 3.1211, 3.0636])\n",
      "Action: tensor([2.7046, 2.9229, 0.3045, 0.2492, 3.0336, 3.0528, 3.1211, 3.0636])\n",
      "Next pose: tensor([5.4093, 5.8458, 0.6089, 0.4984, 6.0672, 6.1056, 6.2423, 6.1272])\n",
      "Reward: -19.294780731201172\n",
      "Discounted Reward: -6.074173927307129\n",
      "Current pose: tensor([2.7761, 2.9245, 0.2992, 0.2568, 3.0386, 3.0465, 3.1264, 3.0655])\n",
      "Action: tensor([2.7761, 2.9245, 0.2992, 0.2568, 3.0386, 3.0465, 3.1264, 3.0655])\n",
      "Next pose: tensor([5.5522, 5.8489, 0.5985, 0.5136, 6.0773, 6.0931, 6.2528, 6.1311])\n",
      "Reward: -19.448015213012695\n",
      "Discounted Reward: -6.061189651489258\n",
      "Current pose: tensor([2.8361, 2.9433, 0.3076, 0.2580, 3.0447, 3.0324, 3.1186, 3.0549])\n",
      "Action: tensor([2.8361, 2.9433, 0.3076, 0.2580, 3.0447, 3.0324, 3.1186, 3.0549])\n",
      "Next pose: tensor([5.6722, 5.8866, 0.6153, 0.5161, 6.0894, 6.0649, 6.2373, 6.1098])\n",
      "Reward: -19.533477783203125\n",
      "Discounted Reward: -6.026946067810059\n",
      "Current pose: tensor([2.9214, 2.9624, 0.2991, 0.2764, 3.0429, 3.0250, 3.1174, 3.0592])\n",
      "Action: tensor([2.9214, 2.9624, 0.2991, 0.2764, 3.0429, 3.0250, 3.1174, 3.0592])\n",
      "Next pose: tensor([5.8429, 5.9248, 0.5981, 0.5528, 6.0859, 6.0499, 6.2348, 6.1183])\n",
      "Reward: -19.710290908813477\n",
      "Discounted Reward: -6.020686149597168\n",
      "Current pose: tensor([2.9945, 3.0239, 0.2807, 0.2853, 3.0387, 3.0304, 3.1146, 3.0694])\n",
      "Action: tensor([2.9945, 3.0239, 0.2807, 0.2853, 3.0387, 3.0304, 3.1146, 3.0694])\n",
      "Next pose: tensor([5.9891, 6.0479, 0.5614, 0.5705, 6.0773, 6.0609, 6.2291, 6.1389])\n",
      "Reward: -20.015979766845703\n",
      "Discounted Reward: -6.052920818328857\n",
      "Current pose: tensor([3.0301, 3.0505, 0.2726, 0.2933, 3.0398, 3.0215, 3.1187, 3.0811])\n",
      "Action: tensor([3.0301, 3.0505, 0.2726, 0.2933, 3.0398, 3.0215, 3.1187, 3.0811])\n",
      "Next pose: tensor([6.0602, 6.1011, 0.5452, 0.5865, 6.0796, 6.0430, 6.2375, 6.1623])\n",
      "Reward: -20.15660858154297\n",
      "Discounted Reward: -6.034493446350098\n",
      "Current pose: tensor([3.0542, 3.0400, 0.2650, 0.2982, 3.0354, 3.0240, 3.1248, 3.0865])\n",
      "Action: tensor([3.0542, 3.0400, 0.2650, 0.2982, 3.0354, 3.0240, 3.1248, 3.0865])\n",
      "Next pose: tensor([6.1084, 6.0799, 0.5300, 0.5965, 6.0707, 6.0479, 6.2496, 6.1730])\n",
      "Reward: -20.207782745361328\n",
      "Discounted Reward: -5.989315986633301\n",
      "Current pose: tensor([3.0642, 3.0309, 0.2620, 0.2984, 3.0386, 3.0293, 3.1192, 3.0956])\n",
      "Action: tensor([3.0642, 3.0309, 0.2620, 0.2984, 3.0386, 3.0293, 3.1192, 3.0956])\n",
      "Next pose: tensor([6.1285, 6.0619, 0.5240, 0.5969, 6.0772, 6.0586, 6.2383, 6.1911])\n",
      "Reward: -20.23938751220703\n",
      "Discounted Reward: -5.938696384429932\n",
      "Current pose: tensor([3.0655, 3.0433, 0.2738, 0.2927, 3.0104, 3.0304, 3.0880, 3.1336])\n",
      "Action: tensor([3.0655, 3.0433, 0.2738, 0.2927, 3.0104, 3.0304, 3.0880, 3.1336])\n",
      "Next pose: tensor([6.1309, 6.0866, 0.5476, 0.5854, 6.0208, 6.0609, 6.1760, 6.2671])\n",
      "Reward: -20.2139949798584\n",
      "Discounted Reward: -5.871932506561279\n",
      "Current pose: tensor([3.0599, 3.0280, 0.2869, 0.2992, 2.9876, 3.0332, 3.0637, 3.1223])\n",
      "Action: tensor([3.0599, 3.0280, 0.2869, 0.2992, 2.9876, 3.0332, 3.0637, 3.1223])\n",
      "Next pose: tensor([6.1199, 6.0560, 0.5739, 0.5983, 5.9752, 6.0664, 6.1275, 6.2445])\n",
      "Reward: -20.022064208984375\n",
      "Discounted Reward: -5.758017539978027\n",
      "Current pose: tensor([3.0916, 3.0293, 0.2729, 0.3034, 2.9846, 3.0326, 3.0695, 3.1216])\n",
      "Action: tensor([3.0916, 3.0293, 0.2729, 0.3034, 2.9846, 3.0326, 3.0695, 3.1216])\n",
      "Next pose: tensor([6.1832, 6.0586, 0.5459, 0.6067, 5.9692, 6.0652, 6.1390, 6.2432])\n",
      "Reward: -20.110530853271484\n",
      "Discounted Reward: -5.7256245613098145\n",
      "Current pose: tensor([3.1176, 2.9744, 0.2674, 0.3240, 2.9918, 3.0333, 3.0586, 3.1274])\n",
      "Action: tensor([3.1176, 2.9744, 0.2674, 0.3240, 2.9918, 3.0333, 3.0586, 3.1274])\n",
      "Next pose: tensor([6.2352, 5.9488, 0.5349, 0.6480, 5.9836, 6.0666, 6.1171, 6.2548])\n",
      "Reward: -20.027856826782227\n",
      "Discounted Reward: -5.645065784454346\n",
      "Current pose: tensor([3.1256, 2.9460, 0.2648, 0.3308, 3.0006, 3.0251, 3.0644, 3.1233])\n",
      "Action: tensor([3.1256, 2.9460, 0.2648, 0.3308, 3.0006, 3.0251, 3.0644, 3.1233])\n",
      "Next pose: tensor([6.2511, 5.8921, 0.5295, 0.6616, 6.0013, 6.0502, 6.1288, 6.2466])\n",
      "Reward: -19.98357391357422\n",
      "Discounted Reward: -5.576258182525635\n",
      "Current pose: tensor([3.1033, 2.9303, 0.2524, 0.3372, 3.0221, 3.0092, 3.1124, 3.1232])\n",
      "Action: tensor([3.1033, 2.9303, 0.2524, 0.3372, 3.0221, 3.0092, 3.1124, 3.1232])\n",
      "Next pose: tensor([6.2067, 5.8606, 0.5049, 0.6745, 6.0442, 6.0184, 6.2249, 6.2463])\n",
      "Reward: -20.026342391967773\n",
      "Discounted Reward: -5.532310485839844\n",
      "Current pose: tensor([3.0559, 2.9245, 0.2588, 0.3396, 3.0444, 2.9960, 3.1348, 3.1187])\n",
      "Action: tensor([3.0559, 2.9245, 0.2588, 0.3396, 3.0444, 2.9960, 3.1348, 3.1187])\n",
      "Next pose: tensor([6.1118, 5.8491, 0.5177, 0.6792, 6.0887, 5.9920, 6.2696, 6.2374])\n",
      "Reward: -19.95648193359375\n",
      "Discounted Reward: -5.457881450653076\n",
      "Current pose: tensor([3.0276, 2.9507, 0.2648, 0.3218, 3.0385, 3.0074, 3.1314, 3.1315])\n",
      "Action: tensor([3.0276, 2.9507, 0.2648, 0.3218, 3.0385, 3.0074, 3.1314, 3.1315])\n",
      "Next pose: tensor([6.0553, 5.9014, 0.5295, 0.6437, 6.0771, 6.0147, 6.2628, 6.2630])\n",
      "Reward: -20.005844116210938\n",
      "Discounted Reward: -5.416667461395264\n",
      "Current pose: tensor([3.0278, 2.9596, 0.2549, 0.3124, 3.0515, 3.0053, 3.1326, 3.1381])\n",
      "Action: tensor([3.0278, 2.9596, 0.2549, 0.3124, 3.0515, 3.0053, 3.1326, 3.1381])\n",
      "Next pose: tensor([6.0556, 5.9192, 0.5099, 0.6249, 6.1031, 6.0106, 6.2652, 6.2761])\n",
      "Reward: -20.09974479675293\n",
      "Discounted Reward: -5.387670516967773\n",
      "Current pose: tensor([3.0515, 2.9500, 0.2446, 0.3146, 3.0491, 3.0150, 3.1276, 3.1385])\n",
      "Action: tensor([3.0515, 2.9500, 0.2446, 0.3146, 3.0491, 3.0150, 3.1276, 3.1385])\n",
      "Next pose: tensor([6.1030, 5.9000, 0.4891, 0.6291, 6.0983, 6.0301, 6.2551, 6.2770])\n",
      "Reward: -20.14996337890625\n",
      "Discounted Reward: -5.34712028503418\n",
      "Current pose: tensor([3.0746, 2.9757, 0.2280, 0.2953, 3.0577, 3.0177, 3.1308, 3.1337])\n",
      "Action: tensor([3.0746, 2.9757, 0.2280, 0.2953, 3.0577, 3.0177, 3.1308, 3.1337])\n",
      "Next pose: tensor([6.1492, 5.9515, 0.4560, 0.5906, 6.1154, 6.0354, 6.2616, 6.2674])\n",
      "Reward: -20.33864402770996\n",
      "Discounted Reward: -5.343217849731445\n",
      "Current pose: tensor([3.0387, 2.9420, 0.2394, 0.3085, 3.0510, 3.0215, 3.1412, 3.1362])\n",
      "Action: tensor([3.0387, 2.9420, 0.2394, 0.3085, 3.0510, 3.0215, 3.1412, 3.1362])\n",
      "Next pose: tensor([6.0774, 5.8841, 0.4789, 0.6170, 6.1020, 6.0430, 6.2825, 6.2725])\n",
      "Reward: -20.170211791992188\n",
      "Discounted Reward: -5.245978832244873\n",
      "Current pose: tensor([3.0114, 2.9604, 0.2538, 0.2885, 3.0477, 3.0405, 3.1373, 3.1231])\n",
      "Action: tensor([3.0114, 2.9604, 0.2538, 0.2885, 3.0477, 3.0405, 3.1373, 3.1231])\n",
      "Next pose: tensor([6.0228, 5.9208, 0.5077, 0.5769, 6.0953, 6.0811, 6.2746, 6.2463])\n",
      "Reward: -20.16092300415039\n",
      "Discounted Reward: -5.191127300262451\n",
      "Current pose: tensor([3.0300, 2.9247, 0.2353, 0.3095, 3.0415, 3.0366, 3.1265, 3.1118])\n",
      "Action: tensor([3.0300, 2.9247, 0.2353, 0.3095, 3.0415, 3.0366, 3.1265, 3.1118])\n",
      "Next pose: tensor([6.0600, 5.8494, 0.4706, 0.6189, 6.0831, 6.0732, 6.2531, 6.2237])\n",
      "Reward: -20.057619094848633\n",
      "Discounted Reward: -5.112882614135742\n",
      "Current pose: tensor([3.0163, 2.9368, 0.2375, 0.2938, 3.0383, 3.0412, 3.1164, 3.0919])\n",
      "Action: tensor([3.0163, 2.9368, 0.2375, 0.2938, 3.0383, 3.0412, 3.1164, 3.0919])\n",
      "Next pose: tensor([6.0326, 5.8737, 0.4751, 0.5876, 6.0765, 6.0824, 6.2328, 6.1837])\n",
      "Reward: -20.02364158630371\n",
      "Discounted Reward: -5.053179740905762\n",
      "Current pose: tensor([3.0214, 2.9411, 0.2195, 0.2885, 3.0316, 3.0434, 3.1331, 3.0468])\n",
      "Action: tensor([3.0214, 2.9411, 0.2195, 0.2885, 3.0316, 3.0434, 3.1331, 3.0468])\n",
      "Next pose: tensor([6.0429, 5.8823, 0.4390, 0.5771, 6.0632, 6.0867, 6.2662, 6.0936])\n",
      "Reward: -20.023496627807617\n",
      "Discounted Reward: -5.0026116371154785\n",
      "Current pose: tensor([3.0486, 2.9353, 0.2070, 0.2955, 3.0283, 3.0450, 3.1412, 3.0500])\n",
      "Action: tensor([3.0486, 2.9353, 0.2070, 0.2955, 3.0283, 3.0450, 3.1412, 3.0500])\n",
      "Next pose: tensor([6.0973, 5.8705, 0.4140, 0.5909, 6.0566, 6.0901, 6.2825, 6.1000])\n",
      "Reward: -20.09668731689453\n",
      "Discounted Reward: -4.970688343048096\n",
      "Current pose: tensor([3.0637, 2.9608, 0.2107, 0.2959, 3.0196, 3.0570, 3.1297, 3.0481])\n",
      "Action: tensor([3.0637, 2.9608, 0.2107, 0.2959, 3.0196, 3.0570, 3.1297, 3.0481])\n",
      "Next pose: tensor([6.1274, 5.9215, 0.4215, 0.5918, 6.0392, 6.1141, 6.2595, 6.0962])\n",
      "Reward: -20.149272918701172\n",
      "Discounted Reward: -4.9338579177856445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pose: tensor([3.0704, 2.9565, 0.2129, 0.2968, 3.0167, 3.0636, 3.1107, 3.0536])\n",
      "Action: tensor([3.0704, 2.9565, 0.2129, 0.2968, 3.0167, 3.0636, 3.1107, 3.0536])\n",
      "Next pose: tensor([6.1409, 5.9131, 0.4258, 0.5937, 6.0334, 6.1271, 6.2213, 6.1072])\n",
      "Reward: -20.12820053100586\n",
      "Discounted Reward: -4.879410743713379\n",
      "Current pose: tensor([3.0767, 2.9585, 0.2134, 0.2983, 3.0184, 3.0669, 3.1054, 3.0584])\n",
      "Action: tensor([3.0767, 2.9585, 0.2134, 0.2983, 3.0184, 3.0669, 3.1054, 3.0584])\n",
      "Next pose: tensor([6.1533, 5.9170, 0.4268, 0.5966, 6.0369, 6.1338, 6.2108, 6.1168])\n",
      "Reward: -20.149944305419922\n",
      "Discounted Reward: -4.835834980010986\n",
      "Current pose: tensor([3.0695, 2.9550, 0.2174, 0.3044, 3.0255, 3.0660, 3.1260, 3.0746])\n",
      "Action: tensor([3.0695, 2.9550, 0.2174, 0.3044, 3.0255, 3.0660, 3.1260, 3.0746])\n",
      "Next pose: tensor([6.1390, 5.9101, 0.4348, 0.6089, 6.0510, 6.1320, 6.2520, 6.1492])\n",
      "Reward: -20.194351196289062\n",
      "Discounted Reward: -4.798027515411377\n",
      "Current pose: tensor([3.0735, 2.9631, 0.2159, 0.3041, 3.0297, 3.0652, 3.1294, 3.0867])\n",
      "Action: tensor([3.0735, 2.9631, 0.2159, 0.3041, 3.0297, 3.0652, 3.1294, 3.0867])\n",
      "Next pose: tensor([6.1469, 5.9262, 0.4317, 0.6082, 6.0594, 6.1305, 6.2588, 6.1734])\n",
      "Reward: -20.260013580322266\n",
      "Discounted Reward: -4.765491962432861\n",
      "Current pose: tensor([3.0511, 2.9567, 0.2252, 0.3077, 3.0346, 3.0639, 3.1226, 3.0864])\n",
      "Action: tensor([3.0511, 2.9567, 0.2252, 0.3077, 3.0346, 3.0639, 3.1226, 3.0864])\n",
      "Next pose: tensor([6.1021, 5.9135, 0.4505, 0.6153, 6.0692, 6.1278, 6.2451, 6.1728])\n",
      "Reward: -20.169414520263672\n",
      "Discounted Reward: -4.69674015045166\n",
      "Current pose: tensor([3.0326, 2.9778, 0.2310, 0.2978, 3.0341, 3.0662, 3.1153, 3.0691])\n",
      "Action: tensor([3.0326, 2.9778, 0.2310, 0.2978, 3.0341, 3.0662, 3.1153, 3.0691])\n",
      "Next pose: tensor([6.0651, 5.9556, 0.4620, 0.5956, 6.0682, 6.1324, 6.2305, 6.1382])\n",
      "Reward: -20.137163162231445\n",
      "Discounted Reward: -4.642337322235107\n",
      "Current pose: tensor([3.0168, 2.9634, 0.2363, 0.3122, 3.0411, 3.0598, 3.1226, 3.0720])\n",
      "Action: tensor([3.0168, 2.9634, 0.2363, 0.3122, 3.0411, 3.0598, 3.1226, 3.0720])\n",
      "Next pose: tensor([6.0336, 5.9267, 0.4726, 0.6244, 6.0821, 6.1197, 6.2451, 6.1440])\n",
      "Reward: -20.05905532836914\n",
      "Discounted Reward: -4.578087329864502\n",
      "Current pose: tensor([3.0158, 2.9520, 0.2390, 0.3208, 3.0480, 3.0637, 3.1329, 3.0635])\n",
      "Action: tensor([3.0158, 2.9520, 0.2390, 0.3208, 3.0480, 3.0637, 3.1329, 3.0635])\n",
      "Next pose: tensor([6.0316, 5.9040, 0.4780, 0.6416, 6.0959, 6.1275, 6.2657, 6.1269])\n",
      "Reward: -20.036727905273438\n",
      "Discounted Reward: -4.527261734008789\n",
      "Current pose: tensor([3.0220, 2.9183, 0.2393, 0.3420, 3.0524, 3.0666, 3.1361, 3.0407])\n",
      "Action: tensor([3.0220, 2.9183, 0.2393, 0.3420, 3.0524, 3.0666, 3.1361, 3.0407])\n",
      "Next pose: tensor([6.0440, 5.8366, 0.4786, 0.6841, 6.1048, 6.1331, 6.2722, 6.0814])\n",
      "Reward: -19.91413116455078\n",
      "Discounted Reward: -4.454565525054932\n",
      "Current pose: tensor([3.0062, 2.9217, 0.2489, 0.3403, 3.0533, 3.0579, 3.1248, 3.0474])\n",
      "Action: tensor([3.0062, 2.9217, 0.2489, 0.3403, 3.0533, 3.0579, 3.1248, 3.0474])\n",
      "Next pose: tensor([6.0124, 5.8433, 0.4978, 0.6805, 6.1067, 6.1159, 6.2496, 6.0947])\n",
      "Reward: -19.8489933013916\n",
      "Discounted Reward: -4.395595073699951\n",
      "Current pose: tensor([3.0076, 2.9314, 0.2462, 0.3337, 3.0554, 3.0497, 3.1235, 3.0619])\n",
      "Action: tensor([3.0076, 2.9314, 0.2462, 0.3337, 3.0554, 3.0497, 3.1235, 3.0619])\n",
      "Next pose: tensor([6.0153, 5.8629, 0.4924, 0.6675, 6.1108, 6.0994, 6.2469, 6.1239])\n",
      "Reward: -19.90403175354004\n",
      "Discounted Reward: -4.363705635070801\n",
      "Current pose: tensor([3.0043, 2.9252, 0.2456, 0.3379, 3.0575, 3.0489, 3.1213, 3.0638])\n",
      "Action: tensor([3.0043, 2.9252, 0.2456, 0.3379, 3.0575, 3.0489, 3.1213, 3.0638])\n",
      "Next pose: tensor([6.0086, 5.8503, 0.4913, 0.6757, 6.1149, 6.0978, 6.2427, 6.1276])\n",
      "Reward: -19.879716873168945\n",
      "Discounted Reward: -4.314790725708008\n",
      "Current pose: tensor([2.9920, 2.9220, 0.2505, 0.3322, 3.0654, 3.0412, 3.0940, 3.0623])\n",
      "Action: tensor([2.9920, 2.9220, 0.2505, 0.3322, 3.0654, 3.0412, 3.0940, 3.0623])\n",
      "Next pose: tensor([5.9840, 5.8439, 0.5009, 0.6644, 6.1307, 6.0824, 6.1879, 6.1247])\n",
      "Reward: -19.792999267578125\n",
      "Discounted Reward: -4.253009796142578\n",
      "Current pose: tensor([2.9900, 2.9282, 0.2501, 0.3196, 3.0647, 3.0359, 3.0936, 3.0464])\n",
      "Action: tensor([2.9900, 2.9282, 0.2501, 0.3196, 3.0647, 3.0359, 3.0936, 3.0464])\n",
      "Next pose: tensor([5.9801, 5.8564, 0.5003, 0.6391, 6.1294, 6.0718, 6.1871, 6.0929])\n",
      "Reward: -19.782981872558594\n",
      "Discounted Reward: -4.208348751068115\n",
      "Current pose: tensor([2.9906, 2.9323, 0.2507, 0.3117, 3.0697, 3.0339, 3.0765, 3.0583])\n",
      "Action: tensor([2.9906, 2.9323, 0.2507, 0.3117, 3.0697, 3.0339, 3.0765, 3.0583])\n",
      "Next pose: tensor([5.9812, 5.8647, 0.5015, 0.6233, 6.1394, 6.0679, 6.1530, 6.1167])\n",
      "Reward: -19.802684783935547\n",
      "Discounted Reward: -4.170414447784424\n",
      "Current pose: tensor([2.9690, 2.9066, 0.2600, 0.3153, 3.0669, 3.0327, 3.0848, 3.0560])\n",
      "Action: tensor([2.9690, 2.9066, 0.2600, 0.3153, 3.0669, 3.0327, 3.0848, 3.0560])\n",
      "Next pose: tensor([5.9381, 5.8132, 0.5200, 0.6305, 6.1339, 6.0655, 6.1696, 6.1119])\n",
      "Reward: -19.686382293701172\n",
      "Discounted Reward: -4.104462146759033\n",
      "Current pose: tensor([2.9656, 2.9272, 0.2618, 0.2981, 3.0720, 3.0230, 3.1008, 3.0645])\n",
      "Action: tensor([2.9656, 2.9272, 0.2618, 0.2981, 3.0720, 3.0230, 3.1008, 3.0645])\n",
      "Next pose: tensor([5.9313, 5.8545, 0.5236, 0.5962, 6.1439, 6.0459, 6.2015, 6.1290])\n",
      "Reward: -19.790956497192383\n",
      "Discounted Reward: -4.085002422332764\n",
      "Current pose: tensor([2.9585, 2.9756, 0.2742, 0.2702, 3.0693, 3.0229, 3.1393, 3.0723])\n",
      "Action: tensor([2.9585, 2.9756, 0.2742, 0.2702, 3.0693, 3.0229, 3.1393, 3.0723])\n",
      "Next pose: tensor([5.9171, 5.9513, 0.5485, 0.5404, 6.1385, 6.0458, 6.2786, 6.1447])\n",
      "Reward: -19.991636276245117\n",
      "Discounted Reward: -4.085160255432129\n",
      "Current pose: tensor([2.9107, 2.9884, 0.3023, 0.2572, 3.0690, 3.0238, 3.0860, 3.0810])\n",
      "Action: tensor([2.9107, 2.9884, 0.3023, 0.2572, 3.0690, 3.0238, 3.0860, 3.0810])\n",
      "Next pose: tensor([5.8213, 5.9768, 0.6046, 0.5144, 6.1381, 6.0476, 6.1721, 6.1620])\n",
      "Reward: -19.8035831451416\n",
      "Discounted Reward: -4.006265640258789\n",
      "Current pose: tensor([2.9150, 3.0213, 0.3094, 0.2528, 3.0621, 3.0130, 3.0918, 3.1258])\n",
      "Action: tensor([2.9150, 3.0213, 0.3094, 0.2528, 3.0621, 3.0130, 3.0918, 3.1258])\n",
      "Next pose: tensor([5.8300, 6.0425, 0.6189, 0.5056, 6.1243, 6.0260, 6.1836, 6.2516])\n",
      "Reward: -19.93830108642578\n",
      "Discounted Reward: -3.9931838512420654\n",
      "Current pose: tensor([2.9168, 3.0115, 0.3115, 0.2587, 3.0630, 3.0159, 3.1002, 3.1101])\n",
      "Action: tensor([2.9168, 3.0115, 0.3115, 0.2587, 3.0630, 3.0159, 3.1002, 3.1101])\n",
      "Next pose: tensor([5.8337, 6.0229, 0.6229, 0.5173, 6.1259, 6.0319, 6.2004, 6.2202])\n",
      "Reward: -19.899410247802734\n",
      "Discounted Reward: -3.9455406665802\n",
      "Current pose: tensor([2.9113, 2.9982, 0.3229, 0.2739, 3.0593, 3.0219, 3.1169, 3.1064])\n",
      "Action: tensor([2.9113, 2.9982, 0.3229, 0.2739, 3.0593, 3.0219, 3.1169, 3.1064])\n",
      "Next pose: tensor([5.8225, 5.9964, 0.6457, 0.5479, 6.1187, 6.0438, 6.2338, 6.2128])\n",
      "Reward: -19.838993072509766\n",
      "Discounted Reward: -3.89422607421875\n",
      "Current pose: tensor([2.9411, 2.9754, 0.3162, 0.2945, 3.0561, 3.0264, 3.1370, 3.0968])\n",
      "Action: tensor([2.9411, 2.9754, 0.3162, 0.2945, 3.0561, 3.0264, 3.1370, 3.0968])\n",
      "Next pose: tensor([5.8822, 5.9507, 0.6324, 0.5890, 6.1123, 6.0527, 6.2739, 6.1936])\n",
      "Reward: -19.848840713500977\n",
      "Discounted Reward: -3.8571975231170654\n",
      "Current pose: tensor([2.9960, 2.9608, 0.2943, 0.3023, 3.0500, 3.0183, 3.1271, 3.1121])\n",
      "Action: tensor([2.9960, 2.9608, 0.2943, 0.3023, 3.0500, 3.0183, 3.1271, 3.1121])\n",
      "Next pose: tensor([5.9919, 5.9217, 0.5885, 0.6046, 6.1001, 6.0367, 6.2543, 6.2241])\n",
      "Reward: -19.9403076171875\n",
      "Discounted Reward: -3.8362224102020264\n",
      "Current pose: tensor([3.0259, 2.9405, 0.2689, 0.3136, 3.0574, 3.0183, 3.1104, 3.1132])\n",
      "Action: tensor([3.0259, 2.9405, 0.2689, 0.3136, 3.0574, 3.0183, 3.1104, 3.1132])\n",
      "Next pose: tensor([6.0519, 5.8810, 0.5379, 0.6273, 6.1148, 6.0366, 6.2209, 6.2263])\n",
      "Reward: -19.971004486083984\n",
      "Discounted Reward: -3.803706645965576\n",
      "Current pose: tensor([3.0606, 2.9803, 0.2585, 0.2959, 3.0523, 3.0172, 3.1258, 3.1052])\n",
      "Action: tensor([3.0606, 2.9803, 0.2585, 0.2959, 3.0523, 3.0172, 3.1258, 3.1052])\n",
      "Next pose: tensor([6.1211, 5.9606, 0.5169, 0.5918, 6.1046, 6.0344, 6.2517, 6.2105])\n",
      "Reward: -20.17890167236328\n",
      "Discounted Reward: -3.804870128631592\n",
      "Current pose: tensor([3.0385, 2.9645, 0.2565, 0.3076, 3.0621, 3.0156, 3.1304, 3.1013])\n",
      "Action: tensor([3.0385, 2.9645, 0.2565, 0.3076, 3.0621, 3.0156, 3.1304, 3.1013])\n",
      "Next pose: tensor([6.0769, 5.9289, 0.5130, 0.6152, 6.1241, 6.0313, 6.2608, 6.2026])\n",
      "Reward: -20.10117530822754\n",
      "Discounted Reward: -3.752311944961548\n",
      "Current pose: tensor([3.0137, 2.9639, 0.2636, 0.3017, 3.0561, 3.0178, 3.1203, 3.1079])\n",
      "Action: tensor([3.0137, 2.9639, 0.2636, 0.3017, 3.0561, 3.0178, 3.1203, 3.1079])\n",
      "Next pose: tensor([6.0274, 5.9278, 0.5272, 0.6033, 6.1121, 6.0356, 6.2406, 6.2159])\n",
      "Reward: -20.033540725708008\n",
      "Discounted Reward: -3.702289581298828\n",
      "Current pose: tensor([2.9957, 2.9812, 0.2628, 0.2938, 3.0443, 3.0210, 3.1124, 3.1090])\n",
      "Action: tensor([2.9957, 2.9812, 0.2628, 0.2938, 3.0443, 3.0210, 3.1124, 3.1090])\n",
      "Next pose: tensor([5.9915, 5.9624, 0.5256, 0.5875, 6.0887, 6.0420, 6.2248, 6.2180])\n",
      "Reward: -20.01886558532715\n",
      "Discounted Reward: -3.6625819206237793\n",
      "Current pose: tensor([2.9959, 2.9842, 0.2550, 0.2948, 3.0458, 3.0185, 3.1141, 3.1033])\n",
      "Action: tensor([2.9959, 2.9842, 0.2550, 0.2948, 3.0458, 3.0185, 3.1141, 3.1033])\n",
      "Next pose: tensor([5.9917, 5.9684, 0.5101, 0.5896, 6.0915, 6.0369, 6.2283, 6.2067])\n",
      "Reward: -20.02861785888672\n",
      "Discounted Reward: -3.6277225017547607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pose: tensor([2.9942, 2.9455, 0.2546, 0.3240, 3.0380, 3.0262, 3.1202, 3.0986])\n",
      "Action: tensor([2.9942, 2.9455, 0.2546, 0.3240, 3.0380, 3.0262, 3.1202, 3.0986])\n",
      "Next pose: tensor([5.9884, 5.8910, 0.5093, 0.6480, 6.0760, 6.0525, 6.2403, 6.1972])\n",
      "Reward: -19.89283561706543\n",
      "Discounted Reward: -3.5670974254608154\n",
      "Current pose: tensor([2.9969, 2.9514, 0.2520, 0.3157, 3.0371, 3.0261, 3.1178, 3.0973])\n",
      "Action: tensor([2.9969, 2.9514, 0.2520, 0.3157, 3.0371, 3.0261, 3.1178, 3.0973])\n",
      "Next pose: tensor([5.9937, 5.9029, 0.5039, 0.6315, 6.0743, 6.0522, 6.2356, 6.1946])\n",
      "Reward: -19.92255401611328\n",
      "Discounted Reward: -3.5367021560668945\n",
      "Current pose: tensor([2.9866, 2.9297, 0.2624, 0.3183, 3.0312, 3.0361, 3.1272, 3.0917])\n",
      "Action: tensor([2.9866, 2.9297, 0.2624, 0.3183, 3.0312, 3.0361, 3.1272, 3.0917])\n",
      "Next pose: tensor([5.9732, 5.8595, 0.5247, 0.6367, 6.0623, 6.0722, 6.2544, 6.1833])\n",
      "Reward: -19.848209381103516\n",
      "Discounted Reward: -3.488269329071045\n",
      "Current pose: tensor([2.9848, 2.9503, 0.2624, 0.3020, 3.0345, 3.0395, 3.1335, 3.0948])\n",
      "Action: tensor([2.9848, 2.9503, 0.2624, 0.3020, 3.0345, 3.0395, 3.1335, 3.0948])\n",
      "Next pose: tensor([5.9695, 5.9007, 0.5249, 0.6040, 6.0691, 6.0790, 6.2669, 6.1895])\n",
      "Reward: -19.95050811767578\n",
      "Discounted Reward: -3.4711854457855225\n",
      "Current pose: tensor([2.9929, 3.1267, 0.2554, 0.3054, 3.0422, 3.0355, 3.1340, 3.1078])\n",
      "Action: tensor([2.9929, 3.1267, 0.2554, 0.3054, 3.0422, 3.0355, 3.1340, 3.1078])\n",
      "Next pose: tensor([5.9857, 6.2534, 0.5108, 0.6107, 6.0843, 6.0710, 6.2681, 6.2156])\n",
      "Reward: -20.361316680908203\n",
      "Discounted Reward: -3.507235288619995\n",
      "Current pose: tensor([3.0031, 3.0646, 0.2519, 0.2948, 3.0387, 3.0336, 3.1372, 3.1080])\n",
      "Action: tensor([3.0031, 3.0646, 0.2519, 0.2948, 3.0387, 3.0336, 3.1372, 3.1080])\n",
      "Next pose: tensor([6.0063, 6.1292, 0.5038, 0.5897, 6.0774, 6.0671, 6.2743, 6.2160])\n",
      "Reward: -20.281574249267578\n",
      "Discounted Reward: -3.4585647583007812\n",
      "Current pose: tensor([3.0095, 3.0568, 0.2480, 0.2854, 3.0358, 3.0317, 3.1373, 3.1165])\n",
      "Action: tensor([3.0095, 3.0568, 0.2480, 0.2854, 3.0358, 3.0317, 3.1373, 3.1165])\n",
      "Next pose: tensor([6.0190, 6.1135, 0.4959, 0.5709, 6.0716, 6.0634, 6.2745, 6.2330])\n",
      "Reward: -20.31293296813965\n",
      "Discounted Reward: -3.4292731285095215\n",
      "Current pose: tensor([2.9973, 3.0457, 0.2534, 0.2840, 3.0393, 3.0262, 3.1333, 3.1184])\n",
      "Action: tensor([2.9973, 3.0457, 0.2534, 0.2840, 3.0393, 3.0262, 3.1333, 3.1184])\n",
      "Next pose: tensor([5.9946, 6.0914, 0.5068, 0.5680, 6.0786, 6.0523, 6.2667, 6.2368])\n",
      "Reward: -20.250234603881836\n",
      "Discounted Reward: -3.3845014572143555\n",
      "Current pose: tensor([3.0181, 3.0189, 0.2407, 0.2872, 3.0366, 3.0269, 3.1322, 3.1205])\n",
      "Action: tensor([3.0181, 3.0189, 0.2407, 0.2872, 3.0366, 3.0269, 3.1322, 3.1205])\n",
      "Next pose: tensor([6.0363, 6.0378, 0.4813, 0.5743, 6.0732, 6.0538, 6.2644, 6.2410])\n",
      "Reward: -20.255538940429688\n",
      "Discounted Reward: -3.351534128189087\n",
      "Current pose: tensor([3.0098, 2.9777, 0.2454, 0.3014, 3.0303, 3.0331, 3.1243, 3.1197])\n",
      "Action: tensor([3.0098, 2.9777, 0.2454, 0.3014, 3.0303, 3.0331, 3.1243, 3.1197])\n",
      "Next pose: tensor([6.0196, 5.9555, 0.4908, 0.6027, 6.0607, 6.0663, 6.2487, 6.2393])\n",
      "Reward: -20.101154327392578\n",
      "Discounted Reward: -3.292729377746582\n",
      "Current pose: tensor([3.0093, 2.9810, 0.2477, 0.2982, 3.0263, 3.0305, 3.1249, 3.1228])\n",
      "Action: tensor([3.0093, 2.9810, 0.2477, 0.2982, 3.0263, 3.0305, 3.1249, 3.1228])\n",
      "Next pose: tensor([6.0186, 5.9620, 0.4953, 0.5965, 6.0527, 6.0610, 6.2499, 6.2456])\n",
      "Reward: -20.102624893188477\n",
      "Discounted Reward: -3.260040521621704\n",
      "Current pose: tensor([3.0121, 2.9589, 0.2470, 0.3024, 3.0265, 3.0360, 3.1242, 3.1207])\n",
      "Action: tensor([3.0121, 2.9589, 0.2470, 0.3024, 3.0265, 3.0360, 3.1242, 3.1207])\n",
      "Next pose: tensor([6.0243, 5.9179, 0.4941, 0.6048, 6.0530, 6.0720, 6.2483, 6.2414])\n",
      "Reward: -20.062658309936523\n",
      "Discounted Reward: -3.2210235595703125\n",
      "Current pose: tensor([3.0142, 2.9373, 0.2465, 0.3144, 3.0287, 3.0332, 3.1249, 3.1202])\n",
      "Action: tensor([3.0142, 2.9373, 0.2465, 0.3144, 3.0287, 3.0332, 3.1249, 3.1202])\n",
      "Next pose: tensor([6.0284, 5.8746, 0.4929, 0.6288, 6.0574, 6.0664, 6.2498, 6.2404])\n",
      "Reward: -20.000043869018555\n",
      "Discounted Reward: -3.178861141204834\n",
      "Current pose: tensor([3.0292, 2.9229, 0.2379, 0.3169, 3.0326, 3.0290, 3.1290, 3.1316])\n",
      "Action: tensor([3.0292, 2.9229, 0.2379, 0.3169, 3.0326, 3.0290, 3.1290, 3.1316])\n",
      "Next pose: tensor([6.0584, 5.8458, 0.4759, 0.6338, 6.0652, 6.0581, 6.2579, 6.2632])\n",
      "Reward: -20.043563842773438\n",
      "Discounted Reward: -3.1539206504821777\n",
      "Current pose: tensor([3.0323, 2.9156, 0.2362, 0.3248, 3.0319, 3.0247, 3.1297, 3.1362])\n",
      "Action: tensor([3.0323, 2.9156, 0.2362, 0.3248, 3.0319, 3.0247, 3.1297, 3.1362])\n",
      "Next pose: tensor([6.0647, 5.8311, 0.4724, 0.6495, 6.0638, 6.0494, 6.2594, 6.2724])\n",
      "Reward: -20.023590087890625\n",
      "Discounted Reward: -3.119269847869873\n",
      "Current pose: tensor([3.0304, 2.9180, 0.2345, 0.3118, 3.0262, 3.0290, 3.1285, 3.1295])\n",
      "Action: tensor([3.0304, 2.9180, 0.2345, 0.3118, 3.0262, 3.0290, 3.1285, 3.1295])\n",
      "Next pose: tensor([6.0608, 5.8359, 0.4690, 0.6237, 6.0524, 6.0581, 6.2571, 6.2589])\n",
      "Reward: -20.035165786743164\n",
      "Discounted Reward: -3.08986234664917\n",
      "Current pose: tensor([3.0330, 2.9147, 0.2314, 0.3120, 3.0264, 3.0296, 3.1284, 3.1271])\n",
      "Action: tensor([3.0330, 2.9147, 0.2314, 0.3120, 3.0264, 3.0296, 3.1284, 3.1271])\n",
      "Next pose: tensor([6.0659, 5.8294, 0.4627, 0.6240, 6.0528, 6.0593, 6.2567, 6.2542])\n",
      "Reward: -20.036338806152344\n",
      "Discounted Reward: -3.059142827987671\n",
      "Current pose: tensor([3.0315, 2.9049, 0.2319, 0.3144, 3.0267, 3.0322, 3.1285, 3.1281])\n",
      "Action: tensor([3.0315, 2.9049, 0.2319, 0.3144, 3.0267, 3.0322, 3.1285, 3.1281])\n",
      "Next pose: tensor([6.0631, 5.8097, 0.4637, 0.6289, 6.0534, 6.0644, 6.2570, 6.2563])\n",
      "Reward: -20.016002655029297\n",
      "Discounted Reward: -3.025477647781372\n",
      "Current pose: tensor([3.0247, 2.9040, 0.2381, 0.3152, 3.0287, 3.0264, 3.1310, 3.1314])\n",
      "Action: tensor([3.0247, 2.9040, 0.2381, 0.3152, 3.0287, 3.0264, 3.1310, 3.1314])\n",
      "Next pose: tensor([6.0494, 5.8081, 0.4763, 0.6303, 6.0574, 6.0529, 6.2619, 6.2627])\n",
      "Reward: -19.990467071533203\n",
      "Discounted Reward: -2.9914016723632812\n",
      "Current pose: tensor([3.0218, 2.9052, 0.2418, 0.3246, 3.0302, 3.0226, 3.1297, 3.1311])\n",
      "Action: tensor([3.0218, 2.9052, 0.2418, 0.3246, 3.0302, 3.0226, 3.1297, 3.1311])\n",
      "Next pose: tensor([6.0437, 5.8104, 0.4835, 0.6491, 6.0603, 6.0453, 6.2593, 6.2623])\n",
      "Reward: -19.953298568725586\n",
      "Discounted Reward: -2.9559812545776367\n",
      "Current pose: tensor([3.0250, 2.9076, 0.2396, 0.3217, 3.0306, 3.0252, 3.1281, 3.1291])\n",
      "Action: tensor([3.0250, 2.9076, 0.2396, 0.3217, 3.0306, 3.0252, 3.1281, 3.1291])\n",
      "Next pose: tensor([6.0500, 5.8153, 0.4791, 0.6435, 6.0612, 6.0503, 6.2563, 6.2583])\n",
      "Reward: -19.973405838012695\n",
      "Discounted Reward: -2.929370641708374\n",
      "Current pose: tensor([3.0340, 2.9063, 0.2407, 0.3277, 3.0301, 3.0262, 3.1281, 3.1295])\n",
      "Action: tensor([3.0340, 2.9063, 0.2407, 0.3277, 3.0301, 3.0262, 3.1281, 3.1295])\n",
      "Next pose: tensor([6.0681, 5.8126, 0.4813, 0.6553, 6.0602, 6.0524, 6.2563, 6.2590])\n",
      "Reward: -19.976665496826172\n",
      "Discounted Reward: -2.90054988861084\n",
      "Current pose: tensor([3.0588, 2.9369, 0.2369, 0.3284, 3.0301, 3.0253, 3.1296, 3.1300])\n",
      "Action: tensor([3.0588, 2.9369, 0.2369, 0.3284, 3.0301, 3.0253, 3.1296, 3.1300])\n",
      "Next pose: tensor([6.1177, 5.8738, 0.4738, 0.6569, 6.0603, 6.0507, 6.2592, 6.2600])\n",
      "Reward: -20.095611572265625\n",
      "Discounted Reward: -2.8886423110961914\n",
      "Current pose: tensor([3.0715, 2.9580, 0.2396, 0.3297, 3.0300, 3.0231, 3.1327, 3.1325])\n",
      "Action: tensor([3.0715, 2.9580, 0.2396, 0.3297, 3.0300, 3.0231, 3.1327, 3.1325])\n",
      "Next pose: tensor([6.1429, 5.9159, 0.4792, 0.6594, 6.0600, 6.0461, 6.2653, 6.2649])\n",
      "Reward: -20.161277770996094\n",
      "Discounted Reward: -2.86910080909729\n",
      "Current pose: tensor([3.0885, 2.9710, 0.2390, 0.3236, 3.0322, 3.0251, 3.1336, 3.1323])\n",
      "Action: tensor([3.0885, 2.9710, 0.2390, 0.3236, 3.0322, 3.0251, 3.1336, 3.1323])\n",
      "Next pose: tensor([6.1771, 5.9419, 0.4780, 0.6473, 6.0643, 6.0503, 6.2672, 6.2647])\n",
      "Reward: -20.244911193847656\n",
      "Discounted Reward: -2.8521924018859863\n",
      "Current pose: tensor([3.1173, 3.0460, 0.2463, 0.3455, 3.0356, 3.0234, 3.1349, 3.1272])\n",
      "Action: tensor([3.1173, 3.0460, 0.2463, 0.3455, 3.0356, 3.0234, 3.1349, 3.1272])\n",
      "Next pose: tensor([6.2346, 6.0919, 0.4926, 0.6910, 6.0712, 6.0468, 6.2699, 6.2544])\n",
      "Reward: -20.38991928100586\n",
      "Discounted Reward: -2.843895673751831\n",
      "Current pose: tensor([3.1378, 3.1039, 0.2650, 0.3668, 3.0378, 3.0220, 3.1357, 3.1273])\n",
      "Action: tensor([3.1378, 3.1039, 0.2650, 0.3668, 3.0378, 3.0220, 3.1357, 3.1273])\n",
      "Next pose: tensor([6.2756, 6.2078, 0.5300, 0.7335, 6.0757, 6.0440, 6.2713, 6.2545])\n",
      "Reward: -20.46998405456543\n",
      "Discounted Reward: -2.826512098312378\n",
      "Current pose: tensor([3.1019, 3.1318, 0.2804, 0.4121, 3.0492, 3.0151, 3.1399, 3.1286])\n",
      "Action: tensor([3.1019, 3.1318, 0.2804, 0.4121, 3.0492, 3.0151, 3.1399, 3.1286])\n",
      "Next pose: tensor([6.2038, 6.2636, 0.5608, 0.8242, 6.0984, 6.0302, 6.2799, 6.2573])\n",
      "Reward: -20.35285186767578\n",
      "Discounted Reward: -2.7822349071502686\n",
      "Current pose: tensor([3.0445, 3.0787, 0.3068, 0.4728, 3.0571, 3.0064, 3.1416, 3.1251])\n",
      "Action: tensor([3.0445, 3.0787, 0.3068, 0.4728, 3.0571, 3.0064, 3.1416, 3.1251])\n",
      "Next pose: tensor([6.0890, 6.1575, 0.6136, 0.9455, 6.1142, 6.0129, 6.2832, 6.2502])\n",
      "Reward: -19.952499389648438\n",
      "Discounted Reward: -2.7002315521240234\n",
      "Current pose: tensor([3.0640, 3.0286, 0.3686, 0.5070, 3.0583, 3.0050, 3.1392, 3.1220])\n",
      "Action: tensor([3.0640, 3.0286, 0.3686, 0.5070, 3.0583, 3.0050, 3.1392, 3.1220])\n",
      "Next pose: tensor([6.1279, 6.0572, 0.7373, 1.0140, 6.1167, 6.0099, 6.2785, 6.2440])\n",
      "Reward: -19.687707901000977\n",
      "Discounted Reward: -2.6377527713775635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pose: tensor([3.0231, 2.9515, 0.4416, 0.5481, 3.0603, 2.9993, 3.1386, 3.1237])\n",
      "Action: tensor([3.0231, 2.9515, 0.4416, 0.5481, 3.0603, 2.9993, 3.1386, 3.1237])\n",
      "Next pose: tensor([6.0462, 5.9029, 0.8832, 1.0963, 6.1207, 5.9986, 6.2773, 6.2474])\n",
      "Reward: -19.218341827392578\n",
      "Discounted Reward: -2.549118757247925\n",
      "Current pose: tensor([2.9553, 2.9206, 0.5113, 0.6093, 3.0640, 2.9961, 3.1369, 3.1251])\n",
      "Action: tensor([2.9553, 2.9206, 0.5113, 0.6093, 3.0640, 2.9961, 3.1369, 3.1251])\n",
      "Next pose: tensor([5.9106, 5.8411, 1.0226, 1.2187, 6.1280, 5.9921, 6.2739, 6.2503])\n",
      "Reward: -18.759572982788086\n",
      "Discounted Reward: -2.4633846282958984\n",
      "Current pose: tensor([2.9675, 2.9061, 0.6292, 0.7289, 3.0661, 2.9923, 3.1333, 3.1275])\n",
      "Action: tensor([2.9675, 2.9061, 0.6292, 0.7289, 3.0661, 2.9923, 3.1333, 3.1275])\n",
      "Next pose: tensor([5.9350, 5.8121, 1.2585, 1.4579, 6.1321, 5.9845, 6.2667, 6.2551])\n",
      "Reward: -18.27382469177246\n",
      "Discounted Reward: -2.375603437423706\n",
      "Current pose: tensor([2.9396, 2.8414, 0.7622, 0.8072, 3.0667, 2.9886, 3.1325, 3.1281])\n",
      "Action: tensor([2.9396, 2.8414, 0.7622, 0.8072, 3.0667, 2.9886, 3.1325, 3.1281])\n",
      "Next pose: tensor([5.8791, 5.6828, 1.5243, 1.6144, 6.1334, 5.9771, 6.2650, 6.2561])\n",
      "Reward: -17.956260681152344\n",
      "Discounted Reward: -2.310976982116699\n",
      "Current pose: tensor([2.7120, 2.8915, 0.8341, 0.9378, 3.0733, 2.9831, 3.1312, 3.1312])\n",
      "Action: tensor([2.7120, 2.8915, 0.8341, 0.9378, 3.0733, 2.9831, 3.1312, 3.1312])\n",
      "Next pose: tensor([5.4240, 5.7829, 1.6681, 1.8756, 6.1466, 5.9661, 6.2624, 6.2625])\n",
      "Reward: -17.80196762084961\n",
      "Discounted Reward: -2.2682080268859863\n",
      "Current pose: tensor([2.9455, 2.9108, 1.0091, 1.0505, 3.0785, 2.9785, 3.1292, 3.1297])\n",
      "Action: tensor([2.9455, 2.9108, 1.0091, 1.0505, 3.0785, 2.9785, 3.1292, 3.1297])\n",
      "Next pose: tensor([5.8911, 5.8215, 2.0182, 2.1010, 6.1571, 5.9570, 6.2583, 6.2594])\n",
      "Reward: -18.877445220947266\n",
      "Discounted Reward: -2.381186008453369\n",
      "Current pose: tensor([3.0017, 2.8497, 1.1945, 1.1412, 3.0791, 2.9838, 3.1290, 3.1274])\n",
      "Action: tensor([3.0017, 2.8497, 1.1945, 1.1412, 3.0791, 2.9838, 3.1290, 3.1274])\n",
      "Next pose: tensor([6.0034, 5.6994, 2.3890, 2.2824, 6.1582, 5.9675, 6.2580, 6.2548])\n",
      "Reward: -19.426389694213867\n",
      "Discounted Reward: -2.4259250164031982\n",
      "Current pose: tensor([2.9002, 2.7991, 1.3279, 1.1989, 3.0864, 2.9889, 3.1280, 3.1233])\n",
      "Action: tensor([2.9002, 2.7991, 1.3279, 1.1989, 3.0864, 2.9889, 3.1280, 3.1233])\n",
      "Next pose: tensor([5.8004, 5.5981, 2.6559, 2.3978, 6.1729, 5.9778, 6.2561, 6.2465])\n",
      "Reward: -19.519126892089844\n",
      "Discounted Reward: -2.413130760192871\n",
      "Current pose: tensor([3.1113, 2.8220, 1.6399, 1.4586, 3.0899, 2.9946, 3.1192, 3.1205])\n",
      "Action: tensor([3.1113, 2.8220, 1.6399, 1.4586, 3.0899, 2.9946, 3.1192, 3.1205])\n",
      "Next pose: tensor([6.2226, 5.6441, 3.2797, 2.9172, 6.1798, 5.9893, 6.2384, 6.2411])\n",
      "Reward: -21.125770568847656\n",
      "Discounted Reward: -2.5856409072875977\n",
      "Current pose: tensor([3.0490, 2.9176, 1.6012, 1.5244, 3.0909, 2.9961, 3.1191, 3.1224])\n",
      "Action: tensor([3.0490, 2.9176, 1.6012, 1.5244, 3.0909, 2.9961, 3.1191, 3.1224])\n",
      "Next pose: tensor([6.0980, 5.8351, 3.2025, 3.0488, 6.1818, 5.9923, 6.2383, 6.2449])\n",
      "Reward: -21.2553653717041\n",
      "Discounted Reward: -2.5754873752593994\n",
      "Current pose: tensor([3.1123, 2.9595, 1.6748, 1.5478, 3.0873, 2.9973, 3.1110, 3.1264])\n",
      "Action: tensor([3.1123, 2.9595, 1.6748, 1.5478, 3.0873, 2.9973, 3.1110, 3.1264])\n",
      "Next pose: tensor([6.2247, 5.9190, 3.3497, 3.0956, 6.1745, 5.9946, 6.2221, 6.2527])\n",
      "Reward: -21.646560668945312\n",
      "Discounted Reward: -2.5966591835021973\n",
      "Current pose: tensor([3.1152, 3.0470, 1.6929, 1.5892, 3.0877, 2.9941, 3.1093, 3.1281])\n",
      "Action: tensor([3.1152, 3.0470, 1.6929, 1.5892, 3.0877, 2.9941, 3.1093, 3.1281])\n",
      "Next pose: tensor([6.2304, 6.0941, 3.3858, 3.1785, 6.1754, 5.9881, 6.2187, 6.2562])\n",
      "Reward: -21.940832138061523\n",
      "Discounted Reward: -2.6056394577026367\n",
      "Current pose: tensor([3.1385, 3.0882, 1.7311, 1.6167, 3.0851, 2.9923, 3.1092, 3.1312])\n",
      "Action: tensor([3.1385, 3.0882, 1.7311, 1.6167, 3.0851, 2.9923, 3.1092, 3.1312])\n",
      "Next pose: tensor([6.2769, 6.1764, 3.4622, 3.2335, 6.1702, 5.9847, 6.2185, 6.2623])\n",
      "Reward: -22.19837188720703\n",
      "Discounted Reward: -2.6098620891571045\n",
      "Current pose: tensor([3.1065, 3.0335, 1.7177, 1.5890, 3.0844, 2.9925, 3.1100, 3.1316])\n",
      "Action: tensor([3.1065, 3.0335, 1.7177, 1.5890, 3.0844, 2.9925, 3.1100, 3.1316])\n",
      "Next pose: tensor([6.2130, 6.0669, 3.4353, 3.1781, 6.1689, 5.9850, 6.2200, 6.2631])\n",
      "Reward: -21.94397735595703\n",
      "Discounted Reward: -2.5541534423828125\n",
      "Current pose: tensor([3.0649, 3.0459, 1.6958, 1.5989, 3.0823, 2.9952, 3.1078, 3.1297])\n",
      "Action: tensor([3.0649, 3.0459, 1.6958, 1.5989, 3.0823, 2.9952, 3.1078, 3.1297])\n",
      "Next pose: tensor([6.1298, 6.0919, 3.3917, 3.1979, 6.1646, 5.9904, 6.2156, 6.2595])\n",
      "Reward: -21.855066299438477\n",
      "Discounted Reward: -2.518366575241089\n",
      "Current pose: tensor([3.0341, 3.0316, 1.6784, 1.6016, 3.0798, 2.9986, 3.1063, 3.1297])\n",
      "Action: tensor([3.0341, 3.0316, 1.6784, 1.6016, 3.0798, 2.9986, 3.1063, 3.1297])\n",
      "Next pose: tensor([6.0681, 6.0633, 3.3569, 3.2032, 6.1597, 5.9971, 6.2127, 6.2594])\n",
      "Reward: -21.734066009521484\n",
      "Discounted Reward: -2.479379653930664\n",
      "Current pose: tensor([3.0068, 3.0271, 1.6586, 1.5887, 3.0776, 3.0013, 3.1048, 3.1310])\n",
      "Action: tensor([3.0068, 3.0271, 1.6586, 1.5887, 3.0776, 3.0013, 3.1048, 3.1310])\n",
      "Next pose: tensor([6.0136, 6.0542, 3.3171, 3.1773, 6.1552, 6.0026, 6.2096, 6.2621])\n",
      "Reward: -21.605491638183594\n",
      "Discounted Reward: -2.4400649070739746\n",
      "Current pose: tensor([2.9778, 3.0367, 1.6454, 1.5843, 3.0771, 3.0002, 3.1046, 3.1327])\n",
      "Action: tensor([2.9778, 3.0367, 1.6454, 1.5843, 3.0771, 3.0002, 3.1046, 3.1327])\n",
      "Next pose: tensor([5.9557, 6.0735, 3.2908, 3.1686, 6.1541, 6.0004, 6.2093, 6.2654])\n",
      "Reward: -21.53141212463379\n",
      "Discounted Reward: -2.407381534576416\n",
      "Current pose: tensor([3.0045, 3.0452, 1.6357, 1.5769, 3.0743, 3.0033, 3.1087, 3.1379])\n",
      "Action: tensor([3.0045, 3.0452, 1.6357, 1.5769, 3.0743, 3.0033, 3.1087, 3.1379])\n",
      "Next pose: tensor([6.0090, 6.0905, 3.2714, 3.1538, 6.1485, 6.0066, 6.2175, 6.2758])\n",
      "Reward: -21.58681869506836\n",
      "Discounted Reward: -2.3894407749176025\n",
      "Current pose: tensor([3.0941, 2.9517, 1.7023, 1.5837, 3.0723, 3.0027, 3.1089, 3.1369])\n",
      "Action: tensor([3.0941, 2.9517, 1.7023, 1.5837, 3.0723, 3.0027, 3.1089, 3.1369])\n",
      "Next pose: tensor([6.1883, 5.9033, 3.4046, 3.1674, 6.1447, 6.0053, 6.2179, 6.2738])\n",
      "Reward: -21.718923568725586\n",
      "Discounted Reward: -2.3800227642059326\n",
      "Current pose: tensor([3.0989, 2.9973, 1.6914, 1.6590, 3.0770, 2.9932, 3.1078, 3.1374])\n",
      "Action: tensor([3.0989, 2.9973, 1.6914, 1.6590, 3.0770, 2.9932, 3.1078, 3.1374])\n",
      "Next pose: tensor([6.1978, 5.9945, 3.3829, 3.3180, 6.1540, 5.9864, 6.2157, 6.2749])\n",
      "Reward: -21.937862396240234\n",
      "Discounted Reward: -2.379974603652954\n",
      "Current pose: tensor([3.0370, 3.0517, 1.6711, 1.6641, 3.0788, 2.9913, 3.1134, 3.1373])\n",
      "Action: tensor([3.0370, 3.0517, 1.6711, 1.6641, 3.0788, 2.9913, 3.1134, 3.1373])\n",
      "Next pose: tensor([6.0740, 6.1035, 3.3423, 3.3281, 6.1576, 5.9826, 6.2268, 6.2746])\n",
      "Reward: -21.903244018554688\n",
      "Discounted Reward: -2.35245680809021\n",
      "Current pose: tensor([3.0368, 3.0601, 1.6633, 1.6463, 3.0748, 2.9948, 3.1170, 3.1403])\n",
      "Action: tensor([3.0368, 3.0601, 1.6633, 1.6463, 3.0748, 2.9948, 3.1170, 3.1403])\n",
      "Next pose: tensor([6.0736, 6.1202, 3.3267, 3.2927, 6.1496, 5.9897, 6.2340, 6.2807])\n",
      "Reward: -21.880847930908203\n",
      "Discounted Reward: -2.3265507221221924\n",
      "Current pose: tensor([3.0796, 3.0822, 1.6757, 1.6529, 3.0705, 2.9942, 3.1157, 3.1317])\n",
      "Action: tensor([3.0796, 3.0822, 1.6757, 1.6529, 3.0705, 2.9942, 3.1157, 3.1317])\n",
      "Next pose: tensor([6.1592, 6.1644, 3.3513, 3.3058, 6.1410, 5.9885, 6.2314, 6.2634])\n",
      "Reward: -22.0186824798584\n",
      "Discounted Reward: -2.3177945613861084\n",
      "Current pose: tensor([3.0885, 3.1002, 1.6710, 1.6419, 3.0664, 2.9955, 3.1165, 3.1173])\n",
      "Action: tensor([3.0885, 3.1002, 1.6710, 1.6419, 3.0664, 2.9955, 3.1165, 3.1173])\n",
      "Next pose: tensor([6.1770, 6.2004, 3.3420, 3.2838, 6.1328, 5.9909, 6.2330, 6.2347])\n",
      "Reward: -22.008344650268555\n",
      "Discounted Reward: -2.29353928565979\n",
      "Current pose: tensor([3.1327, 3.0721, 1.6835, 1.6638, 3.0715, 2.9878, 3.1112, 3.1264])\n",
      "Action: tensor([3.1327, 3.0721, 1.6835, 1.6638, 3.0715, 2.9878, 3.1112, 3.1264])\n",
      "Next pose: tensor([6.2654, 6.1443, 3.3670, 3.3275, 6.1430, 5.9755, 6.2224, 6.2527])\n",
      "Reward: -22.11149787902832\n",
      "Discounted Reward: -2.2812459468841553\n",
      "Current pose: tensor([3.0718, 3.0990, 1.6614, 1.6489, 3.0686, 2.9969, 3.1022, 3.1232])\n",
      "Action: tensor([3.0718, 3.0990, 1.6614, 1.6489, 3.0686, 2.9969, 3.1022, 3.1232])\n",
      "Next pose: tensor([6.1436, 6.1980, 3.3227, 3.2977, 6.1371, 5.9938, 6.2044, 6.2464])\n",
      "Reward: -21.95748519897461\n",
      "Discounted Reward: -2.2427029609680176\n",
      "Current pose: tensor([3.0596, 3.0780, 1.6585, 1.6320, 3.0708, 2.9973, 3.1024, 3.1184])\n",
      "Action: tensor([3.0596, 3.0780, 1.6585, 1.6320, 3.0708, 2.9973, 3.1024, 3.1184])\n",
      "Next pose: tensor([6.1192, 6.1559, 3.3170, 3.2640, 6.1417, 5.9945, 6.2047, 6.2368])\n",
      "Reward: -21.847524642944336\n",
      "Discounted Reward: -2.2091572284698486\n",
      "Current pose: tensor([3.0631, 3.0583, 1.6475, 1.6072, 3.0748, 3.0001, 3.0980, 3.1161])\n",
      "Action: tensor([3.0631, 3.0583, 1.6475, 1.6072, 3.0748, 3.0001, 3.0980, 3.1161])\n",
      "Next pose: tensor([6.1263, 6.1165, 3.2949, 3.2145, 6.1496, 6.0002, 6.1960, 6.2322])\n",
      "Reward: -21.743850708007812\n",
      "Discounted Reward: -2.176687240600586\n",
      "Current pose: tensor([3.0861, 3.0912, 1.6574, 1.6369, 3.0779, 3.0015, 3.0986, 3.1088])\n",
      "Action: tensor([3.0861, 3.0912, 1.6574, 1.6369, 3.0779, 3.0015, 3.0986, 3.1088])\n",
      "Next pose: tensor([6.1723, 6.1823, 3.3147, 3.2738, 6.1558, 6.0030, 6.1973, 6.2176])\n",
      "Reward: -21.93037223815918\n",
      "Discounted Reward: -2.173405408859253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pose: tensor([3.0507, 3.0753, 1.6474, 1.6337, 3.0775, 3.0012, 3.1034, 3.1068])\n",
      "Action: tensor([3.0507, 3.0753, 1.6474, 1.6337, 3.0775, 3.0012, 3.1034, 3.1068])\n",
      "Next pose: tensor([6.1013, 6.1505, 3.2948, 3.2674, 6.1550, 6.0024, 6.2069, 6.2137])\n",
      "Reward: -21.805580139160156\n",
      "Discounted Reward: -2.139427661895752\n",
      "Current pose: tensor([3.0664, 2.9934, 1.6589, 1.5936, 3.0763, 3.0016, 3.1046, 3.1164])\n",
      "Action: tensor([3.0664, 2.9934, 1.6589, 1.5936, 3.0763, 3.0016, 3.1046, 3.1164])\n",
      "Next pose: tensor([6.1328, 5.9868, 3.3178, 3.1872, 6.1525, 6.0033, 6.2091, 6.2328])\n",
      "Reward: -21.6359920501709\n",
      "Discounted Reward: -2.1015608310699463\n",
      "Current pose: tensor([3.1173, 3.0742, 1.6734, 1.6474, 3.0744, 2.9995, 3.1052, 3.1246])\n",
      "Action: tensor([3.1173, 3.0742, 1.6734, 1.6474, 3.0744, 2.9995, 3.1052, 3.1246])\n",
      "Next pose: tensor([6.2347, 6.1483, 3.3467, 3.2947, 6.1489, 5.9989, 6.2105, 6.2491])\n",
      "Reward: -22.04558753967285\n",
      "Discounted Reward: -2.1199324131011963\n",
      "Current pose: tensor([3.0574, 3.0342, 1.6404, 1.6137, 3.0635, 3.0066, 3.1198, 3.1246])\n",
      "Action: tensor([3.0574, 3.0342, 1.6404, 1.6137, 3.0635, 3.0066, 3.1198, 3.1246])\n",
      "Next pose: tensor([6.1148, 6.0685, 3.2807, 3.2274, 6.1270, 6.0131, 6.2395, 6.2492])\n",
      "Reward: -21.73398208618164\n",
      "Discounted Reward: -2.069068431854248\n",
      "Current pose: tensor([3.0261, 3.0587, 1.6381, 1.6399, 3.0660, 3.0036, 3.1192, 3.1323])\n",
      "Action: tensor([3.0261, 3.0587, 1.6381, 1.6399, 3.0660, 3.0036, 3.1192, 3.1323])\n",
      "Next pose: tensor([6.0522, 6.1173, 3.2761, 3.2797, 6.1320, 6.0073, 6.2383, 6.2647])\n",
      "Reward: -21.78131103515625\n",
      "Discounted Reward: -2.0528383255004883\n",
      "Current pose: tensor([3.0351, 3.0959, 1.6479, 1.6681, 3.0669, 3.0042, 3.1154, 3.1385])\n",
      "Action: tensor([3.0351, 3.0959, 1.6479, 1.6681, 3.0669, 3.0042, 3.1154, 3.1385])\n",
      "Next pose: tensor([6.0701, 6.1918, 3.2959, 3.3363, 6.1338, 6.0085, 6.2308, 6.2769])\n",
      "Reward: -21.957786560058594\n",
      "Discounted Reward: -2.0487759113311768\n",
      "Current pose: tensor([3.0303, 3.0858, 1.6603, 1.6623, 3.0666, 3.0068, 3.1152, 3.1378])\n",
      "Action: tensor([3.0303, 3.0858, 1.6603, 1.6623, 3.0666, 3.0068, 3.1152, 3.1378])\n",
      "Next pose: tensor([6.0605, 6.1716, 3.3206, 3.3246, 6.1332, 6.0136, 6.2303, 6.2756])\n",
      "Reward: -21.943679809570312\n",
      "Discounted Reward: -2.0269851684570312\n",
      "Current pose: tensor([3.0461, 3.1034, 1.6787, 1.6800, 3.0640, 3.0053, 3.1134, 3.1388])\n",
      "Action: tensor([3.0461, 3.1034, 1.6787, 1.6800, 3.0640, 3.0053, 3.1134, 3.1388])\n",
      "Next pose: tensor([6.0923, 6.2068, 3.3573, 3.3600, 6.1281, 6.0106, 6.2268, 6.2775])\n",
      "Reward: -22.073165893554688\n",
      "Discounted Reward: -2.018556594848633\n",
      "Current pose: tensor([3.0609, 3.0977, 1.6847, 1.6730, 3.0646, 3.0031, 3.1123, 3.1409])\n",
      "Action: tensor([3.0609, 3.0977, 1.6847, 1.6730, 3.0646, 3.0031, 3.1123, 3.1409])\n",
      "Next pose: tensor([6.1218, 6.1954, 3.3694, 3.3460, 6.1292, 6.0062, 6.2247, 6.2818])\n",
      "Reward: -22.08806610107422\n",
      "Discounted Reward: -1.9997199773788452\n",
      "Current pose: tensor([3.0537, 3.1337, 1.6769, 1.6924, 3.0661, 3.0057, 3.1080, 3.1397])\n",
      "Action: tensor([3.0537, 3.1337, 1.6769, 1.6924, 3.0661, 3.0057, 3.1080, 3.1397])\n",
      "Next pose: tensor([6.1074, 6.2674, 3.3538, 3.3848, 6.1322, 6.0115, 6.2160, 6.2795])\n",
      "Reward: -22.16636848449707\n",
      "Discounted Reward: -1.986741065979004\n",
      "Current pose: tensor([3.0373, 3.1053, 1.6658, 1.7133, 3.0659, 3.0038, 3.1092, 3.1384])\n",
      "Action: tensor([3.0373, 3.1053, 1.6658, 1.7133, 3.0659, 3.0038, 3.1092, 3.1384])\n",
      "Next pose: tensor([6.0746, 6.2105, 3.3316, 3.4266, 6.1318, 6.0076, 6.2184, 6.2767])\n",
      "Reward: -22.09149932861328\n",
      "Discounted Reward: -1.9602302312850952\n",
      "Current pose: tensor([3.0145, 3.1120, 1.6632, 1.7109, 3.0648, 3.0075, 3.1068, 3.1388])\n",
      "Action: tensor([3.0145, 3.1120, 1.6632, 1.7109, 3.0648, 3.0075, 3.1068, 3.1388])\n",
      "Next pose: tensor([6.0290, 6.2241, 3.3264, 3.4218, 6.1296, 6.0151, 6.2137, 6.2776])\n",
      "Reward: -22.050823211669922\n",
      "Discounted Reward: -1.9370548725128174\n",
      "Current pose: tensor([3.0044, 3.1289, 1.6638, 1.7437, 3.0633, 3.0121, 3.1086, 3.1357])\n",
      "Action: tensor([3.0044, 3.1289, 1.6638, 1.7437, 3.0633, 3.0121, 3.1086, 3.1357])\n",
      "Next pose: tensor([6.0088, 6.2578, 3.3277, 3.4874, 6.1266, 6.0242, 6.2172, 6.2713])\n",
      "Reward: -22.134830474853516\n",
      "Discounted Reward: -1.9249900579452515\n",
      "Current pose: tensor([2.9550, 3.1124, 1.6349, 1.6955, 3.0614, 3.0096, 3.1154, 3.1292])\n",
      "Action: tensor([2.9550, 3.1124, 1.6349, 1.6955, 3.0614, 3.0096, 3.1154, 3.1292])\n",
      "Next pose: tensor([5.9101, 6.2247, 3.2698, 3.3910, 6.1228, 6.0192, 6.2308, 6.2585])\n",
      "Reward: -21.840497970581055\n",
      "Discounted Reward: -1.8803989887237549\n",
      "Current pose: tensor([2.9939, 3.1288, 1.6590, 1.7159, 3.0573, 3.0064, 3.1271, 3.1164])\n",
      "Action: tensor([2.9939, 3.1288, 1.6590, 1.7159, 3.0573, 3.0064, 3.1271, 3.1164])\n",
      "Next pose: tensor([5.9878, 6.2576, 3.3181, 3.4319, 6.1145, 6.0128, 6.2542, 6.2327])\n",
      "Reward: -22.02334213256836\n",
      "Discounted Reward: -1.8771798610687256\n",
      "Current pose: tensor([3.0229, 3.1093, 1.6567, 1.7042, 3.0555, 3.0045, 3.1358, 3.1085])\n",
      "Action: tensor([3.0229, 3.1093, 1.6567, 1.7042, 3.0555, 3.0045, 3.1358, 3.1085])\n",
      "Next pose: tensor([6.0457, 6.2187, 3.3134, 3.4084, 6.1109, 6.0090, 6.2715, 6.2169])\n",
      "Reward: -22.008344650268555\n",
      "Discounted Reward: -1.8571425676345825\n",
      "Current pose: tensor([3.0363, 3.1044, 1.6629, 1.6897, 3.0537, 3.0048, 3.1393, 3.1056])\n",
      "Action: tensor([3.0363, 3.1044, 1.6629, 1.6897, 3.0537, 3.0048, 3.1393, 3.1056])\n",
      "Next pose: tensor([6.0726, 6.2088, 3.3259, 3.3794, 6.1074, 6.0096, 6.2786, 6.2112])\n",
      "Reward: -22.007089614868164\n",
      "Discounted Reward: -1.8384664058685303\n",
      "Current pose: tensor([3.0291, 3.1103, 1.6733, 1.7036, 3.0420, 3.0087, 3.1263, 3.1029])\n",
      "Action: tensor([3.0291, 3.1103, 1.6733, 1.7036, 3.0420, 3.0087, 3.1263, 3.1029])\n",
      "Next pose: tensor([6.0582, 6.2206, 3.3466, 3.4072, 6.0841, 6.0174, 6.2526, 6.2058])\n",
      "Reward: -22.006145477294922\n",
      "Discounted Reward: -1.820003628730774\n",
      "Current pose: tensor([3.0119, 3.1158, 1.6527, 1.7004, 3.0495, 3.0093, 3.1383, 3.1005])\n",
      "Action: tensor([3.0119, 3.1158, 1.6527, 1.7004, 3.0495, 3.0093, 3.1383, 3.1005])\n",
      "Next pose: tensor([6.0238, 6.2317, 3.3054, 3.4009, 6.0991, 6.0186, 6.2766, 6.2010])\n",
      "Reward: -21.970836639404297\n",
      "Discounted Reward: -1.7989126443862915\n",
      "Current pose: tensor([3.0007, 3.1342, 1.6396, 1.7086, 3.0474, 3.0123, 3.1332, 3.1009])\n",
      "Action: tensor([3.0007, 3.1342, 1.6396, 1.7086, 3.0474, 3.0123, 3.1332, 3.1009])\n",
      "Next pose: tensor([6.0014, 6.2684, 3.2793, 3.4172, 6.0948, 6.0245, 6.2665, 6.2018])\n",
      "Reward: -21.967605590820312\n",
      "Discounted Reward: -1.7806615829467773\n",
      "Current pose: tensor([2.9821, 3.1129, 1.6351, 1.6842, 3.0470, 3.0081, 3.1322, 3.1010])\n",
      "Action: tensor([2.9821, 3.1129, 1.6351, 1.6842, 3.0470, 3.0081, 3.1322, 3.1010])\n",
      "Next pose: tensor([5.9643, 6.2258, 3.2702, 3.3683, 6.0939, 6.0162, 6.2644, 6.2020])\n",
      "Reward: -21.81878662109375\n",
      "Discounted Reward: -1.7509124279022217\n",
      "Current pose: tensor([3.0002, 3.1070, 1.6411, 1.6948, 3.0468, 3.0072, 3.1279, 3.1070])\n",
      "Action: tensor([3.0002, 3.1070, 1.6411, 1.6948, 3.0468, 3.0072, 3.1279, 3.1070])\n",
      "Next pose: tensor([6.0003, 6.2141, 3.2822, 3.3895, 6.0936, 6.0145, 6.2559, 6.2140])\n",
      "Reward: -21.877788543701172\n",
      "Discounted Reward: -1.7380907535552979\n",
      "Current pose: tensor([2.9937, 3.0856, 1.6416, 1.6819, 3.0497, 3.0074, 3.1283, 3.1060])\n",
      "Action: tensor([2.9937, 3.0856, 1.6416, 1.6819, 3.0497, 3.0074, 3.1283, 3.1060])\n",
      "Next pose: tensor([5.9873, 6.1713, 3.2832, 3.3638, 6.0994, 6.0148, 6.2566, 6.2121])\n",
      "Reward: -21.80221939086914\n",
      "Discounted Reward: -1.714766263961792\n",
      "Current pose: tensor([3.0110, 3.1068, 1.6622, 1.6910, 3.0502, 3.0065, 3.1294, 3.1075])\n",
      "Action: tensor([3.0110, 3.1068, 1.6622, 1.6910, 3.0502, 3.0065, 3.1294, 3.1075])\n",
      "Next pose: tensor([6.0220, 6.2136, 3.3244, 3.3821, 6.1004, 6.0129, 6.2587, 6.2150])\n",
      "Reward: -21.942779541015625\n",
      "Discounted Reward: -1.7085633277893066\n",
      "Current pose: tensor([3.0022, 3.0998, 1.6505, 1.6878, 3.0536, 3.0045, 3.1369, 3.1068])\n",
      "Action: tensor([3.0022, 3.0998, 1.6505, 1.6878, 3.0536, 3.0045, 3.1369, 3.1068])\n",
      "Next pose: tensor([6.0044, 6.1996, 3.3011, 3.3756, 6.1071, 6.0090, 6.2738, 6.2136])\n",
      "Reward: -21.89788055419922\n",
      "Discounted Reward: -1.688016653060913\n",
      "Current pose: tensor([3.0052, 3.1039, 1.6517, 1.6794, 3.0553, 3.0005, 3.1362, 3.1089])\n",
      "Action: tensor([3.0052, 3.1039, 1.6517, 1.6794, 3.0553, 3.0005, 3.1362, 3.1089])\n",
      "Next pose: tensor([6.0105, 6.2079, 3.3034, 3.3588, 6.1107, 6.0009, 6.2725, 6.2177])\n",
      "Reward: -21.89612579345703\n",
      "Discounted Reward: -1.6710025072097778\n",
      "Current pose: tensor([3.0018, 3.0982, 1.6494, 1.6753, 3.0557, 3.0005, 3.1365, 3.1094])\n",
      "Action: tensor([3.0018, 3.0982, 1.6494, 1.6753, 3.0557, 3.0005, 3.1365, 3.1094])\n",
      "Next pose: tensor([6.0035, 6.1965, 3.2989, 3.3505, 6.1113, 6.0009, 6.2730, 6.2187])\n",
      "Reward: -21.86707305908203\n",
      "Discounted Reward: -1.6520975828170776\n",
      "Current pose: tensor([3.0145, 3.1128, 1.6585, 1.6773, 3.0572, 3.0007, 3.1358, 3.1078])\n",
      "Action: tensor([3.0145, 3.1128, 1.6585, 1.6773, 3.0572, 3.0007, 3.1358, 3.1078])\n",
      "Next pose: tensor([6.0290, 6.2256, 3.3169, 3.3546, 6.1145, 6.0013, 6.2715, 6.2156])\n",
      "Reward: -21.942760467529297\n",
      "Discounted Reward: -1.641237735748291\n",
      "Current pose: tensor([3.0098, 3.1173, 1.6584, 1.6821, 3.0582, 2.9966, 3.1376, 3.1040])\n",
      "Action: tensor([3.0098, 3.1173, 1.6584, 1.6821, 3.0582, 2.9966, 3.1376, 3.1040])\n",
      "Next pose: tensor([6.0196, 6.2347, 3.3168, 3.3641, 6.1164, 5.9933, 6.2752, 6.2081])\n",
      "Reward: -21.94184684753418\n",
      "Discounted Reward: -1.6247576475143433\n",
      "Current pose: tensor([3.0062, 3.1343, 1.6646, 1.7050, 3.0803, 2.9918, 3.1015, 3.1207])\n",
      "Action: tensor([3.0062, 3.1343, 1.6646, 1.7050, 3.0803, 2.9918, 3.1015, 3.1207])\n",
      "Next pose: tensor([6.0125, 6.2686, 3.3291, 3.4101, 6.1605, 5.9836, 6.2030, 6.2415])\n",
      "Reward: -22.022655487060547\n",
      "Discounted Reward: -1.614434003829956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pose: tensor([3.0906, 2.8592, 1.6889, 1.8555, 3.1006, 2.9885, 3.0877, 3.1397])\n",
      "Action: tensor([3.0906, 2.8592, 1.6889, 1.8555, 3.1006, 2.9885, 3.0877, 3.1397])\n",
      "Next pose: tensor([6.1813, 5.7184, 3.3777, 3.7109, 6.2012, 5.9771, 6.1753, 6.2793])\n",
      "Reward: -22.035018920898438\n",
      "Discounted Reward: -1.5991867780685425\n",
      "Current pose: tensor([3.1219, 3.0904, 1.7694, 1.7116, 3.0995, 2.9935, 3.0829, 3.1255])\n",
      "Action: tensor([3.1219, 3.0904, 1.7694, 1.7116, 3.0995, 2.9935, 3.0829, 3.1255])\n",
      "Next pose: tensor([6.2439, 6.1808, 3.5387, 3.4232, 6.1990, 5.9871, 6.1658, 6.2511])\n",
      "Reward: -22.403099060058594\n",
      "Discounted Reward: -1.609641194343567\n",
      "Current pose: tensor([3.1409, 3.0966, 1.7423, 1.6825, 3.0944, 2.9914, 3.0907, 3.1315])\n",
      "Action: tensor([3.1409, 3.0966, 1.7423, 1.6825, 3.0944, 2.9914, 3.0907, 3.1315])\n",
      "Next pose: tensor([6.2818, 6.1931, 3.4847, 3.3650, 6.1888, 5.9828, 6.1813, 6.2630])\n",
      "Reward: -22.354267120361328\n",
      "Discounted Reward: -1.5900713205337524\n",
      "Current pose: tensor([3.0365, 3.0542, 1.6945, 1.6740, 3.0820, 3.0089, 3.0981, 3.1125])\n",
      "Action: tensor([3.0365, 3.0542, 1.6945, 1.6740, 3.0820, 3.0089, 3.0981, 3.1125])\n",
      "Next pose: tensor([6.0731, 6.1084, 3.3890, 3.3480, 6.1640, 6.0178, 6.1962, 6.2250])\n",
      "Reward: -21.935131072998047\n",
      "Discounted Reward: -1.5446553230285645\n",
      "Current pose: tensor([3.0065, 3.0349, 1.6840, 1.6604, 3.0780, 3.0097, 3.1004, 3.1191])\n",
      "Action: tensor([3.0065, 3.0349, 1.6840, 1.6604, 3.0780, 3.0097, 3.1004, 3.1191])\n",
      "Next pose: tensor([6.0131, 6.0698, 3.3680, 3.3209, 6.1561, 6.0195, 6.2008, 6.2382])\n",
      "Reward: -21.79994010925293\n",
      "Discounted Reward: -1.5197839736938477\n",
      "Current pose: tensor([3.1126, 3.0225, 1.7364, 1.6803, 3.0818, 2.9929, 3.1019, 3.1402])\n",
      "Action: tensor([3.1126, 3.0225, 1.7364, 1.6803, 3.0818, 2.9929, 3.1019, 3.1402])\n",
      "Next pose: tensor([6.2253, 6.0450, 3.4727, 3.3606, 6.1636, 5.9858, 6.2037, 6.2804])\n",
      "Reward: -22.15089225769043\n",
      "Discounted Reward: -1.5288081169128418\n",
      "Current pose: tensor([3.0678, 3.0100, 1.7640, 1.6829, 3.0736, 2.9919, 3.1093, 3.1364])\n",
      "Action: tensor([3.0678, 3.0100, 1.7640, 1.6829, 3.0736, 2.9919, 3.1093, 3.1364])\n",
      "Next pose: tensor([6.1355, 6.0199, 3.5281, 3.3658, 6.1471, 5.9837, 6.2186, 6.2727])\n",
      "Reward: -22.085115432739258\n",
      "Discounted Reward: -1.5090256929397583\n",
      "Current pose: tensor([3.0777, 2.9997, 1.7309, 1.6413, 3.0780, 2.9971, 3.1082, 3.1309])\n",
      "Action: tensor([3.0777, 2.9997, 1.7309, 1.6413, 3.0780, 2.9971, 3.1082, 3.1309])\n",
      "Next pose: tensor([6.1554, 5.9993, 3.4617, 3.2826, 6.1559, 5.9942, 6.2165, 6.2619])\n",
      "Reward: -21.941301345825195\n",
      "Discounted Reward: -1.4842071533203125\n",
      "Current pose: tensor([3.1312, 2.8777, 1.7134, 1.5647, 3.0721, 3.0032, 3.1140, 3.1292])\n",
      "Action: tensor([3.1312, 2.8777, 1.7134, 1.5647, 3.0721, 3.0032, 3.1140, 3.1292])\n",
      "Next pose: tensor([6.2624, 5.7553, 3.4267, 3.1293, 6.1442, 6.0064, 6.2280, 6.2584])\n",
      "Reward: -21.62452507019043\n",
      "Discounted Reward: -1.4481512308120728\n",
      "Current pose: tensor([3.1258, 3.0680, 1.7014, 1.6535, 3.0725, 3.0079, 3.1131, 3.1153])\n",
      "Action: tensor([3.1258, 3.0680, 1.7014, 1.6535, 3.0725, 3.0079, 3.1131, 3.1153])\n",
      "Next pose: tensor([6.2517, 6.1361, 3.4028, 3.3070, 6.1450, 6.0158, 6.2262, 6.2306])\n",
      "Reward: -22.128915786743164\n",
      "Discounted Reward: -1.4671099185943604\n",
      "Current pose: tensor([3.1027, 3.0517, 1.6574, 1.6248, 3.0791, 2.9992, 3.1114, 3.1226])\n",
      "Action: tensor([3.1027, 3.0517, 1.6574, 1.6248, 3.0791, 2.9992, 3.1114, 3.1226])\n",
      "Next pose: tensor([6.2054, 6.1035, 3.3147, 3.2496, 6.1583, 5.9984, 6.2229, 6.2453])\n",
      "Reward: -21.911693572998047\n",
      "Discounted Reward: -1.4381814002990723\n",
      "Current pose: tensor([3.1079, 2.9809, 1.6809, 1.5770, 3.0800, 2.9998, 3.1117, 3.1122])\n",
      "Action: tensor([3.1079, 2.9809, 1.6809, 1.5770, 3.0800, 2.9998, 3.1117, 3.1122])\n",
      "Next pose: tensor([6.2159, 5.9618, 3.3619, 3.1540, 6.1600, 5.9995, 6.2235, 6.2244])\n",
      "Reward: -21.714702606201172\n",
      "Discounted Reward: -1.4109994173049927\n",
      "Current pose: tensor([3.1360, 2.9715, 1.6530, 1.5573, 3.0807, 2.9955, 3.1114, 3.1092])\n",
      "Action: tensor([3.1360, 2.9715, 1.6530, 1.5573, 3.0807, 2.9955, 3.1114, 3.1092])\n",
      "Next pose: tensor([6.2721, 5.9431, 3.3060, 3.1147, 6.1615, 5.9910, 6.2228, 6.2184])\n",
      "Reward: -21.643173217773438\n",
      "Discounted Reward: -1.3922879695892334\n",
      "Current pose: tensor([3.0597, 3.0218, 1.5810, 1.4670, 3.0809, 2.9840, 3.1223, 3.1122])\n",
      "Action: tensor([3.0597, 3.0218, 1.5810, 1.4670, 3.0809, 2.9840, 3.1223, 3.1122])\n",
      "Next pose: tensor([6.1194, 6.0436, 3.1621, 2.9340, 6.1618, 5.9679, 6.2446, 6.2244])\n",
      "Reward: -21.271530151367188\n",
      "Discounted Reward: -1.3546966314315796\n",
      "Current pose: tensor([3.0716, 3.0231, 1.5031, 1.3561, 3.0634, 2.9872, 3.1333, 3.1070])\n",
      "Action: tensor([3.0716, 3.0231, 1.5031, 1.3561, 3.0634, 2.9872, 3.1333, 3.1070])\n",
      "Next pose: tensor([6.1433, 6.0461, 3.0063, 2.7123, 6.1268, 5.9745, 6.2666, 6.2141])\n",
      "Reward: -20.903642654418945\n",
      "Discounted Reward: -1.3179547786712646\n",
      "Current pose: tensor([3.1411, 3.0052, 1.3783, 1.2826, 3.0533, 2.9895, 3.1369, 3.1043])\n",
      "Action: tensor([3.1411, 3.0052, 1.3783, 1.2826, 3.0533, 2.9895, 3.1369, 3.1043])\n",
      "Next pose: tensor([6.2822, 6.0105, 2.7566, 2.5652, 6.1067, 5.9791, 6.2737, 6.2085])\n",
      "Reward: -20.596141815185547\n",
      "Discounted Reward: -1.285581350326538\n",
      "Current pose: tensor([3.1224, 3.0276, 1.3057, 1.1865, 3.0530, 2.9921, 3.1350, 3.1026])\n",
      "Action: tensor([3.1224, 3.0276, 1.3057, 1.1865, 3.0530, 2.9921, 3.1350, 3.1026])\n",
      "Next pose: tensor([6.2449, 6.0552, 2.6114, 2.3731, 6.1059, 5.9842, 6.2700, 6.2051])\n",
      "Reward: -20.263408660888672\n",
      "Discounted Reward: -1.252164602279663\n",
      "Current pose: tensor([3.0680, 3.0018, 1.2375, 1.1023, 3.0347, 2.9979, 3.1399, 3.1117])\n",
      "Action: tensor([3.0680, 3.0018, 1.2375, 1.1023, 3.0347, 2.9979, 3.1399, 3.1117])\n",
      "Next pose: tensor([6.1360, 6.0036, 2.4750, 2.2046, 6.0694, 5.9957, 6.2797, 6.2234])\n",
      "Reward: -19.80106544494629\n",
      "Discounted Reward: -1.2113584280014038\n",
      "Current pose: tensor([3.0157, 3.0151, 1.1833, 1.0530, 3.0309, 3.0008, 3.1374, 3.1081])\n",
      "Action: tensor([3.0157, 3.0151, 1.1833, 1.0530, 3.0309, 3.0008, 3.1374, 3.1081])\n",
      "Next pose: tensor([6.0314, 6.0303, 2.3666, 2.1060, 6.0619, 6.0016, 6.2748, 6.2163])\n",
      "Reward: -19.50245475769043\n",
      "Discounted Reward: -1.181159496307373\n",
      "Current pose: tensor([3.0318, 3.0203, 1.1614, 1.0015, 3.0334, 3.0089, 3.1351, 3.1065])\n",
      "Action: tensor([3.0318, 3.0203, 1.1614, 1.0015, 3.0334, 3.0089, 3.1351, 3.1065])\n",
      "Next pose: tensor([6.0635, 6.0407, 2.3228, 2.0029, 6.0668, 6.0179, 6.2702, 6.2131])\n",
      "Reward: -19.411701202392578\n",
      "Discounted Reward: -1.163906455039978\n",
      "Current pose: tensor([3.0455, 3.0601, 1.1637, 0.9770, 3.0306, 3.0134, 3.1343, 3.1045])\n",
      "Action: tensor([3.0455, 3.0601, 1.1637, 0.9770, 3.0306, 3.0134, 3.1343, 3.1045])\n",
      "Next pose: tensor([6.0909, 6.1201, 2.3273, 1.9540, 6.0613, 6.0268, 6.2686, 6.2091])\n",
      "Reward: -19.4717960357666\n",
      "Discounted Reward: -1.1558345556259155\n",
      "Current pose: tensor([3.0303, 3.0537, 1.1662, 0.9717, 3.0234, 3.0198, 3.1372, 3.1016])\n",
      "Action: tensor([3.0303, 3.0537, 1.1662, 0.9717, 3.0234, 3.0198, 3.1372, 3.1016])\n",
      "Next pose: tensor([6.0606, 6.1074, 2.3324, 1.9433, 6.0469, 6.0395, 6.2745, 6.2032])\n",
      "Reward: -19.42138671875\n",
      "Discounted Reward: -1.141313910484314\n",
      "Current pose: tensor([2.9735, 3.0420, 1.1449, 0.9772, 3.0309, 3.0203, 3.1326, 3.1004])\n",
      "Action: tensor([2.9735, 3.0420, 1.1449, 0.9772, 3.0309, 3.0203, 3.1326, 3.1004])\n",
      "Next pose: tensor([5.9471, 6.0840, 2.2897, 1.9544, 6.0618, 6.0407, 6.2651, 6.2007])\n",
      "Reward: -19.257360458374023\n",
      "Discounted Reward: -1.1203579902648926\n",
      "Current pose: tensor([3.0542, 3.0216, 1.1781, 0.9806, 3.0396, 3.0164, 3.1303, 3.1026])\n",
      "Action: tensor([3.0542, 3.0216, 1.1781, 0.9806, 3.0396, 3.0164, 3.1303, 3.1026])\n",
      "Next pose: tensor([6.1083, 6.0432, 2.3563, 1.9613, 6.0792, 6.0327, 6.2605, 6.2052])\n",
      "Reward: -19.46041488647461\n",
      "Discounted Reward: -1.120849609375\n",
      "Current pose: tensor([3.0848, 3.0208, 1.2390, 0.9901, 3.0414, 3.0174, 3.1316, 3.1009])\n",
      "Action: tensor([3.0848, 3.0208, 1.2390, 0.9901, 3.0414, 3.0174, 3.1316, 3.1009])\n",
      "Next pose: tensor([6.1695, 6.0415, 2.4781, 1.9802, 6.0828, 6.0347, 6.2632, 6.2018])\n",
      "Reward: -19.665491104125977\n",
      "Discounted Reward: -1.1213346719741821\n",
      "Current pose: tensor([3.0428, 3.0347, 1.2939, 1.0502, 3.0438, 3.0166, 3.1268, 3.1002])\n",
      "Action: tensor([3.0428, 3.0347, 1.2939, 1.0502, 3.0438, 3.0166, 3.1268, 3.1002])\n",
      "Next pose: tensor([6.0855, 6.0694, 2.5878, 2.1005, 6.0876, 6.0331, 6.2536, 6.2004])\n",
      "Reward: -19.83165740966797\n",
      "Discounted Reward: -1.1195014715194702\n",
      "Current pose: tensor([3.1370, 2.9730, 1.3988, 1.0784, 3.0460, 3.0204, 3.1232, 3.1006])\n",
      "Action: tensor([3.1370, 2.9730, 1.3988, 1.0784, 3.0460, 3.0204, 3.1232, 3.1006])\n",
      "Next pose: tensor([6.2740, 5.9460, 2.7976, 2.1568, 6.0920, 6.0407, 6.2465, 6.2012])\n",
      "Reward: -20.1685848236084\n",
      "Discounted Reward: -1.1271358728408813\n",
      "Current pose: tensor([3.1296, 2.9215, 1.4691, 1.1396, 3.0436, 3.0289, 3.1214, 3.0958])\n",
      "Action: tensor([3.1296, 2.9215, 1.4691, 1.1396, 3.0436, 3.0289, 3.1214, 3.0958])\n",
      "Next pose: tensor([6.2592, 5.8430, 2.9382, 2.2793, 6.0871, 6.0579, 6.2427, 6.1915])\n",
      "Reward: -20.31269073486328\n",
      "Discounted Reward: -1.1238374710083008\n",
      "Current pose: tensor([3.1397, 2.9456, 1.5135, 1.2493, 3.0477, 3.0247, 3.1156, 3.0978])\n",
      "Action: tensor([3.1397, 2.9456, 1.5135, 1.2493, 3.0477, 3.0247, 3.1156, 3.0978])\n",
      "Next pose: tensor([6.2795, 5.8912, 3.0271, 2.4986, 6.0954, 6.0494, 6.2311, 6.1956])\n",
      "Reward: -20.681562423706055\n",
      "Discounted Reward: -1.1328035593032837\n",
      "Current pose: tensor([3.1364, 2.9383, 1.5514, 1.3009, 3.0501, 3.0239, 3.1120, 3.1001])\n",
      "Action: tensor([3.1364, 2.9383, 1.5514, 1.3009, 3.0501, 3.0239, 3.1120, 3.1001])\n",
      "Next pose: tensor([6.2729, 5.8767, 3.1028, 2.6018, 6.1002, 6.0478, 6.2239, 6.2002])\n",
      "Reward: -20.840017318725586\n",
      "Discounted Reward: -1.1300678253173828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pose: tensor([3.0686, 2.9238, 1.5499, 1.3633, 3.0500, 3.0257, 3.1117, 3.1033])\n",
      "Action: tensor([3.0686, 2.9238, 1.5499, 1.3633, 3.0500, 3.0257, 3.1117, 3.1033])\n",
      "Next pose: tensor([6.1372, 5.8476, 3.0998, 2.7266, 6.1001, 6.0513, 6.2234, 6.2066])\n",
      "Reward: -20.806350708007812\n",
      "Discounted Reward: -1.116959810256958\n",
      "Current pose: tensor([3.0320, 2.9394, 1.5706, 1.4125, 3.0515, 3.0205, 3.1120, 3.1079])\n",
      "Action: tensor([3.0320, 2.9394, 1.5706, 1.4125, 3.0515, 3.0205, 3.1120, 3.1079])\n",
      "Next pose: tensor([6.0639, 5.8788, 3.1412, 2.8250, 6.1029, 6.0410, 6.2239, 6.2158])\n",
      "Reward: -20.90621566772461\n",
      "Discounted Reward: -1.1110976934432983\n",
      "Current pose: tensor([3.0291, 2.9709, 1.5864, 1.4645, 3.0519, 3.0216, 3.1117, 3.1077])\n",
      "Action: tensor([3.0291, 2.9709, 1.5864, 1.4645, 3.0519, 3.0216, 3.1117, 3.1077])\n",
      "Next pose: tensor([6.0582, 5.9418, 3.1729, 2.9291, 6.1039, 6.0431, 6.2234, 6.2154])\n",
      "Reward: -21.10154914855957\n",
      "Discounted Reward: -1.1102643013000488\n",
      "Current pose: tensor([3.1020, 3.0106, 1.6577, 1.4967, 3.0542, 3.0183, 3.1080, 3.1153])\n",
      "Action: tensor([3.1020, 3.0106, 1.6577, 1.4967, 3.0542, 3.0183, 3.1080, 3.1153])\n",
      "Next pose: tensor([6.2041, 6.0212, 3.3155, 2.9935, 6.1084, 6.0366, 6.2161, 6.2306])\n",
      "Reward: -21.539518356323242\n",
      "Discounted Reward: -1.121975064277649\n",
      "Current pose: tensor([3.0733, 3.0822, 1.6284, 1.5552, 3.0522, 3.0198, 3.1081, 3.1193])\n",
      "Action: tensor([3.0733, 3.0822, 1.6284, 1.5552, 3.0522, 3.0198, 3.1081, 3.1193])\n",
      "Next pose: tensor([6.1467, 6.1645, 3.2568, 3.1104, 6.1044, 6.0396, 6.2163, 6.2385])\n",
      "Reward: -21.690879821777344\n",
      "Discounted Reward: -1.118560791015625\n",
      "Current pose: tensor([3.0329, 3.0967, 1.6157, 1.5632, 3.0510, 3.0202, 3.1081, 3.1190])\n",
      "Action: tensor([3.0329, 3.0967, 1.6157, 1.5632, 3.0510, 3.0202, 3.1081, 3.1190])\n",
      "Next pose: tensor([6.0657, 6.1934, 3.2313, 3.1263, 6.1020, 6.0404, 6.2161, 6.2380])\n",
      "Reward: -21.626976013183594\n",
      "Discounted Reward: -1.1041127443313599\n",
      "Current pose: tensor([3.0119, 3.0600, 1.6134, 1.5576, 3.0503, 3.0154, 3.1091, 3.1303])\n",
      "Action: tensor([3.0119, 3.0600, 1.6134, 1.5576, 3.0503, 3.0154, 3.1091, 3.1303])\n",
      "Next pose: tensor([6.0238, 6.1200, 3.2268, 3.1153, 6.1006, 6.0309, 6.2182, 6.2606])\n",
      "Reward: -21.509889602661133\n",
      "Discounted Reward: -1.0871537923812866\n",
      "Current pose: tensor([3.0568, 3.1036, 1.6189, 1.6068, 3.0516, 3.0162, 3.1097, 3.1272])\n",
      "Action: tensor([3.0568, 3.1036, 1.6189, 1.6068, 3.0516, 3.0162, 3.1097, 3.1272])\n",
      "Next pose: tensor([6.1136, 6.2071, 3.2377, 3.2137, 6.1033, 6.0325, 6.2194, 6.2545])\n",
      "Reward: -21.795438766479492\n",
      "Discounted Reward: -1.0905702114105225\n",
      "Current pose: tensor([3.0482, 3.1400, 1.6215, 1.6441, 3.0463, 3.0164, 3.1115, 3.1267])\n",
      "Action: tensor([3.0482, 3.1400, 1.6215, 1.6441, 3.0463, 3.0164, 3.1115, 3.1267])\n",
      "Next pose: tensor([6.0965, 6.2801, 3.2431, 3.2881, 6.0926, 6.0328, 6.2230, 6.2533])\n",
      "Reward: -21.92314910888672\n",
      "Discounted Reward: -1.0859907865524292\n",
      "Current pose: tensor([3.0387, 3.1309, 1.6147, 1.6249, 3.0457, 3.0217, 3.1093, 3.1259])\n",
      "Action: tensor([3.0387, 3.1309, 1.6147, 1.6249, 3.0457, 3.0217, 3.1093, 3.1259])\n",
      "Next pose: tensor([6.0773, 6.2618, 3.2293, 3.2499, 6.0914, 6.0434, 6.2187, 6.2519])\n",
      "Reward: -21.837465286254883\n",
      "Discounted Reward: -1.0709288120269775\n",
      "Current pose: tensor([3.0308, 3.1256, 1.6185, 1.6313, 3.0447, 3.0219, 3.1126, 3.1263])\n",
      "Action: tensor([3.0308, 3.1256, 1.6185, 1.6313, 3.0447, 3.0219, 3.1126, 3.1263])\n",
      "Next pose: tensor([6.0617, 6.2512, 3.2371, 3.2627, 6.0893, 6.0438, 6.2251, 6.2527])\n",
      "Reward: -21.837230682373047\n",
      "Discounted Reward: -1.0602082014083862\n",
      "Current pose: tensor([3.0346, 3.1397, 1.6169, 1.6220, 3.0391, 3.0249, 3.1200, 3.1242])\n",
      "Action: tensor([3.0346, 3.1397, 1.6169, 1.6220, 3.0391, 3.0249, 3.1200, 3.1242])\n",
      "Next pose: tensor([6.0693, 6.2793, 3.2338, 3.2440, 6.0783, 6.0497, 6.2400, 6.2485])\n",
      "Reward: -21.856609344482422\n",
      "Discounted Reward: -1.0505374670028687\n",
      "Current pose: tensor([3.0316, 3.1236, 1.6143, 1.6124, 3.0385, 3.0270, 3.1211, 3.1260])\n",
      "Action: tensor([3.0316, 3.1236, 1.6143, 1.6124, 3.0385, 3.0270, 3.1211, 3.1260])\n",
      "Next pose: tensor([6.0631, 6.2472, 3.2286, 3.2249, 6.0770, 6.0539, 6.2422, 6.2521])\n",
      "Reward: -21.802824020385742\n",
      "Discounted Reward: -1.0374727249145508\n",
      "Current pose: tensor([3.0209, 3.1224, 1.6152, 1.6159, 3.0388, 3.0267, 3.1208, 3.1279])\n",
      "Action: tensor([3.0209, 3.1224, 1.6152, 1.6159, 3.0388, 3.0267, 3.1208, 3.1279])\n",
      "Next pose: tensor([6.0418, 6.2449, 3.2304, 3.2319, 6.0775, 6.0534, 6.2415, 6.2558])\n",
      "Reward: -21.79096031188965\n",
      "Discounted Reward: -1.0265392065048218\n",
      "Current pose: tensor([3.0089, 3.1166, 1.6121, 1.6070, 3.0386, 3.0264, 3.1206, 3.1317])\n",
      "Action: tensor([3.0089, 3.1166, 1.6121, 1.6070, 3.0386, 3.0264, 3.1206, 3.1317])\n",
      "Next pose: tensor([6.0178, 6.2332, 3.2243, 3.2141, 6.0772, 6.0529, 6.2412, 6.2633])\n",
      "Reward: -21.73761749267578\n",
      "Discounted Reward: -1.0137859582901\n",
      "Current pose: tensor([3.0096, 3.1283, 1.6134, 1.6161, 3.0438, 3.0237, 3.1181, 3.1330])\n",
      "Action: tensor([3.0096, 3.1283, 1.6134, 1.6161, 3.0438, 3.0237, 3.1181, 3.1330])\n",
      "Next pose: tensor([6.0193, 6.2566, 3.2268, 3.2321, 6.0876, 6.0473, 6.2362, 6.2661])\n",
      "Reward: -21.78575897216797\n",
      "Discounted Reward: -1.0058709383010864\n",
      "Current pose: tensor([3.0093, 3.1207, 1.6132, 1.6046, 3.0426, 3.0257, 3.1181, 3.1336])\n",
      "Action: tensor([3.0093, 3.1207, 1.6132, 1.6046, 3.0426, 3.0257, 3.1181, 3.1336])\n",
      "Next pose: tensor([6.0185, 6.2414, 3.2264, 3.2091, 6.0852, 6.0514, 6.2361, 6.2671])\n",
      "Reward: -21.74892807006836\n",
      "Discounted Reward: -0.9941287040710449\n",
      "Current pose: tensor([3.0101, 3.1034, 1.6154, 1.6020, 3.0408, 3.0244, 3.1183, 3.1380])\n",
      "Action: tensor([3.0101, 3.1034, 1.6154, 1.6020, 3.0408, 3.0244, 3.1183, 3.1380])\n",
      "Next pose: tensor([6.0202, 6.2069, 3.2308, 3.2040, 6.0817, 6.0489, 6.2366, 6.2760])\n",
      "Reward: -21.718650817871094\n",
      "Discounted Reward: -0.9828172922134399\n",
      "Current pose: tensor([3.0206, 3.0884, 1.5999, 1.6053, 3.0513, 3.0185, 3.1121, 3.1403])\n",
      "Action: tensor([3.0206, 3.0884, 1.5999, 1.6053, 3.0513, 3.0185, 3.1121, 3.1403])\n",
      "Next pose: tensor([6.0413, 6.1767, 3.1997, 3.2106, 6.1026, 6.0371, 6.2242, 6.2806])\n",
      "Reward: -21.686565399169922\n",
      "Discounted Reward: -0.9715517163276672\n",
      "Current pose: tensor([3.0362, 3.1001, 1.6108, 1.6307, 3.0562, 3.0138, 3.1134,    nan])\n",
      "Action: tensor([3.0362, 3.1001, 1.6108, 1.6307, 3.0562, 3.0138, 3.1134,    nan])\n",
      "Next pose: tensor([6.0723, 6.2002, 3.2217, 3.2614, 6.1123, 6.0275, 6.2268,    nan])\n",
      "Reward: nan\n",
      "Discounted Reward: nan\n",
      "Current pose: tensor([3.0504, 3.0717, 1.6053, 1.6181, 3.0587, 3.0121, 3.1131, 3.1409])\n",
      "Action: tensor([3.0504, 3.0717, 1.6053, 1.6181, 3.0587, 3.0121, 3.1131, 3.1409])\n",
      "Next pose: tensor([6.1008, 6.1434, 3.2106, 3.2362, 6.1175, 6.0242, 6.2262, 6.2818])\n",
      "Reward: -21.75429344177246\n",
      "Discounted Reward: -0.9551916718482971\n",
      "Current pose: tensor([3.0318, 3.1071, 1.6070, 1.6480, 3.0581, 3.0088, 3.1157, 3.1406])\n",
      "Action: tensor([3.0318, 3.1071, 1.6070, 1.6480, 3.0581, 3.0088, 3.1157, 3.1406])\n",
      "Next pose: tensor([6.0637, 6.2141, 3.2140, 3.2960, 6.1162, 6.0176, 6.2315, 6.2812])\n",
      "Reward: -21.84809112548828\n",
      "Discounted Reward: -0.9497169852256775\n",
      "Current pose: tensor([3.0586, 3.0816, 1.6167, 1.6468, 3.0646, 3.0040, 3.1113, 3.1411])\n",
      "Action: tensor([3.0586, 3.0816, 1.6167, 1.6468, 3.0646, 3.0040, 3.1113, 3.1411])\n",
      "Next pose: tensor([6.1172, 6.1632, 3.2333, 3.2935, 6.1292, 6.0080, 6.2227, 6.2822])\n",
      "Reward: -21.86298179626465\n",
      "Discounted Reward: -0.9408606290817261\n",
      "Current pose: tensor([3.0828, 3.0980, 1.6167, 1.6694, 3.0779, 2.9948, 3.1118, 3.1401])\n",
      "Action: tensor([3.0828, 3.0980, 1.6167, 1.6694, 3.0779, 2.9948, 3.1118, 3.1401])\n",
      "Next pose: tensor([6.1655, 6.1960, 3.2334, 3.3387, 6.1557, 5.9896, 6.2236, 6.2803])\n",
      "Reward: -21.996532440185547\n",
      "Discounted Reward: -0.9371418356895447\n",
      "Current pose: tensor([3.1139, 3.0340, 1.6463, 1.6438, 3.0814, 2.9940, 3.1079, 3.1396])\n",
      "Action: tensor([3.1139, 3.0340, 1.6463, 1.6438, 3.0814, 2.9940, 3.1079, 3.1396])\n",
      "Next pose: tensor([6.2278, 6.0680, 3.2926, 3.2876, 6.1627, 5.9879, 6.2158, 6.2792])\n",
      "Reward: -21.93532371520996\n",
      "Discounted Reward: -0.9251887798309326\n",
      "Current pose: tensor([3.0835, 3.0642, 1.6317, 1.6418, 3.0790, 2.9966, 3.1108, 3.1416])\n",
      "Action: tensor([3.0835, 3.0642, 1.6317, 1.6418, 3.0790, 2.9966, 3.1108, 3.1416])\n",
      "Next pose: tensor([6.1670, 6.1285, 3.2634, 3.2837, 6.1581, 5.9931, 6.2217, 6.2832])\n",
      "Reward: -21.912389755249023\n",
      "Discounted Reward: -0.9149792194366455\n",
      "Current pose: tensor([3.0785, 3.0665, 1.6119, 1.6564, 3.0808, 2.9990, 3.1080, 3.1337])\n",
      "Action: tensor([3.0785, 3.0665, 1.6119, 1.6564, 3.0808, 2.9990, 3.1080, 3.1337])\n",
      "Next pose: tensor([6.1570, 6.1331, 3.2238, 3.3127, 6.1617, 5.9979, 6.2160, 6.2674])\n",
      "Reward: -21.883338928222656\n",
      "Discounted Reward: -0.904628574848175\n",
      "Current pose: tensor([3.0686, 3.0710, 1.6111, 1.6512, 3.0788, 2.9997, 3.1097, 3.1333])\n",
      "Action: tensor([3.0686, 3.0710, 1.6111, 1.6512, 3.0788, 2.9997, 3.1097, 3.1333])\n",
      "Next pose: tensor([6.1372, 6.1419, 3.2223, 3.3023, 6.1576, 5.9994, 6.2195, 6.2666])\n",
      "Reward: -21.860424041748047\n",
      "Discounted Reward: -0.8946444392204285\n",
      "Current pose: tensor([3.1215, 3.0457, 1.6435, 1.6445, 3.0647, 3.0064, 3.1111, 3.1416])\n",
      "Action: tensor([3.1215, 3.0457, 1.6435, 1.6445, 3.0647, 3.0064, 3.1111, 3.1416])\n",
      "Next pose: tensor([6.2430, 6.0913, 3.2870, 3.2890, 6.1294, 6.0128, 6.2221, 6.2832])\n",
      "Reward: -21.971527099609375\n",
      "Discounted Reward: -0.8901994824409485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pose: tensor([3.0815, 2.9903, 1.6604, 1.6043, 3.0598, 3.0088, 3.1089, 3.1412])\n",
      "Action: tensor([3.0815, 2.9903, 1.6604, 1.6043, 3.0598, 3.0088, 3.1089, 3.1412])\n",
      "Next pose: tensor([6.1630, 5.9806, 3.3208, 3.2086, 6.1196, 6.0175, 6.2178, 6.2825])\n",
      "Reward: -21.724111557006836\n",
      "Discounted Reward: -0.8713733553886414\n",
      "Current pose: tensor([3.0599, 3.0227, 1.6608, 1.6176, 3.0562, 3.0101, 3.1112, 3.1374])\n",
      "Action: tensor([3.0599, 3.0227, 1.6608, 1.6176, 3.0562, 3.0101, 3.1112, 3.1374])\n",
      "Next pose: tensor([6.1198, 6.0455, 3.3216, 3.2351, 6.1124, 6.0201, 6.2223, 6.2747])\n",
      "Reward: -21.765275955200195\n",
      "Discounted Reward: -0.8642943501472473\n",
      "Current pose: tensor([3.0591, 3.0325, 1.6589, 1.6197, 3.0555, 3.0127, 3.1112, 3.1378])\n",
      "Action: tensor([3.0591, 3.0325, 1.6589, 1.6197, 3.0555, 3.0127, 3.1112, 3.1378])\n",
      "Next pose: tensor([6.1183, 6.0649, 3.3177, 3.2394, 6.1109, 6.0254, 6.2224, 6.2756])\n",
      "Reward: -21.78836441040039\n",
      "Discounted Reward: -0.8565589785575867\n",
      "Current pose: tensor([3.0323, 3.0196, 1.6373, 1.6252, 3.0558, 3.0087, 3.1105, 3.1370])\n",
      "Action: tensor([3.0323, 3.0196, 1.6373, 1.6252, 3.0558, 3.0087, 3.1105, 3.1370])\n",
      "Next pose: tensor([6.0645, 6.0392, 3.2747, 3.2503, 6.1116, 6.0175, 6.2210, 6.2739])\n",
      "Reward: -21.666379928588867\n",
      "Discounted Reward: -0.843245804309845\n",
      "Current pose: tensor([3.0356, 2.9582, 1.6069, 1.5883, 3.0559, 3.0079, 3.1149, 3.1368])\n",
      "Action: tensor([3.0356, 2.9582, 1.6069, 1.5883, 3.0559, 3.0079, 3.1149, 3.1368])\n",
      "Next pose: tensor([6.0713, 5.9164, 3.2138, 3.1766, 6.1118, 6.0159, 6.2299, 6.2736])\n",
      "Reward: -21.422883987426758\n",
      "Discounted Reward: -0.8254313468933105\n",
      "Current pose: tensor([3.0575, 2.9981, 1.6432, 1.6366, 3.0642, 3.0073, 3.1115, 3.1416])\n",
      "Action: tensor([3.0575, 2.9981, 1.6432, 1.6366, 3.0642, 3.0073, 3.1115, 3.1416])\n",
      "Next pose: tensor([6.1149, 5.9963, 3.2865, 3.2732, 6.1285, 6.0146, 6.2231, 6.2832])\n",
      "Reward: -21.73396110534668\n",
      "Discounted Reward: -0.8290431499481201\n",
      "Current pose: tensor([3.0638, 3.0158, 1.6094, 1.6510, 3.0685, 3.0110, 3.1160, 3.1248])\n",
      "Action: tensor([3.0638, 3.0158, 1.6094, 1.6510, 3.0685, 3.0110, 3.1160, 3.1248])\n",
      "Next pose: tensor([6.1276, 6.0315, 3.2188, 3.3021, 6.1370, 6.0220, 6.2320, 6.2495])\n",
      "Reward: -21.734230041503906\n",
      "Discounted Reward: -0.8207628130912781\n",
      "Current pose: tensor([3.0548, 3.0820, 1.5987, 1.6483, 3.0675, 3.0168, 3.1181, 3.1102])\n",
      "Action: tensor([3.0548, 3.0820, 1.5987, 1.6483, 3.0675, 3.0168, 3.1181, 3.1102])\n",
      "Next pose: tensor([6.1095, 6.1641, 3.1974, 3.2967, 6.1350, 6.0335, 6.2361, 6.2204])\n",
      "Reward: -21.806442260742188\n",
      "Discounted Reward: -0.8152549266815186\n",
      "Current pose: tensor([3.0847, 3.0759, 1.6179, 1.6379, 3.0611, 3.0202, 3.1238, 3.1053])\n",
      "Action: tensor([3.0847, 3.0759, 1.6179, 1.6379, 3.0611, 3.0202, 3.1238, 3.1053])\n",
      "Next pose: tensor([6.1695, 6.1517, 3.2358, 3.2757, 6.1222, 6.0404, 6.2476, 6.2106])\n",
      "Reward: -21.867216110229492\n",
      "Discounted Reward: -0.8093517422676086\n",
      "Current pose: tensor([3.0819, 3.0775, 1.6241, 1.6548, 3.0615, 3.0199, 3.1205, 3.1058])\n",
      "Action: tensor([3.0819, 3.0775, 1.6241, 1.6548, 3.0615, 3.0199, 3.1205, 3.1058])\n",
      "Next pose: tensor([6.1637, 6.1551, 3.2483, 3.3097, 6.1230, 6.0399, 6.2411, 6.2117])\n",
      "Reward: -21.90609359741211\n",
      "Discounted Reward: -0.8026828169822693\n",
      "Current pose: tensor([3.0662, 3.0750, 1.6208, 1.6634, 3.0655, 3.0175, 3.1150, 3.1054])\n",
      "Action: tensor([3.0662, 3.0750, 1.6208, 1.6634, 3.0655, 3.0175, 3.1150, 3.1054])\n",
      "Next pose: tensor([6.1324, 6.1501, 3.2416, 3.3267, 6.1311, 6.0349, 6.2299, 6.2107])\n",
      "Reward: -21.87114143371582\n",
      "Discounted Reward: -0.7933881282806396\n",
      "Current pose: tensor([3.0521, 3.1021, 1.6174, 1.6941, 3.0664, 3.0150, 3.1145, 3.1087])\n",
      "Action: tensor([3.0521, 3.1021, 1.6174, 1.6941, 3.0664, 3.0150, 3.1145, 3.1087])\n",
      "Next pose: tensor([6.1041, 6.2043, 3.2349, 3.3881, 6.1327, 6.0301, 6.2289, 6.2174])\n",
      "Reward: -21.95421600341797\n",
      "Discounted Reward: -0.7884376049041748\n",
      "Current pose: tensor([3.0584, 3.0909, 1.6192, 1.6900, 3.0675, 3.0148, 3.1141, 3.1135])\n",
      "Action: tensor([3.0584, 3.0909, 1.6192, 1.6900, 3.0675, 3.0148, 3.1141, 3.1135])\n",
      "Next pose: tensor([6.1169, 6.1818, 3.2385, 3.3801, 6.1350, 6.0295, 6.2282, 6.2271])\n",
      "Reward: -21.950637817382812\n",
      "Discounted Reward: -0.780426025390625\n",
      "Current pose: tensor([3.0565, 3.0965, 1.6177, 1.6919, 3.0682, 3.0132, 3.1168, 3.1144])\n",
      "Action: tensor([3.0565, 3.0965, 1.6177, 1.6919, 3.0682, 3.0132, 3.1168, 3.1144])\n",
      "Next pose: tensor([6.1129, 6.1931, 3.2355, 3.3837, 6.1363, 6.0265, 6.2337, 6.2288])\n",
      "Reward: -21.964256286621094\n",
      "Discounted Reward: -0.7731011509895325\n",
      "Current pose: tensor([3.0679, 3.0972, 1.6257, 1.6911, 3.0708, 3.0092, 3.1159, 3.1137])\n",
      "Action: tensor([3.0679, 3.0972, 1.6257, 1.6911, 3.0708, 3.0092, 3.1159, 3.1137])\n",
      "Next pose: tensor([6.1359, 6.1943, 3.2514, 3.3823, 6.1416, 6.0184, 6.2319, 6.2274])\n",
      "Reward: -21.996912002563477\n",
      "Discounted Reward: -0.7665079832077026\n",
      "Current pose: tensor([3.0714, 3.0425, 1.6165, 1.6385, 3.0715, 3.0132, 3.1143, 3.1072])\n",
      "Action: tensor([3.0714, 3.0425, 1.6165, 1.6385, 3.0715, 3.0132, 3.1143, 3.1072])\n",
      "Next pose: tensor([6.1427, 6.0849, 3.2329, 3.2770, 6.1429, 6.0264, 6.2285, 6.2143])\n",
      "Reward: -21.76342010498047\n",
      "Discounted Reward: -0.7507880330085754\n",
      "Current pose: tensor([3.1088, 3.0960, 1.6215, 1.6587, 3.0682, 3.0162, 3.1105, 3.1037])\n",
      "Action: tensor([3.1088, 3.0960, 1.6215, 1.6587, 3.0682, 3.0162, 3.1105, 3.1037])\n",
      "Next pose: tensor([6.2176, 6.1919, 3.2431, 3.3175, 6.1365, 6.0325, 6.2211, 6.2073])\n",
      "Reward: -21.98102378845215\n",
      "Discounted Reward: -0.7507119178771973\n",
      "Current pose: tensor([3.0805, 3.0759, 1.6215, 1.6555, 3.0631, 3.0168, 3.1072, 3.1048])\n",
      "Action: tensor([3.0805, 3.0759, 1.6215, 1.6555, 3.0631, 3.0168, 3.1072, 3.1048])\n",
      "Next pose: tensor([6.1610, 6.1519, 3.2430, 3.3110, 6.1263, 6.0337, 6.2143, 6.2097])\n",
      "Reward: -21.864490509033203\n",
      "Discounted Reward: -0.7392646670341492\n",
      "Current pose: tensor([3.0633, 2.9772, 1.6182, 1.5999, 3.0625, 3.0170, 3.1019, 3.1057])\n",
      "Action: tensor([3.0633, 2.9772, 1.6182, 1.5999, 3.0625, 3.0170, 3.1019, 3.1057])\n",
      "Next pose: tensor([6.1265, 5.9544, 3.2364, 3.1998, 6.1251, 6.0339, 6.2038, 6.2114])\n",
      "Reward: -21.505037307739258\n",
      "Discounted Reward: -0.7198400497436523\n",
      "Current pose: tensor([3.0717, 2.9831, 1.6109, 1.5834, 3.0625, 3.0117, 3.1000, 3.1119])\n",
      "Action: tensor([3.0717, 2.9831, 1.6109, 1.5834, 3.0625, 3.0117, 3.1000, 3.1119])\n",
      "Next pose: tensor([6.1434, 5.9661, 3.2217, 3.1668, 6.1249, 6.0234, 6.1999, 6.2238])\n",
      "Reward: -21.483837127685547\n",
      "Discounted Reward: -0.7119390964508057\n",
      "Current pose: tensor([3.0758, 3.0194, 1.6156, 1.6105, 3.0606, 3.0127, 3.1022, 3.1125])\n",
      "Action: tensor([3.0758, 3.0194, 1.6156, 1.6105, 3.0606, 3.0127, 3.1022, 3.1125])\n",
      "Next pose: tensor([6.1517, 6.0389, 3.2311, 3.2211, 6.1211, 6.0254, 6.2045, 6.2249])\n",
      "Reward: -21.63235855102539\n",
      "Discounted Reward: -0.7096922397613525\n",
      "Current pose: tensor([3.0956, 3.0148, 1.6182, 1.5979, 3.0586, 3.0130, 3.1035, 3.1124])\n",
      "Action: tensor([3.0956, 3.0148, 1.6182, 1.5979, 3.0586, 3.0130, 3.1035, 3.1124])\n",
      "Next pose: tensor([6.1912, 6.0295, 3.2365, 3.1957, 6.1171, 6.0260, 6.2069, 6.2249])\n",
      "Reward: -21.641538619995117\n",
      "Discounted Reward: -0.7028934359550476\n",
      "Current pose: tensor([3.0866, 2.9995, 1.6165, 1.5906, 3.0597, 3.0129, 3.1039, 3.1133])\n",
      "Action: tensor([3.0866, 2.9995, 1.6165, 1.5906, 3.0597, 3.0129, 3.1039, 3.1133])\n",
      "Next pose: tensor([6.1732, 5.9989, 3.2329, 3.1813, 6.1193, 6.0258, 6.2078, 6.2267])\n",
      "Reward: -21.579683303833008\n",
      "Discounted Reward: -0.6938755512237549\n",
      "Current pose: tensor([3.0864, 3.0192, 1.6175, 1.5975, 3.0620, 3.0119, 3.1034, 3.1152])\n",
      "Action: tensor([3.0864, 3.0192, 1.6175, 1.5975, 3.0620, 3.0119, 3.1034, 3.1152])\n",
      "Next pose: tensor([6.1729, 6.0384, 3.2350, 3.1951, 6.1240, 6.0237, 6.2068, 6.2304])\n",
      "Reward: -21.63996696472168\n",
      "Discounted Reward: -0.6888558268547058\n",
      "Current pose: tensor([3.0895, 3.0112, 1.6190, 1.5789, 3.0633, 3.0107, 3.1023, 3.1165])\n",
      "Action: tensor([3.0895, 3.0112, 1.6190, 1.5789, 3.0633, 3.0107, 3.1023, 3.1165])\n",
      "Next pose: tensor([6.1790, 6.0223, 3.2380, 3.1578, 6.1266, 6.0215, 6.2045, 6.2331])\n",
      "Reward: -21.5966739654541\n",
      "Discounted Reward: -0.6806029081344604\n",
      "Current pose: tensor([3.0794, 2.9938, 1.6145, 1.5742, 3.0631, 3.0109, 3.1052, 3.1193])\n",
      "Action: tensor([3.0794, 2.9938, 1.6145, 1.5742, 3.0631, 3.0109, 3.1052, 3.1193])\n",
      "Next pose: tensor([6.1588, 5.9876, 3.2290, 3.1485, 6.1261, 6.0217, 6.2104, 6.2386])\n",
      "Reward: -21.53447723388672\n",
      "Discounted Reward: -0.6718564033508301\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Placeholder functions\n",
    "def policy(state):\n",
    "    return state\n",
    "\n",
    "def apply_action(state, action):\n",
    "    return state + action\n",
    "\n",
    "def get_reward(state, target_pose):\n",
    "    return -torch.sum(torch.abs(state - target_pose))\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    a = torch.tensor(a) - torch.tensor(b)\n",
    "    b = torch.tensor(c) - torch.tensor(b)\n",
    "    \n",
    "    cosine_angle = torch.dot(a, b) / (torch.norm(a) * torch.norm(b))\n",
    "    angle = torch.arccos(cosine_angle)\n",
    "    \n",
    "    return angle\n",
    "\n",
    "\n",
    "discount_factor = 0.99\n",
    "\n",
    "def get_discounted_reward(state, target_pose, t):\n",
    "    # Calculate the reward as the negative distance to the target\n",
    "    distance = torch.sum(torch.abs(state - target_pose))\n",
    "    \n",
    "    # Apply the discount factor\n",
    "    discounted_reward = -(discount_factor ** t) * distance\n",
    "    return discounted_reward\n",
    "\n",
    "\n",
    "def get_joint_angles(landmarks):\n",
    "    # Extract landmarks\n",
    "    left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "    left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "    left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "    left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "    left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "    left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "    right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "    right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "    right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "    right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "    right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "    right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "\n",
    "    # Calculate angles\n",
    "    left_elbow_angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "    right_elbow_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "    left_shoulder_angle = calculate_angle(left_hip, left_shoulder, left_elbow)\n",
    "    right_shoulder_angle = calculate_angle(right_hip, right_shoulder, right_elbow)\n",
    "    left_hip_angle = calculate_angle(left_knee, left_hip, left_shoulder)\n",
    "    right_hip_angle = calculate_angle(right_knee, right_hip, right_shoulder)\n",
    "    left_knee_angle = calculate_angle(left_ankle, left_knee, left_hip)\n",
    "    right_knee_angle = calculate_angle(right_ankle, right_knee, right_hip)\n",
    "\n",
    "    joint_angles = [left_elbow_angle, right_elbow_angle, left_shoulder_angle, right_shoulder_angle, left_hip_angle, right_hip_angle, left_knee_angle, right_knee_angle]\n",
    "\n",
    "    return joint_angles  # Return a list of joint angles. Add all joint angles you're interested in\n",
    "\n",
    "# For the sake of demonstration, let's define a target_pose\n",
    "target_pose = torch.tensor([3.1393, 2.9625, 1.6294, 1.4661, 3.0787, 3.0327, 3.1403, 3.1373])  # Change this according to your use case\n",
    "t = 0  # Initialize time step\n",
    "\n",
    "reward_list = []  # List to store rewards\n",
    "disc_reward_list = []  # List to store discounted rewards\n",
    "time = []  # List to store time steps\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display, and convert the BGR image to RGB.\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "        # To improve performance, optionally mark the image as not writeable to pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Draw the pose annotation on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Show the image\n",
    "        cv2.imshow('MediaPipe Pose', image)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get joint angles\n",
    "            joint_angles = get_joint_angles(landmarks)\n",
    "            current_pose = torch.tensor(joint_angles)  # current_pose is the same as state in this case\n",
    "\n",
    "            print(f\"Current pose: {current_pose}\")\n",
    "\n",
    "            action = policy(current_pose)\n",
    "\n",
    "            print(f\"Action: {action}\")\n",
    "\n",
    "            next_pose = apply_action(current_pose, action)\n",
    "\n",
    "            print(f\"Next pose: {next_pose}\")\n",
    "\n",
    "            reward = get_reward(next_pose, target_pose)\n",
    "            print(f\"Reward: {reward}\")\n",
    "                       \n",
    "            discounted_reward = get_discounted_reward(next_pose, target_pose, t)\n",
    "\n",
    "            print(f\"Discounted Reward: {discounted_reward}\")\n",
    "\n",
    "            # Increment the time step\n",
    "            t += 1\n",
    "            reward_list.append(reward)\n",
    "            disc_reward_list.append(discounted_reward)\n",
    "            time.append(t)\n",
    "        \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Exception: {e}\")\n",
    "\n",
    "cap.release()\n",
    "# Plotting\n",
    "plt.plot(time, reward_list, label='Reward')\n",
    "plt.plot(time, disc_reward_list, label='Discounted Reward')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Reward and Discounted Reward over Time')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93266e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
